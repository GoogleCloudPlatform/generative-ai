{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "ht3MT6z2u4B6"
      },
      "id": "ht3MT6z2u4B6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodal Analysis and Vector Search with BigQuery ML\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/bigquery/import?url=https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/applying-llms-to-data/ai-assisted-data-science/ai-assisted-data-science.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/bigquery/v1/32px.svg\" alt=\"BigQuery Studio logo\"><br> Open in BigQuery Studio\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/applying-llms-to-data/ai-assisted-data-science/ai-assisted-data-science.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fuse-cases%2Fapplying-llms-to-data%2Fai-assisted-data-science%2Fai-assisted-data-science.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/applying-llms-to-data/ai-assisted-data-science/ai-assisted-data-science.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://storage.googleapis.com/github-repo/generative-ai/logos/GitHub_Invertocat_Dark.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>"
      ],
      "metadata": {
        "id": "9Ku6cXXnwATV"
      },
      "id": "9Ku6cXXnwATV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Author(s) |\n",
        "| --- |\n",
        "| [Jeff Nelson](https://github.com/jeffonelson) |"
      ],
      "metadata": {
        "id": "lANfIejdvZYQ"
      },
      "id": "lANfIejdvZYQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "In this notebook, you'll explore a multimodal data science workflow in BigQuery. You will start with a raw dataset of house listings, enrich it with AI, build a clustering model to find customer segments, and finally, build a powerful text-to-image and image-to-image search engine.\n",
        "\n",
        "Next, you'll compare this SQL-native workflow with a modern, generative AI approach by using the [Data Science Agent](https://cloud.google.com/bigquery/docs/colab-data-science-agent) to automatically generate a Python-based clustering model from a simple text prompt.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "*   **Prepare data** and perform feature engineering on a raw dataset.\n",
        "*   **Enrich data** by using BigQuery ML's AI functions to analyze images.\n",
        "*   **Build and evaluate** a K-means clustering model using BQML.\n",
        "*   **Automate model creation** by using the Data Science Agent to generate a Python clustering model.\n",
        "*   **Generate embeddings** for house images using a multimodal model.\n",
        "*   **Perform vector search** to find similar houses using text or image queries."
      ],
      "metadata": {
        "id": "XJy67x0Cn4s4"
      },
      "id": "XJy67x0Cn4s4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Before you can begin the analysis, you need to set up your environment. This involves enabling the necessary APIs, creating a resource connection for BigQuery, and configuring permissions for the service account that connection will use."
      ],
      "metadata": {
        "id": "B8vBqblSM_9w"
      },
      "id": "B8vBqblSM_9w"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create BigQuery Cloud resource connection\n",
        "\n",
        "Create a [Cloud resource connection](https://cloud.google.com/bigquery/docs/create-cloud-resource-connection). This connection acts as a secure bridge between BigQuery and other Google Cloud services. It allows BigQuery to call the Gemini models hosted on Vertex AI for inference and data enrichment."
      ],
      "metadata": {
        "id": "LjsOfBUTNMR5"
      },
      "id": "LjsOfBUTNMR5"
    },
    {
      "cell_type": "code",
      "source": [
        "!bq mk --connection --location=us --connection_type=CLOUD_RESOURCE ai_connection"
      ],
      "metadata": {
        "id": "mt4Xdf2uM73o"
      },
      "id": "mt4Xdf2uM73o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure environment and grant permissions\n",
        "\n",
        "The next block of code handles the necessary setup for your environment. These cells perform several key actions:\n",
        "\n",
        "*   **Capture variables:** Your `PROJECT_ID` and the connection's service account email are captured as Python variables.\n",
        "*   **Initialize a GCS client:** A connection to Google Cloud Storage is created so you can access the house listing images.\n",
        "*   **Grant permissions:** The necessary IAM roles ([`Storage Object Viewer`](https://cloud.google.com/storage/docs/access-control/iam-roles#storage.objectViewer) and [`Vertex AI User`](https://cloud.google.com/vertex-ai/docs/general/access-control#aiplatform.user)) are granted to the connection's service account, allowing it to read images and call Vertex AI models.\n",
        "*   **Define a helper function:** The `display_images` function is defined, which you'll use to visualize images throughout the notebook.\n",
        "*   **Enable interactive tables:** A Colab extension is enabled to render pandas DataFrames as interactive tables."
      ],
      "metadata": {
        "id": "3Z1O6H-8NaSx"
      },
      "id": "3Z1O6H-8NaSx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Service Account\n",
        "SERVICE_ACCT = !bq show --format=prettyjson --connection us.ai_connection | grep \"serviceAccountId\" | cut -d '\"' -f 4\n",
        "SERVICE_ACCT_EMAIL = SERVICE_ACCT[-1]\n",
        "print(SERVICE_ACCT_EMAIL)"
      ],
      "metadata": {
        "id": "jdSIMRCcNit8"
      },
      "id": "jdSIMRCcNit8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set project id variables for Python and Shell\n",
        "PROJECT_ID = !gcloud config get-value project\n",
        "PROJECT_ID = PROJECT_ID[-1]\n",
        "%env PROJECT_ID=$PROJECT_ID"
      ],
      "metadata": {
        "id": "D9MC8XqQmD97"
      },
      "id": "D9MC8XqQmD97",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "# Define bucket containing housing images\n",
        "bucket_name = 'dataproc-metastore-public-binaries'\n",
        "# Create Cloud Storage client\n",
        "client = storage.Client(project=PROJECT_ID)\n",
        "bucket = client.bucket(bucket_name)"
      ],
      "metadata": {
        "id": "iRMV48N6XoYY"
      },
      "id": "iRMV48N6XoYY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Grant permissions\n",
        "!gcloud projects add-iam-policy-binding --format=none $PROJECT_ID --member=serviceAccount:$SERVICE_ACCT_EMAIL --role='roles/storage.objectViewer'\n",
        "!gcloud projects add-iam-policy-binding --format=none $PROJECT_ID --member=serviceAccount:$SERVICE_ACCT_EMAIL --role='roles/aiplatform.user'\n",
        "\n",
        "# Wait ~60 seconds, to give IAM updates time to propagate. Otherwise, subsequent cells may fail.\n",
        "time.sleep(60)"
      ],
      "metadata": {
        "id": "HvATOolaNmoQ"
      },
      "id": "HvATOolaNmoQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "import pandas as pd\n",
        "import io\n",
        "import math\n",
        "\n",
        "# Helper function to display images in a DataFrame\n",
        "\n",
        "def display_images(df, uri_column='uri', title_column=None):\n",
        "    \"\"\"\n",
        "    Displays images from a DataFrame in a 3-column grid.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame with a column containing GCS URIs.\n",
        "        uri_column (str): The name of the column containing the GCS URIs.\n",
        "        title_column (str, optional): The name of the column to use for the image title.\n",
        "                                      If None, the image filename is used.\n",
        "    \"\"\"\n",
        "    # Calculate grid size\n",
        "    num_images = len(df)\n",
        "    if num_images == 0:\n",
        "        print(\"No images to display.\")\n",
        "        return\n",
        "\n",
        "    cols = 3\n",
        "    rows = math.ceil(num_images / cols)\n",
        "\n",
        "    # Handle single image case for correct subplot array shape\n",
        "    if num_images == 1:\n",
        "        fig, axs = plt.subplots(1, 1, figsize=(3.5, 3.5))\n",
        "        axs = [axs]\n",
        "    else:\n",
        "        fig, axs = plt.subplots(rows, cols, figsize=(10, rows * 3.5))\n",
        "        axs = axs.flatten()\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        if i >= len(axs):\n",
        "            break\n",
        "\n",
        "        # 1. Extract the image path from the full GCS URI\n",
        "        image_uri = row[uri_column]\n",
        "        image_path = image_uri.split('/', 3)[-1]\n",
        "\n",
        "        # 2. Get the image from GCS\n",
        "        try:\n",
        "            blob = bucket.blob(image_path)\n",
        "            image_bytes = blob.download_as_bytes()\n",
        "            image = PIL.Image.open(io.BytesIO(image_bytes))\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load image {image_uri}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # 3. Plot the image\n",
        "        axs[i].imshow(image)\n",
        "\n",
        "        # Determine the title\n",
        "        if title_column and title_column in df.columns:\n",
        "            title = f\"Cluster: {row[title_column]}\"\n",
        "        else:\n",
        "            title = image_path.split('/')[-1]\n",
        "\n",
        "        axs[i].set_title(title, fontsize=10)\n",
        "        axs[i].axis('off')\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for j in range(num_images, len(axs)):\n",
        "        axs[j].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_zLmwszkkJC4"
      },
      "id": "_zLmwszkkJC4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enable interactive tables for DataFrames\n",
        "\n",
        "For a better data exploration experience, you can enable a [Colab extension](https://colab.sandbox.google.com/notebooks/data_table.ipynb) that renders pandas DataFrames as interactive, sortable tables. This makes it much easier to inspect large amounts of data."
      ],
      "metadata": {
        "id": "9YUTHxYpXGQH"
      },
      "id": "9YUTHxYpXGQH"
    },
    {
      "cell_type": "code",
      "source": [
        "# %load_ext google.colab.data_table"
      ],
      "metadata": {
        "id": "h8DPEKFrXA2q"
      },
      "id": "h8DPEKFrXA2q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "## 1. Data Preparation and Feature Engineering\n",
        "\n",
        "### Create a BigQuery dataset\n",
        "\n",
        "A [BigQuery dataset](https://cloud.google.com/bigquery/docs/datasets-intro) is a container that holds all of your other BigQuery objects, including tables, views, and models."
      ],
      "metadata": {
        "id": "FONKhnbyWx-x"
      },
      "id": "FONKhnbyWx-x"
    },
    {
      "cell_type": "code",
      "source": [
        "!bq mk --dataset housing_dataset"
      ],
      "metadata": {
        "id": "L3Ih_zHiW5g8"
      },
      "id": "L3Ih_zHiW5g8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the raw data into a BigQuery table\n",
        "\n",
        "You can now load your source data using the [`bq load`](https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv#loading_csv_data_into_a_table) command. It  directly loads a CSV file from a public Google Cloud Storage bucket into a new BigQuery table named `listings`."
      ],
      "metadata": {
        "id": "EYtdDkK-ZbD5"
      },
      "id": "EYtdDkK-ZbD5"
    },
    {
      "cell_type": "code",
      "source": [
        "!bq load \\\n",
        "    --autodetect \\\n",
        "    --source_format=CSV \\\n",
        "    --skip_leading_rows=1 \\\n",
        "    housing_dataset.listings \\\n",
        "    gs://housing-data-qwiklab/housing-data.csv"
      ],
      "metadata": {
        "id": "1JqWUw49XxWN"
      },
      "id": "1JqWUw49XxWN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6952daf"
      },
      "source": [
        "\n",
        "## Explore the data with `ML.DESCRIBE_DATA`\n",
        "\n",
        "Next, you'll perform exploratory data analysis to understand the data's characteristics. Instead of writing many individual `COUNT`, `AVG`, and `STDDEV` queries, you can use the [`ML.DESCRIBE_DATA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-describe-data) function.\n",
        "\n",
        "The function returns descriptive statistics for each column in a table, giving you a quick overview of distributions, missing values, and potential outliers.\n"
      ],
      "id": "e6952daf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1331e1c"
      },
      "source": [
        "%%bigquery --project {PROJECT_ID}\n",
        "\n",
        "SELECT *\n",
        "FROM\n",
        "  ML.DESCRIBE_DATA((SELECT * FROM `housing_dataset.listings`));"
      ],
      "id": "f1331e1c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean, filter, and enrich the data\n",
        "\n",
        "Create a new, cleaned table from the raw data. The following query:\n",
        "\n",
        "1.  **Filters the data** to include only listings that are currently 'For Sale'.\n",
        "2.  **Creates a new feature**, `property_age`, by subtracting the `year_built` from the current year.\n",
        "3.  **Creates an [`ObjectRef`](https://cloud.google.com/blog/products/data-analytics/new-objectref-data-type-brings-unstructured-data-into-bigquery?e=48754805)**, a BigQuery object that allows you to reference unstructured image data in Google Cloud Storage."
      ],
      "metadata": {
        "id": "gAOfp_g9IUbx"
      },
      "id": "gAOfp_g9IUbx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbfde5ec"
      },
      "source": [
        "%%bigquery --project {PROJECT_ID}\n",
        "\n",
        "CREATE OR REPLACE TABLE `housing_dataset.listings` AS\n",
        "SELECT\n",
        "  *,\n",
        "  EXTRACT(YEAR FROM CURRENT_DATE()) - year_built AS property_age,\n",
        "  OBJ.FETCH_METADATA(OBJ.MAKE_REF(house_uri, 'us.ai_connection')) as image_ref\n",
        "FROM\n",
        "  `housing_dataset.listings`\n",
        "WHERE sale_status = 'For Sale';"
      ],
      "id": "dbfde5ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. Multimodal Enrichment with AI Functions\n",
        "\n",
        "### Create a remote model for Gemini\n",
        "\n",
        "To use a like Gemini from within BigQuery, you need to create a [Remote Model](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model). This object acts as a secure pointer to the underlying model hosted on Vertex AI.\n",
        "\n",
        "Then, you can reference this remote model in your SQL queries, allowing you to use Gemini's powerful capabilities to analyze and enrich your data."
      ],
      "metadata": {
        "id": "E19E_rcpcoXi"
      },
      "id": "E19E_rcpcoXi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "For BigQuery's [`AI.GENERATE_TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-table) to call Gemini to parse unstructured data, we first need to create a [Remote Model](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model). We'll create that and move to our multimodal query."
      ],
      "metadata": {
        "id": "jyby41N0bChT"
      },
      "id": "jyby41N0bChT"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project {PROJECT_ID}\n",
        "\n",
        "CREATE OR REPLACE MODEL `housing_dataset.gemini`\n",
        "REMOTE WITH CONNECTION `us.ai_connection`\n",
        "  OPTIONS(ENDPOINT = 'gemini-2.5-flash');"
      ],
      "metadata": {
        "id": "muSly43kbGdt"
      },
      "id": "muSly43kbGdt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enrich images with `AI.GENERATE_TABLE`\n",
        "\n",
        "You'll use the remote model with the `AI.GENERATE_TABLE` function. The follwing query contains:\n",
        "1. A **prompt** to the Gemini model, asking it to analyze the house image (`image_ref`) and extract specific features.\n",
        "2.  An **output schema**. You can define exact column names and data types (e.g. `near_water BOOL`) you want it to return.\n",
        "\n",
        "The result is a new table, `listings_multimodal`, that contains all the columns plus the new, AI-generated features."
      ],
      "metadata": {
        "id": "DijByYGYIZIU"
      },
      "id": "DijByYGYIZIU"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project {PROJECT_ID}\n",
        "\n",
        "CREATE OR REPLACE TABLE `housing_dataset.listings_multimodal` AS (\n",
        "SELECT\n",
        "id,\n",
        "price,\n",
        "sq_ft,\n",
        "year_built,\n",
        "city,\n",
        "zipcode,\n",
        "number_of_rooms,\n",
        "number_of_baths,\n",
        "acre_lot,\n",
        "property_age,\n",
        "near_water,\n",
        "number_windows,\n",
        "prop_description,\n",
        "image_ref\n",
        "FROM AI.GENERATE_TABLE(\n",
        "  MODEL `housing_dataset.gemini`,\n",
        "  (\n",
        "    SELECT (\n",
        "      'Analyze the following image to find whether it is near a body of water,'\n",
        "      'the number of windows, and give a brief description of the property.'\n",
        "      , image_ref\n",
        "    ) AS prompt,\n",
        "    *\n",
        "    FROM `housing_dataset.listings`\n",
        "  ),\n",
        "  STRUCT(\n",
        "     \"near_water BOOL, number_windows INT64, prop_description STRING\" AS output_schema\n",
        "  )\n",
        "));"
      ],
      "metadata": {
        "id": "7L0lP5SObaJr"
      },
      "id": "7L0lP5SObaJr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Review the enriched data\n",
        "\n",
        "Let's examine the new table. The last three columns (`near_water`, `number_windows`, `prop_description`) were generated by the Gemini model analyzing each house image."
      ],
      "metadata": {
        "id": "6O5pFprsjIG_"
      },
      "id": "6O5pFprsjIG_"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project {PROJECT_ID}\n",
        "\n",
        "SELECT *\n",
        "FROM `housing_dataset.listings_multimodal`\n",
        "LIMIT 2"
      ],
      "metadata": {
        "id": "30HQkt6sjK7Z"
      },
      "id": "30HQkt6sjK7Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3522675"
      },
      "source": [
        "---\n",
        "## 3. Model Training with K-Means Clustering\n",
        "\n",
        "With your enriched and feature-engineered dataset, you can now build a machine learning model. Your goal is to segment the house listings into distinct groups based on their characteristics. K-means clustering is an unsupervised learning algorithm that groups data points based on their similarity.\n",
        "\n",
        "You'll use `CREATE MODEL` to train a K-means model with 3 clusters. By including the `model_registry='VERTEX_AI'` [option](https://cloud.google.com/bigquery/docs/managing-models-vertex), the model is also automatically registered in the [Vertex AI Model Registry](https://cloud.google.com/vertex-ai/docs/model-registry/introduction) upon completion. This makes it visible and deployable alongside your other custom models in Vertex AI."
      ],
      "id": "e3522675"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "057ad575"
      },
      "source": [
        "%%bigquery --project {PROJECT_ID}\n",
        "\n",
        "CREATE OR REPLACE MODEL `housing_dataset.kmeans_clustering_model`\n",
        "OPTIONS(model_type='KMEANS', num_clusters=3,\n",
        "        model_registry = 'VERTEX_AI', VERTEX_AI_MODEL_ID = 'housing_clustering') AS\n",
        "SELECT\n",
        "  price,\n",
        "  sq_ft,\n",
        "  year_built,\n",
        "  number_of_rooms,\n",
        "  number_of_baths,\n",
        "  acre_lot,\n",
        "  property_age,\n",
        "  near_water,\n",
        "  number_windows\n",
        "FROM\n",
        "  `housing_dataset.listings_multimodal`;"
      ],
      "id": "057ad575",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52e64434"
      },
      "source": [
        "---\n",
        "## 4. Model Evaluation and Prediction\n",
        "\n",
        "### Evaluate the clustering model\n",
        "\n",
        "Evaluate the model with [`ML.EVALUATE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-evaluate). This function returns key metrics like the Davies-Bouldin index to help you measure cluster quality and separation."
      ],
      "id": "52e64434"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26e0edd7"
      },
      "source": [
        "%%bigquery --project {PROJECT_ID}\n",
        "\n",
        "SELECT * FROM ML.EVALUATE(MODEL `housing_dataset.kmeans_clustering_model`);"
      ],
      "id": "26e0edd7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze cluster centroids\n",
        "\n",
        "Inspect the cluster centroids with [`ML.CENTROIDS`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-centroids). Each centroid represents the \"average\" house in a cluster, making it easy to compare the defining characteristics of each segment."
      ],
      "metadata": {
        "id": "rD6LwGszJ3bR"
      },
      "id": "rD6LwGszJ3bR"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project {PROJECT_ID}\n",
        "\n",
        "SELECT * FROM ML.CENTROIDS(MODEL `housing_dataset.kmeans_clustering_model`)\n",
        "WHERE feature IN ( 'price', 'property_age' )\n",
        "ORDER BY feature, centroid_id;"
      ],
      "metadata": {
        "id": "0R8ZGIjYJkg-"
      },
      "id": "0R8ZGIjYJkg-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assign listings to clusters with `ML.PREDICT`\n",
        "\n",
        "Use [`ML.PREDICT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-predict) to assign each house to a cluster. The function returns a `CENTROID_ID` for each listing, indicating which cluster it belongs to. We'll rename `CENTROID_ID` to `cluster` for ease of use."
      ],
      "metadata": {
        "id": "wPrkl7Gcky_t"
      },
      "id": "wPrkl7Gcky_t"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc9392ad"
      },
      "source": [
        "%%bigquery df --project {PROJECT_ID}\n",
        "\n",
        "SELECT\n",
        "  CENTROID_ID AS cluster,\n",
        "  * EXCEPT(CENTROID_ID)\n",
        "FROM\n",
        "  ML.PREDICT(\n",
        "    MODEL `housing_dataset.kmeans_clustering_model`,\n",
        "    TABLE `housing_dataset.listings_multimodal`\n",
        ");"
      ],
      "id": "bc9392ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 5. Visualize and Interpret Clusters\n",
        "\n",
        "With each property now assigned to a cluster, you can visualize the results to better understand the distinct housing segments."
      ],
      "metadata": {
        "id": "IiPMp9jkLGxj"
      },
      "id": "IiPMp9jkLGxj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare cluster characteristics\n",
        "\n",
        "Visualizations make it easy to compare the clusters. The following plots use:\n",
        "*   **Box plots** to compare the distribution of numeric features like `price`.\n",
        "*   **Bar charts** to compare the counts of boolean features like `near_water`."
      ],
      "metadata": {
        "id": "1FLU3-7fp6Ja"
      },
      "id": "1FLU3-7fp6Ja"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Box Plots for Numeric Features"
      ],
      "metadata": {
        "id": "xU8jWif2HlPh"
      },
      "id": "xU8jWif2HlPh"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assume 'df' is your DataFrame with the 'cluster' column\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.suptitle('Sample Numeric Variable Distributions by Cluster', fontsize=16)\n",
        "\n",
        "# Boxplot for Price (Corrected)\n",
        "plt.subplot(1, 2, 1)\n",
        "# Assign 'cluster' to hue and turn off the redundant legend\n",
        "sns.boxplot(x='cluster', y='price', data=df, hue='cluster', palette='tab20', legend=False)\n",
        "plt.title('Price Distribution per Cluster')\n",
        "plt.ylabel('Price')\n",
        "plt.xlabel('Cluster ID')\n",
        "\n",
        "# Boxplot for Property Age (Corrected)\n",
        "plt.subplot(1, 2, 2)\n",
        "# Assign 'cluster' to hue and turn off the redundant legend\n",
        "sns.boxplot(x='cluster', y='property_age', data=df, hue='cluster', palette='tab20', legend=False)\n",
        "plt.title('Property Age Distribution per Cluster')\n",
        "plt.ylabel('Property Age (Years)')\n",
        "plt.xlabel('Cluster ID')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hKjcSmkqpg7x"
      },
      "id": "hKjcSmkqpg7x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bar Charts for Categorical/Boolean Features"
      ],
      "metadata": {
        "id": "TvSRM4Xnp1Av"
      },
      "id": "TvSRM4Xnp1Av"
    },
    {
      "cell_type": "code",
      "source": [
        "water_crosstab = pd.crosstab(df['cluster'], df['near_water'])\n",
        "\n",
        "water_proportions = water_crosstab.div(water_crosstab.sum(axis=1), axis=0)\n",
        "\n",
        "water_proportions.plot(\n",
        "    kind='bar',\n",
        "    stacked=True,\n",
        "    figsize=(10, 6),\n",
        "    colormap='tab20' # Changed from 'coolwarm' to 'Pastel1'\n",
        ")\n",
        "\n",
        "plt.title('Proportion of Properties Near Water within Each Cluster', fontsize=16)\n",
        "plt.xlabel('Cluster ID')\n",
        "plt.ylabel('Proportion')\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='Is Near Water?', labels=['No', 'Yes'])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "omgSiqGpHHZ_"
      },
      "id": "omgSiqGpHHZ_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6. Generate Cluster Descriptions with Gemini\n",
        "\n",
        "While the centroids and visualizations are useful, you can use generative AI to create human-readable descriptions for each cluster.\n",
        "\n",
        "First, you'll aggregate the average statistics for each cluster into a pandas DataFrame."
      ],
      "metadata": {
        "id": "Nu7u6X7PlHUv"
      },
      "id": "Nu7u6X7PlHUv"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery df_cluster_stats --project {PROJECT_ID}\n",
        "\n",
        "SELECT\n",
        "  centroid_id AS cluster,\n",
        "  AVG(price) AS avg_price,\n",
        "  AVG(sq_ft) AS avg_sq_ft,\n",
        "  AVG(year_built) AS avg_year_built,\n",
        "  AVG(number_of_rooms) AS avg_number_of_rooms,\n",
        "  AVG(number_of_baths) AS avg_number_of_baths,\n",
        "  AVG(acre_lot) AS avg_acre_lot,\n",
        "  AVG(property_age) AS avg_property_age,\n",
        "  AVG(number_windows) AS avg_number_windows,\n",
        "  COUNT(*) AS cluster_size\n",
        "FROM\n",
        "  ML.PREDICT(MODEL `housing_dataset.kmeans_clustering_model`,\n",
        "    TABLE `housing_dataset.listings_multimodal`)\n",
        "GROUP BY\n",
        "  cluster\n",
        "ORDER BY\n",
        "  cluster;"
      ],
      "metadata": {
        "id": "ECCeTbB7K9w4"
      },
      "id": "ECCeTbB7K9w4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the prompt for Gemini\n",
        "\n",
        "Next, you'll convert the statistics DataFrame into a simple string and create a prompt template. This prompt instructs the model to act as a real estate professional and provides a clear structure for the desired output."
      ],
      "metadata": {
        "id": "XH2W6Ju7Lv24"
      },
      "id": "XH2W6Ju7Lv24"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the df_cluster_stats to a string for input to a Gemini model\n",
        "cluster_info = df_cluster_stats.to_string()\n",
        "\n",
        "# Define the prompt template\n",
        "prompt = f\"\"\"You're a real estate professional. Come up with a description of each cluster.\n",
        "\n",
        "Clusters:\n",
        "{cluster_info}\n",
        "\n",
        "For each cluster, please return:\n",
        "1. A category for the cluster that describes the type of houses\n",
        "2. A couple of summary statistics - average price and square footage\n",
        "3. Key characteristics of the cluster\n",
        "4. A target buyer\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "w9Vzn69PgDgb"
      },
      "id": "w9Vzn69PgDgb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate cluster descriptions with a Gemini model\n",
        "\n",
        "With the prompt and data prepared, you can now send the request to a Gemini model through the Vertex AI SDK to generate the descriptions."
      ],
      "metadata": {
        "id": "EXWfa2Hsn2kY"
      },
      "id": "EXWfa2Hsn2kY"
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "from IPython.display import Markdown\n",
        "\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Pass string with cluster information to Gemini model\n",
        "model = GenerativeModel(model_name=\"gemini-2.5-flash\")\n",
        "response = model.generate_content(\n",
        "    prompt,\n",
        "    generation_config={\n",
        "        \"temperature\": 0.2,\n",
        "        \"max_output_tokens\": 4096\n",
        "    }\n",
        ")\n",
        "\n",
        "# Display the response\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "gU9iZu-BgQdQ"
      },
      "id": "gU9iZu-BgQdQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize a sample from each cluster\n",
        "\n",
        "To complement the generated text descriptions, you can also visualize a sample image from each cluster. This gives a quick visual check on what a sample from each cluster looks like."
      ],
      "metadata": {
        "id": "t_E8RmodtbbP"
      },
      "id": "t_E8RmodtbbP"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery df_example_images --project {PROJECT_ID}\n",
        "\n",
        "# Select one row per centroid_id and generate signed URLs\n",
        "\n",
        "SELECT\n",
        "  t1.centroid_id AS cluster,\n",
        "  ANY_VALUE(t2.image_ref).uri AS uri,\n",
        "  ANY_VALUE(t2.id) AS id\n",
        "FROM\n",
        "  ML.PREDICT(MODEL `housing_dataset.kmeans_clustering_model`, TABLE `housing_dataset.listings_multimodal`) AS t1\n",
        "JOIN\n",
        "  `housing_dataset.listings_multimodal` AS t2\n",
        "ON\n",
        "  t1.id = t2.id\n",
        "GROUP BY\n",
        "  cluster\n",
        "ORDER BY\n",
        "  cluster"
      ],
      "metadata": {
        "id": "tI4JfgONkqrV"
      },
      "id": "tI4JfgONkqrV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_images(df_example_images, uri_column='uri', title_column='cluster')"
      ],
      "metadata": {
        "id": "tNZEDhJhkr3H"
      },
      "id": "tNZEDhJhkr3H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 7. Automate Modeling with the Data Science Agent\n",
        "\n",
        "Now, you'll explore a different approach to the same problem. Instead of writing SQL and Python code manually, you will use the integrated [**Data Science Agent**](https://cloud.google.com/bigquery/docs/colab-data-science-agent) to automatically generate code for a K-means clustering model.\n",
        "\n",
        "This section is a placeholder to demonstrate where you would switch to the agent. In a live environment, you would open a new notebook and use the following prompt to have the agent build the model for you.\n",
        "\n",
        "To use the Data Science Agent, follow these steps:\n",
        "1. Follow [documentation steps](https://cloud.google.com/bigquery/docs/colab-data-science-agent#before_you_begin) to enable the proper APIs.\n",
        "2. Open a new Colab Enterprise Notebook in BigQuery.\n",
        "3. Open the Data Science Agent (it opens as a modal at the bottom of the screen or as a side pane).\n",
        "4. Write `@housing_dataset.listings_multimodal` to @ select the proper table for context.\n",
        "5. Give the Agent the following prompt and click-to-run the code that is generated: ```Use this table to generate a k-means clustering model to generate 3 clusters for housing listings. Then help me understand the characteristics of each of these clusters, so I can market to them as a real estate professional. Use Python.```\n",
        "6. Feel free to ask follow-up questions, ask for SQL or Spark instead of Python, or simply play around with the integrated agent.\n",
        "6. Once satisfied with the results, return back to this notebook for the next section."
      ],
      "metadata": {
        "id": "iUco9FZnl0iR"
      },
      "id": "iUco9FZnl0iR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 8. Multimodal Search with Embeddings and Vector Search\n",
        "\n",
        "In this final section, you will use a multimodal embedding model to convert images into [vector embeddings](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-embedding#embeddings) and then use BigQuery's built-in [vector search](https://cloud.google.com/bigquery/docs/vector-search-intro) capabilities to find similar houses based on a text description or another image."
      ],
      "metadata": {
        "id": "sfHY9-E2OxgG"
      },
      "id": "sfHY9-E2OxgG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a remote model for embeddings\n",
        "\n",
        "Create a remote model that points to the [`multimodalembedding@001`](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings) model in Vertex AI. This model converts images and text into high-dimensional numeric vectors, known as embeddings."
      ],
      "metadata": {
        "id": "64ORffYcmp_E"
      },
      "id": "64ORffYcmp_E"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project {PROJECT_ID}\n",
        "\n",
        "CREATE OR REPLACE MODEL housing_dataset.multimodal_embedding_model\n",
        "REMOTE WITH CONNECTION DEFAULT\n",
        "OPTIONS (ENDPOINT = 'multimodalembedding@001');"
      ],
      "metadata": {
        "id": "zXKyKu9yPLbn"
      },
      "id": "zXKyKu9yPLbn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate image embeddings\n",
        "\n",
        "Use [`ML.GENERATE_EMBEDDING`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-embedding) to pass each house image to the model. This creates a new table, `home_embeddings`, containing the original image reference and its corresponding 1408-dimension vector embedding."
      ],
      "metadata": {
        "id": "7u3R0xGQm0Q7"
      },
      "id": "7u3R0xGQm0Q7"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project {PROJECT_ID}\n",
        "\n",
        "CREATE OR REPLACE TABLE housing_dataset.home_embeddings AS\n",
        "  SELECT\n",
        "  id,\n",
        "  price,\n",
        "  sq_ft,\n",
        "  prop_description,\n",
        "  image_ref,\n",
        "  ml_generate_embedding_result AS mm_embedding\n",
        "FROM ML.GENERATE_EMBEDDING(\n",
        "  MODEL housing_dataset.multimodal_embedding_model,\n",
        "  (\n",
        "    SELECT *, image_ref AS content from housing_dataset.listings_multimodal),\n",
        "    STRUCT(TRUE AS flatten_json_output\n",
        "  )\n",
        ");"
      ],
      "metadata": {
        "id": "1Z3WYs3sPf_D"
      },
      "id": "1Z3WYs3sPf_D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Review the generated embeddings\n",
        "\n",
        "Run a quick `SELECT` query to inspect the `home_embeddings` table. This is a good practice to verify that the `mm_embedding` column was created correctly before you build an index on it."
      ],
      "metadata": {
        "id": "mFW3MzIMSvvu"
      },
      "id": "mFW3MzIMSvvu"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project {PROJECT_ID}\n",
        "\n",
        "SELECT *\n",
        "FROM housing_dataset.home_embeddings\n",
        "LIMIT 2"
      ],
      "metadata": {
        "id": "xJzQpqNMRJOn"
      },
      "id": "xJzQpqNMRJOn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a vector index for efficient search\n",
        "\n",
        "To enable fast and scalable similarity searches, create a [`VECTOR INDEX`](https://cloud.google.com/bigquery/docs/vector-index) on the embedding column. The index allows BigQuery to find the nearest neighbors much more efficiently than a full table scan.\n",
        "\n",
        "Vector indexes are ideal for large datasets. Because we only have ~80 records here, we'll get an error that our data isn't large enough to benefit from an index."
      ],
      "metadata": {
        "id": "VP9QOrB5T86e"
      },
      "id": "VP9QOrB5T86e"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project $PROJECT_ID\n",
        "\n",
        "CREATE OR REPLACE\n",
        "  VECTOR INDEX `house_images_index`\n",
        "ON\n",
        "  housing_dataset.home_embeddings(mm_embedding)\n",
        "  OPTIONS (\n",
        "    index_type = 'IVF',\n",
        "    distance_type = 'COSINE');"
      ],
      "metadata": {
        "id": "2lQL9YG1SJX-"
      },
      "id": "2lQL9YG1SJX-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform text-to-image search\n",
        "\n",
        "Now, perform a similarity search using [`VECTOR_SEARCH`](https://cloud.google.com/bigquery/docs/reference/standard-sql/search_functions#vector_search). A subquery first generates an embedding for the text \"house near the ocean\" and the main query then finds the 3 images whose embeddings are most similar to that text query.\n",
        "\n",
        "Note that we're searching text-to-image without using metadata tags on the images."
      ],
      "metadata": {
        "id": "dVzjjsrqnt9T"
      },
      "id": "dVzjjsrqnt9T"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery text_to_image_df --project {PROJECT_ID}\n",
        "\n",
        "SELECT base.image_ref.uri\n",
        "    FROM\n",
        "      VECTOR_SEARCH(\n",
        "        TABLE `housing_dataset.home_embeddings`,\n",
        "        'mm_embedding',\n",
        "        (\n",
        "        -- GENERATE AN EMBEDDING AS A SUBQUERY\n",
        "        SELECT\n",
        "          ml_generate_embedding_result,\n",
        "          content AS query\n",
        "        FROM\n",
        "          ML.GENERATE_EMBEDDING(\n",
        "            MODEL housing_dataset.multimodal_embedding_model,\n",
        "            ( SELECT \"house near the ocean\" AS content)\n",
        "          )\n",
        "        ),\n",
        "        top_k => 3)\n",
        "ORDER BY distance ASC;"
      ],
      "metadata": {
        "id": "PGFdnrHyUG-9"
      },
      "id": "PGFdnrHyUG-9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's visualize the top results returned from the `VECTOR_SEARCH`."
      ],
      "metadata": {
        "id": "NG3VLVXkdCOx"
      },
      "id": "NG3VLVXkdCOx"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "display_images(text_to_image_df)\n"
      ],
      "metadata": {
        "id": "7xrFhVGYWR0H"
      },
      "id": "7xrFhVGYWR0H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform image-to-image search\n",
        "\n",
        "The process for image-to-image search is nearly identical. Instead of using a text string, the subquery generates an embedding for a sample image URI, and `VECTOR_SEARCH` finds the most visually similar images."
      ],
      "metadata": {
        "id": "S2XgHbMlnaNS"
      },
      "id": "S2XgHbMlnaNS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a sample house image from GCS\n",
        "sample_house = 'gs://dataproc-metastore-public-binaries/home_image_search/test_image/house_test_image.jpg'\n",
        "image_df = pd.DataFrame({'uri': [sample_house]})\n",
        "display_images(image_df)"
      ],
      "metadata": {
        "id": "WqMDudECj5b7"
      },
      "id": "WqMDudECj5b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery image_to_image_df --project {PROJECT_ID}\n",
        "\n",
        "SELECT base.image_ref.uri\n",
        "    FROM\n",
        "      VECTOR_SEARCH(\n",
        "        TABLE `housing_dataset.home_embeddings`,\n",
        "        'mm_embedding',\n",
        "        (\n",
        "        -- GENERATE AN EMBEDDING AS A SUBQUERY\n",
        "        SELECT\n",
        "          ml_generate_embedding_result,\n",
        "          content AS query\n",
        "        FROM\n",
        "          ML.GENERATE_EMBEDDING(\n",
        "            MODEL housing_dataset.multimodal_embedding_model,\n",
        "            ( SELECT OBJ.FETCH_METADATA(OBJ.MAKE_REF('gs://dataproc-metastore-public-binaries/home_image_search/test_image/house_test_image.jpg', 'us.ai_connection')) AS content)\n",
        "          )\n",
        "        ),\n",
        "        top_k => 3)\n",
        "ORDER BY distance ASC;"
      ],
      "metadata": {
        "id": "4jMgLYBmWVsr"
      },
      "id": "4jMgLYBmWVsr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vizualize the results from the image-to-image vector search."
      ],
      "metadata": {
        "id": "4heV5z3SdIE-"
      },
      "id": "4heV5z3SdIE-"
    },
    {
      "cell_type": "code",
      "source": [
        "display_images(image_to_image_df)"
      ],
      "metadata": {
        "id": "YRG4GBtiX-5n"
      },
      "id": "YRG4GBtiX-5n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 9. Cleaning Up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created:"
      ],
      "metadata": {
        "id": "rm4jpiP7HEhP"
      },
      "id": "rm4jpiP7HEhP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the BigQuery tables\n",
        "! bq rm --table -f housing_dataset.listings\n",
        "! bq rm --table -f housing_dataset.listings_multimodal\n",
        "! bq rm --table -f housing_dataset.home_embeddings\n",
        "\n",
        "# Delete the remote model\n",
        "! bq rm --model -f housing_dataset.gemini\n",
        "! bq rm --model -f housing_dataset.kmeans_clustering_model\n",
        "! bq rm --model -f housing_dataset.multimodal_embedding_model\n",
        "\n",
        "# Delete the remote connection\n",
        "! bq rm --connection --project_id=$PROJECT_ID --location=us ai_connection\n",
        "\n",
        "# Delete the BigQuery dataset\n",
        "! bq rm -r -f $PROJECT_ID:housing_dataset"
      ],
      "metadata": {
        "id": "JSf6m7Z7j213"
      },
      "id": "JSf6m7Z7j213",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "Oct 14 Event Notebook Scratch",
      "collapsed_sections": [
        "B8vBqblSM_9w"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}