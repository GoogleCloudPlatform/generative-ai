{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Advanced Diarized Transcription and domain specific summarizaton\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/diarized-transcription-summarization/diarized_transcription_with_summarization.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fuse-cases%2Fdiarized-transcription-summarization%2Fdiarized_transcription_with_summarization\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/diarized-transcription-summarization/diarized_transcription_with_summarization.ipynb\">\n",
    "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/diarized-transcription-summarization/diarized_transcription_with_summarization.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84f0f73a0f76"
   },
   "source": [
    "| | |\n",
    "|-|-|\n",
    "| Author(s) | [Anant Nawalgaria](https://github.com/anantnawal/), [Patrick Nestler](https://github.com/nestler/)| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Many businesses, particularly in the financial sector( but also other industries), struggle with accurately transcribing and summarizing multilingual audio recordings. This challenge is especially critical for use cases that directly impact customer experience and financial outcomes.\n",
    "\n",
    "Some key obstacles include:\n",
    "\n",
    "- **Hallucinations**: AI models sometimes generate incorrect or nonsensical information.\n",
    "- **Numerical Inaccuracies**: Precise transcription of numbers is crucial in finance, and errors can have serious consequences.\n",
    "- **Speaker Misidentification for multilingual conversations**: Accurately attributing dialogue in multi-speaker settings, especially with more than two participants in multilingual settings, can be complex.\n",
    "- **Summarization Deficiencies**: Generating concise summaries tailored to the specific financial domain is essential for efficient analysis.\n",
    "This notebook demonstrates sample code for a semi-agentic, multimodal [solution developed for Commerzbank](https://cloud.google.com/blog/products/ai-machine-learning/how-commerzbank-is-transforming-financial-advisory-workflows-with-gen-ai).  A more advanced version of this solution is currently deployed in production, delivering substantial productivity gains.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "In this tutorial, you will learn how to do build an advanced diarized transcription and domain/task specific summarization using the multimodal capabilities of  Vertex AI Gemini API  together with the Gen AI Evaluation Service API in Vertex AI service for Python.\n",
    "You will complete the following tasks:\n",
    "\n",
    "- Install the Vertex AI SDK for Python\n",
    "- Chunk an audio file into segments of pre specified durations\n",
    "- Use the Vertex AI Gemini API to interact with the audio files\n",
    "  - Gemini 1.5 Pro (`gemini-1.5-pro`) model:\n",
    "    - to use few-shot multimodal prompting combined with specific task specific instructions to perform sequential diarized transcription of  all the contiguous audio chunks, using the output generated at each step as input for the next one\n",
    "    - extract task/domain specific facts and figures \n",
    "    - generate multple task specific summaries from the extracted facts and diarized transcript\n",
    "    - select the best summary for each task, using pointwise and pairwise evaluations using the Gen AI Evaluation Service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Install Vertex AI SDK and other required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tFy3H3aPgx12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --user --quiet google-cloud-aiplatform[evaluation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
    "\n",
    "The restart might take a minute or longer. After it's restarted, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XRvKdaPDTznN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NyKGtVQjgx13"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Nqwi-5ufWp_B"
   },
   "outputs": [],
   "source": [
    "# Use the environment variable if the user doesn't provide Project ID.\n",
    "import os\n",
    "\n",
    "import vertexai\n",
    "\n",
    "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
    "PROJECT_ID = \"oxydincdevproj1\"\n",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5303c05f7aa6"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6fc324893334"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from functools import partial\n",
    "import uuid\n",
    "\n",
    "from google import auth\n",
    "from google.cloud import aiplatform, storage\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "from vertexai.evaluation import EvalTask, MetricPromptTemplateExamples\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Part\n",
    "\n",
    "nest_asyncio.apply()  # @param {type:\"string\", isTemplate: true}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e43229f3ad4f"
   },
   "source": [
    "## Load Helper Functions\n",
    "In this blog we are going to define the various functions involved in developing an advanced diarized transcription and domain/task specific summarization system like shown in this blog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d4a983bd7f3"
   },
   "source": [
    "### Step 1. Audio chunking.\n",
    "In this step we chunk the audio into smaller chunks of predefined durations, in order to allow transcriptions of large audio files ( laasting several hours) which go beyond the size of the output window of the Gemini 1.5.  (which was 8192 atht the time of publication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3091633fde85"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client()\n",
    "\n",
    "\n",
    "def chunk_audio(\n",
    "    audio_url: str,\n",
    "    output_bucket: str,\n",
    "    output_format: str = \"wav\",\n",
    "    chunk_length: int = 600000,\n",
    "):\n",
    "    \"\"\"Splits a audio file in GCS into chunks and stores them back in GCS.\n",
    "\n",
    "    Args:\n",
    "        audio_url (str): the GCS url of the audio file to be chunked.\n",
    "        output_bucket (str):the GCS bucket the chunked audio files would be stored.\n",
    "        chunk_length_ms (int): Desired chunk length in milliseconds (default: 10\n",
    "          minutes).\n",
    "        output_format (str): Output audio format (default: wav).\n",
    "    \"\"\"\n",
    "    bucket_name = audio_url.split(\"/\")[2]\n",
    "\n",
    "    input_blob_name = \"/\".join(audio_url.split(\"/\")[3:])\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(input_blob_name)\n",
    "\n",
    "    # Download the FLAC file to a temporary local file\n",
    "    with open(\"temp_audio.\" + output_format, \"wb\") as temp_file:\n",
    "        storage_client.download_blob_to_file(blob, temp_file)\n",
    "\n",
    "    url_audio_chunks = list()\n",
    "    # Split the audio using pydub\n",
    "    audio = AudioSegment.from_file(\"temp_audio.\" + output_format, format=output_format)\n",
    "    chunks = make_chunks(audio, chunk_length)\n",
    "\n",
    "    bucket = storage_client.bucket(output_bucket)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_name_local = (\n",
    "            f\"{input_blob_name.split('/')[-1].split('.')[0]}_part{i+1}.{output_format}\"\n",
    "        )\n",
    "        chunk.export(chunk_name_local, format=output_format)\n",
    "\n",
    "        chunk_name_gcs = f\"{input_blob_name.split('.')[0]}_part{i+1}.{output_format}\"\n",
    "\n",
    "        # Upload the split chunk back to GCS\n",
    "        blob = bucket.blob(chunk_name_gcs)\n",
    "        blob.upload_from_filename(chunk_name_local)\n",
    "        url_audio_chunks.append(f\"gs://{output_bucket}/{chunk_name_gcs}\")\n",
    "\n",
    "    return url_audio_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d369ed0db89e"
   },
   "source": [
    "### Step 2. Advanced diarized transcription\n",
    "This step is crucial for generating a high-quality, structured transcript that captures the nuances of the conversation. Gemini 1.5 Pro is employed to create a diarized transcript, meaning each speaker is identified and their contributions are accurately attributed. This process occurs sequentially, with each audio chunk processed in order. To maximize accuracy, the model receives the transcript generated up to that point, along with carefully engineered prompts and a few-shot example of audio-to-text transcription. This ensures the final transcript is not only accurate in terms of content but also includes correct speaker identification and especially numerical information, which is crucial in a many contexts. Once the final transcript is generated, the individual audio chunks from the previous step should be deleted to optimize storage. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "a8ffaf698c51"
   },
   "outputs": [],
   "source": [
    "def diarize_transcribe(\n",
    "    url_audio_chunks: list[str],\n",
    "    consider_previous: bool = True,\n",
    "    quick: bool = False,\n",
    "    file_format: str = \"audio/wav\",\n",
    "    path_example_transcription: str = \"gs://\",\n",
    "    path_example_audio: str = \"gs://\",\n",
    "):\n",
    "    \"\"\"Take the GCS urls of contiguous chunked audio giles and the example transcription of audio files and\n",
    "    do advanced diarized transcription\n",
    "    \"\"\"\n",
    "\n",
    "    bucket = storage_client.bucket(path_example_transcription.split(\"/\")[2])\n",
    "    blob = bucket.blob(\"/\".join(path_example_transcription.split(\"/\")[3:]))\n",
    "    ex_output_transcription = blob.download_as_string().decode(\"utf-8\")\n",
    "\n",
    "    generation_model_audio = GenerativeModel(\n",
    "        \"gemini-1.5-pro-002\".replace(\"pro\", \"flash\" if quick else \"pro\")\n",
    "    )\n",
    "    generation_config_audio = GenerationConfig(\n",
    "        temperature=0.0,\n",
    "        max_output_tokens=8192,\n",
    "        candidate_count=1,\n",
    "    )\n",
    "    prompts_transcription_initial_p1 = \"\"\"\n",
    "      Transcribe the referenced audio file. The file contains a recording of an advisory call between one or more bank advisor(s) and their customer.\n",
    "      Differentiate and diarize the speakers in the call clearly. Do not add time marks.\n",
    "      Ensure correctness and consistency in speaker names while attributing statements during diarization.\n",
    "      Ensure that spoken numbers and numerical figures are transcribed correctly and precisely.\n",
    "      Some calls can also contain segments of conversations just between between banking advisors, sure the diarization correctly reflects that.\n",
    "      In case the call contains conversation segments between banking advisors might contain reference to internal systems, make sure this is properly transcribed.\n",
    "      Here is an example of an input audio file and its corresponding transcription.\n",
    "      Example Input Audio File:\n",
    "      \"\"\"\n",
    "    prompts_transcription_initial_p2 = \"\"\"\n",
    "      transcription of the example audio file:\n",
    "      {ex_output_transcription}\n",
    "      Here is the referenced audio file to transcribe keeping the instructions above in mind:\n",
    "      \"\"\"\n",
    "    prompts_transcription_subsequent_p1 = \"\"\"\n",
    "      The given file is a contiguos audio chunk, containing continuation of a recording of an advisory call between one or more bank advisor(s) and their customer.\n",
    "      Differentiate and diarize the speakers in the call clearly. \n",
    "      Transcribe the referenced audio file, contiuing on from the given transcription of the previous part , while also keeping speaker names consistent. Do not add time marks.\n",
    "      Ensure correctness and consistency in speaker names while attributing statements during diarization.\n",
    "      Ensure that spoken numbers and numerical figures are transcribed correctly and precisely.\n",
    "      Some calls can also contain segments of conversations just between between banking advisors, sure the diarization correctly reflects that.\n",
    "      In case the call contains conversation segments between banking advisors might contain reference to internal systems, make sure this is properly transcribed.\n",
    "      Here is an example of an input audio file and its corresponding transcription.\n",
    "      Example Input Audio File:\n",
    "      \"\"\"\n",
    "    prompts_transcription_subsequent_p2 = \"\"\"\n",
    "      transcription of the example audio file:\n",
    "      {ex_output_transcription}    \n",
    "      Transcription so far of previous audio chunks:\n",
    "      {transcription}\n",
    "      Here is the referenced audio file to transcribe keeping the instructions above in mind:\n",
    "      \"\"\"\n",
    "    generated_transcription = \"\"\n",
    "    for i in range(len(url_audio_chunks)):\n",
    "        print(i)\n",
    "        if i == 0:\n",
    "            prompt = prompts_transcription_initial_p1\n",
    "            prompt_2 = prompts_transcription_initial_p2.format(\n",
    "                ex_output_transcription=ex_output_transcription\n",
    "            )\n",
    "        else:\n",
    "\n",
    "            prompt = (\n",
    "                prompts_transcription_subsequent_p1\n",
    "                if consider_previous\n",
    "                else prompts_transcription_initial_p1\n",
    "            )\n",
    "            prompt_2 = (\n",
    "                prompts_transcription_subsequent_p2.format(\n",
    "                    ex_output_transcription=ex_output_transcription,\n",
    "                    transcription=generated_transcription,\n",
    "                )\n",
    "                if consider_previous\n",
    "                else prompts_transcription_initial_p2.format(\n",
    "                    ex_output_transcription=ex_output_transcription\n",
    "                )\n",
    "            )\n",
    "        audio_url = url_audio_chunks[i]\n",
    "        audio_file = Part.from_uri(audio_url, mime_type=file_format)\n",
    "        ex_audio_file = Part.from_uri(path_example_audio, mime_type=file_format)\n",
    "        contents = [prompt, ex_audio_file, prompt_2, audio_file]\n",
    "        response = generation_model_audio.generate_content(\n",
    "            contents=contents, generation_config=generation_config_audio\n",
    "        )\n",
    "        generated_transcription += response.text\n",
    "\n",
    "    return generated_transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b4e256e8259"
   },
   "source": [
    "### Step 3 and 4: Fact extraction & Summary generation\n",
    "Step 3 involves identifying key information related to the specific task/dsocument ( in this example financial advisory document) that needs to be completed. The model is prompted to recognize and extract crucial details such as client names, investment preferences, risk tolerance, and financial goals.\n",
    "\n",
    "Step 4 then focuses on generating concise and accurate summaries for each field within the document. Leveraging the extracted facts from the previous step and employing Zero-shot Chain-of-Thought (CoT) prompting, Gemini creates multiple  summaries tailored to the specific domain and the requirements of each form field. This ensures the generated summaries are not only informative but also comply any internal guidelines requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "82811a63412e"
   },
   "outputs": [],
   "source": [
    "def extract_facts(generated_transcription: str, quick: bool = True):\n",
    "    \"\"\"\n",
    "    Take the generated transcript and extract key domain/taks specific facts for downstream processing\n",
    "    \"\"\"\n",
    "    generation_model_facts = GenerativeModel(\n",
    "        \"gemini-1.5-pro-002\".replace(\"pro\", \"flash\" if quick else \"pro\")\n",
    "    )\n",
    "    generation_config_facts = GenerationConfig(\n",
    "        temperature=0.0,\n",
    "        max_output_tokens=512,\n",
    "    )\n",
    "\n",
    "    prompt = \"\"\"You are an experienced bank advisor who provides consultations to clients regarding financial products. You conducted a telephone consultation with a client, during which you discussed the client's need for one or more financial products. This consultation was recorded. A consultation can span multiple individual conversations. The transcription or transcriptions of the recording can be found below.\n",
    "    Your task is to extract information from the content of the consultation that you conducted with your client. Combine the content of multiple transcripts. Use the field definition provided below for the extraction of fields. The field definition consists of the field name and a field description for each field.\n",
    "\n",
    "    Reason for Consultation: Describes the reason for the consultation, i.e., the reason why the consultation was conducted.\n",
    "\n",
    "    Details of the Consultation Reason: Details of the client's needs. The following content should be mentioned in particular, if they were discussed in the conversation: financial needs, the scope of a basic transaction, interest rates, and desired conditions.\n",
    "\n",
    "    Current Market Expectation and Market Forecast of the Client (if available): Information on the market expectation and expected changes in the market that the client has in relation to the reason for the consultation.\n",
    "\n",
    "    Investment/Financing Horizon of the Client: Period for which the financial need exists or an investment is to be made.\n",
    "\n",
    "    Priorities and Goals of the Client: Expected benefits for the client and priorities of the client. Also includes any exclusion criteria for certain products mentioned by the client.\n",
    "\n",
    "    Existing Knowledge and Experience of the Client: Existing knowledge and experience of the client in relation to the reason for the consultation.\n",
    "\n",
    "    Risk Profile of the Client: What risks the client is willing to take.\n",
    "\n",
    "    Existing Products: Financial products that the client already uses at Commerzbank or other financial institutions in connection with the reason for the consultation.\n",
    "\n",
    "    Products Discussed: Products that were discussed as candidates for a recommendation to meet the client's needs.\n",
    "\n",
    "    Recommended Product: Financial product or products recommended to the client. Explicit mention of the product name/product designation.\n",
    "\n",
    "    Reason for the Recommended Product: Recommendation of the advisor regarding the use of the product. Suitability of the product for the investment objectives, the investment horizon, and the risk profile of the client.\n",
    "\n",
    "    Functionality of the Proposed Product: Describes the functionality of the proposed product.\n",
    "\n",
    "    Product Advantages: The advantages of the presented product. If several products were discussed, comparison of the advantages of the recommended product to these products.\n",
    "\n",
    "    Risk Disclosure: The risks and disadvantages of the presented product. If several products were discussed, comparison of the risks and disadvantages of the recommended product to these products.\n",
    "\n",
    "    Product-Specific Features: Important additional information on the product and its functionality that was explained to the client. In particular, this includes mandatory disclosures such as bail-in, fee-based advice, default risk, or a negative market value.\n",
    "\n",
    "    Higher Costs of Structured Products Compared to Plain Vanilla Products: Mentioning and naming the higher costs of structured products compared to plain vanilla products.\n",
    "\n",
    "    Initially Negative Market Value for OTC Products: Initially negative market value for structured OTC products, with the exception of purchased options.\n",
    "\n",
    "    Client's Feedback on the Recommendation: Client's feedback on the recommended product and further steps.\n",
    "\n",
    "    Objection Handling: Client's objections and the advisor's response to these objections.\n",
    "\n",
    "    Client Questions: Questions clearly attributable to the client regarding the recommendation made and the answer to these questions.\n",
    "\n",
    "    Agreement to Receive the Documents after the Trade: Client's consent to receive the documents used in connection with the consultation only after the trade or the conclusion of the transaction.\n",
    "\n",
    "    Client's Prior Knowledge of the Recommended Product: Describes the client's prior knowledge in the specific context of the recommended product.\n",
    "\n",
    "    Always consider the following guidelines for extracting information:\n",
    "    Do not add any statements or comments to the content of the recording.\n",
    "    Verify facts contained in the document, especially product names, numerical values, dates, and sums, within the context of the entire transcript.\n",
    "    Ensure that details from the conversation such as product names, sums, and interest rates are included in the extracted information.\n",
    "    Retain English terms, particularly the names of financial products.\n",
    "    Justify your answers with facts from the provided input and refer specifically only to sources from the audio call.\n",
    "    Ensure that statements are correctly attributed to either the bank or the client. Do not include source references or timestamps.\n",
    "    Use the term 'The Client' instead of the client's name.\n",
    "    Provide the information grammatically correct and in German.\n",
    "    Think step-by-step and check whether the results meet the above tasks.\n",
    "    Here is the transcript of the telephone call or the transcripts of the telephone calls. Iterate over the transcript multiple times to increase confidence in extracting all information correctly:\n",
    "    {transcription}\n",
    "    \"\"\".format(\n",
    "        transcription=generated_transcription\n",
    "    )\n",
    "    generated_facts = generation_model_facts.generate_content(\n",
    "        contents=prompt,\n",
    "        generation_config=generation_config_facts,\n",
    "    ).text\n",
    "    return generated_facts\n",
    "\n",
    "\n",
    "def generate_summaries(context: str, quick: bool = False, num_summaries: int = 3):\n",
    "    \"\"\"\n",
    "    Take the generated transcript extarcted facts and generate one or more task and domain specific summaries.\n",
    "    \"\"\"\n",
    "    prompt_instr = \"\"\"\n",
    "    You are an experienced bank advisor providing consultations to clients on banking products. Create a 5-sentence summary. Ensure that details from the conversation, like sums and interest rates, are included in the summary.\n",
    "    Your inputs are the transcription of the conversation and some important information extracted from this transcription, provided below. The relevant fields for you to consider are the following:\n",
    "    - Reason for consultation:\n",
    "    - Details of the reason for consultation:\n",
    "    - Existing products:\n",
    "    Do not mention the client's name, refrain from using a salutation.\n",
    "    Formulate the summary as continuous text and use varied sentence beginnings. Formulate the answer as a direct customer address. Start the summary with the phrase 'The reason for our conversation was'. Address the customer in the following sentences with 'you'.\n",
    "    Provide the information grammatically correctly and in German.\n",
    "    Avoid translating product names into German. Make sure that all product names are pronounced as they were mentioned in the conversation.\n",
    "    Avoid abbreviations. Spell out the entire word.\n",
    "    Base your answer on facts from the provided inputs and refer only to sources from the available fields.\n",
    "    Ensure that statements from the client and the advisor are clearly distinguished.\n",
    "    Think step-by-step and check if the results meet the above tasks.\n",
    "    \"\"\"\n",
    "    generation_model_summary = GenerativeModel(\n",
    "        \"gemini-1.5-pro-002\".replace(\"pro\", \"flash\" if quick else \"pro\")\n",
    "    )\n",
    "    generation_config_summary = GenerationConfig(\n",
    "        temperature=0.0, max_output_tokens=512, candidate_count=num_summaries\n",
    "    )\n",
    "    prompt = \"\"\"{instructions}\n",
    "    {context}\n",
    "    \"\"\".format(\n",
    "        instructions=prompt_instr, context=context\n",
    "    )\n",
    "\n",
    "    generated_summaries = [\n",
    "        candidate.text\n",
    "        for candidate in generation_model_summary.generate_content(\n",
    "            contents=prompt,\n",
    "            generation_config=generation_config_summary,\n",
    "        ).candidates\n",
    "    ]\n",
    "    return prompt_instr, generated_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "693996feb2ef"
   },
   "source": [
    "### Step 5: Fact extraction & Summary generation\n",
    "To ensure the highest quality output, the multiple summaries generated for each form field are [evaluated and the best summary for each field is selected](https://cloud.google.com/blog/products/ai-machine-learning/enhancing-llm-quality-and-interpretability-with-the-vertex-gen-ai-evaluation-service?e=48754805) using the Vertex AI Gen AI Evaluation Service. Importantly, the service also provides a human-readable explanation for its selection, enabling sales advisors to understand the reasoning behind the AI's choices and maintain trust in the automated process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cf93d5f0ce00"
   },
   "outputs": [],
   "source": [
    "experiment_name = \"summarization-quality\"\n",
    "\n",
    "\n",
    "def pointwise_eval(\n",
    "    instruction: str,\n",
    "    context: str,\n",
    "    responses: list[str],\n",
    "    experiment_name: str = experiment_name,\n",
    "    eval_metrics: list[object] = [\n",
    "        MetricPromptTemplateExamples.Pointwise.SUMMARIZATION_QUALITY,\n",
    "        MetricPromptTemplateExamples.Pointwise.GROUNDEDNESS,\n",
    "    ],\n",
    ") -> object:\n",
    "    \"\"\"\n",
    "    Takes the instruction, context and a variable number of corresponding generated responses, and returns the pointwise evaluation metrics\n",
    "    for each of the provided metrics. For this example the metrics are Q & A related, however the full list can be found on the website:\n",
    "    https://cloud.google.com/vertex-ai/generative-ai/docs/models/online-pipeline-services\n",
    "    \"\"\"\n",
    "\n",
    "    instructions = [instruction] * len(responses)\n",
    "\n",
    "    contexts = [context] * len(responses)\n",
    "\n",
    "    eval_dataset = pd.DataFrame(\n",
    "        {\n",
    "            \"instruction\": instructions,\n",
    "            \"context\": contexts,\n",
    "            \"response\": responses,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    eval_task = EvalTask(\n",
    "        dataset=eval_dataset,\n",
    "        metrics=[\n",
    "            MetricPromptTemplateExamples.Pointwise.SUMMARIZATION_QUALITY,\n",
    "            MetricPromptTemplateExamples.Pointwise.GROUNDEDNESS,\n",
    "        ],\n",
    "        experiment=experiment_name,\n",
    "    )\n",
    "    results = eval_task.evaluate(\n",
    "        prompt_template=\"{instruction} \\n {context}\",\n",
    "        experiment_run_name=\"gemini-summ-pointwise-\" + str(uuid.uuid4()),\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def pairwise_greater(\n",
    "    instructions: list,\n",
    "    context: str,\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    experiment_name: str,\n",
    "    baseline: str,\n",
    "    candidate: str,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Takes Instructions, Context and two different responses.\n",
    "    Returns the response which best matches the instructions/Context for the given\n",
    "    quality metric ( in this case question answering).\n",
    "    More details on the web API and different quality metrics which this function\n",
    "    can be extended to can be found on\n",
    "    https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/evaluation\n",
    "    \"\"\"\n",
    "    eval_dataset = pd.DataFrame(\n",
    "        {\n",
    "            \"instruction\": [instructions],\n",
    "            \"context\": [context],\n",
    "            \"response\": [candidate],\n",
    "            \"baseline_model_response\": [baseline],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    eval_task = EvalTask(\n",
    "        dataset=eval_dataset,\n",
    "        metrics=[\n",
    "            MetricPromptTemplateExamples.Pairwise.SUMMARIZATION_QUALITY,\n",
    "        ],\n",
    "        experiment=experiment_name,\n",
    "    )\n",
    "    results = eval_task.evaluate(\n",
    "        prompt_template=\"{instruction} \\n {context}\",\n",
    "        experiment_run_name=\"gemini-summ-pairwise-\" + str(uuid.uuid4()),\n",
    "    )\n",
    "    print(results.metrics_table.columns)\n",
    "    result = results.metrics_table[\n",
    "        [\n",
    "            \"pairwise_summarization_quality/pairwise_choice\",\n",
    "            \"pairwise_summarization_quality/explanation\",\n",
    "        ]\n",
    "    ].to_dict(\"records\")[0]\n",
    "    choice = (\n",
    "        baseline\n",
    "        if result[\"pairwise_summarization_quality/pairwise_choice\"] == \"BASELINE\"\n",
    "        else candidate\n",
    "    )\n",
    "    return (choice, result[\"pairwise_summarization_quality/explanation\"])\n",
    "\n",
    "\n",
    "def greater(cmp: callable, a: str, b: str) -> int:\n",
    "    \"\"\"\n",
    "    A comparison function which takes the comparison function, and two variables as input\n",
    "    and returns the one which is greater according to the logic defined inside the cmp function.\n",
    "    \"\"\"\n",
    "    choice, explanation = cmp(a, b)\n",
    "\n",
    "    if choice == a:\n",
    "        return 1\n",
    "    return -1\n",
    "\n",
    "\n",
    "def select_best_response(instruction, context, responses):\n",
    "    \"\"\"Takes the instruction, context and a variable number of responses as input, and returns the best performing response as well as its associated\n",
    "\n",
    "    human readable pointwise quality metrics for the configured criteria in the\n",
    "    above functions.\n",
    "    The process consists of two steps:\n",
    "    1. Selecting the best response by using Pairwise comparisons between the\n",
    "    responses for the user specified metric ( e.g. Q & A)\n",
    "    2. Doing pointwise evaluation of the best response and returning human\n",
    "    readable quality metrics and explanation along with the best response.\n",
    "    \"\"\"\n",
    "    cmp_f = partial(\n",
    "        pairwise_greater, instruction, context, PROJECT_ID, LOCATION, experiment_name\n",
    "    )\n",
    "    cmp_greater = partial(greater, cmp_f)\n",
    "\n",
    "    pairwise_best_response = max(responses, key=functools.cmp_to_key(cmp_greater))\n",
    "    pointwise_metric = pointwise_eval(\n",
    "        instruction, context, [pairwise_best_response], experiment_name\n",
    "    )\n",
    "    qa_metrics = pointwise_metric.metrics_table[\n",
    "        [\n",
    "            col\n",
    "            for col in pointwise_metric.metrics_table.columns\n",
    "            if (\"summarization\" in col) or (\"groundedness\" in col)\n",
    "        ]\n",
    "    ].to_dict(\"records\")[0]\n",
    "    return pairwise_best_response, qa_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fee5aabe694"
   },
   "source": [
    "We put all the steps together in one final step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a4e033321ad"
   },
   "source": [
    "## End-to-end execution for diarized transcription and summarization\n",
    "\n",
    "In this step you will run all the steps mentioned in sequence on an toy audio file.First we do step 1 and 2: to chunk the audio file into smaller contiguos chunks, and then sequentially iterate over them to do advanced multimodal task/domain-specific diarized transcription. Then step 3 to extract facts is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2cdca4a8b090"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://oxydincdevproj1-bucket1/use-cases/diarization-transcription-summarization/rec1_part1.wav']\n",
      "Finished audio chunking\n",
      "0\n",
      "Finished transcription\n",
      "Finished fact generation\n"
     ]
    }
   ],
   "source": [
    "use_facts_for_summaries: bool = True\n",
    "# enter the bucket to store temporary chunked audio files\n",
    "output_bucket: str = \"oxydincdevproj1-bucket1\"\n",
    "audio_url = (\n",
    "    \"gs://github-repo/use-cases/diarization-transcription-summarization/rec1.wav\"\n",
    ")\n",
    "url_audio_chunks = chunk_audio(audio_url, output_bucket)\n",
    "print(url_audio_chunks)\n",
    "print(\"Finished audio chunking\")\n",
    "generated_transcription = diarize_transcribe(\n",
    "    url_audio_chunks,\n",
    "    path_example_transcription=\"gs://github-repo/use-cases/diarization-transcription-summarization/transcript_example.txt\",\n",
    "    path_example_audio=\"gs://github-repo/use-cases/diarization-transcription-summarization/rec2.wav\",\n",
    ")\n",
    "print(\"Finished transcription\")\n",
    "generated_facts = extract_facts(generated_transcription)\n",
    "print(\"Finished fact generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "a593abeaf90b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank Advisor: Good morning, Mr. Chen. Thanks for taking the time. I understand you are interested in exploring investment options for Tech Nova Solutions surplus capital.\n",
      "Client: Good morning, Marcus. Yes, we have accumulated a significant reserve, around $2 million, and we're looking for strategic investments with moderate risk and reasonable return in the next three to five years. Our primary goal is capital appreciation to support future expansion.\n",
      "Bank Advisor: Excellent. Given Tech Nova's growth trajectory and your three to five year time frame, I'd recommend exploring our Venture Growth Fund. It's a diversified portfolio primarily invested in high growth tech companies similar to yours, offering a potential annual return of 8 to 12%, though past performance is not indicative of future results, of course. The fund actively manages its portfolio, adapting to market changes.\n",
      "Client: 8 to 12% sounds promising. What about the risk profile? We're not looking for anything overly speculative.\n",
      "Bank Advisor: The Venture Growth Fund has a moderate to high risk profile. There's potential for significant gains, but it's important to remember that market fluctuations can impact returns. We provide regular portfolio updates and risk assessments. We also have a comprehensive risk tolerance questionnaire to ensure the investment aligns with your company's risk appetite.\n",
      "Client: Yeah, I mean, we've completed similar questionnaires in the past. Could you briefly outline the fund's diversification strategy? We're particularly interested in avoiding overexposure to any single sector.\n",
      "Bank Advisor: Certainly. The fund is diversified across various technology sub-sectors: cloud computing, AI, cybersecurity, and SaaS, mitigating risk by spreading investments across multiple companies. Currently, no single sector represents more than 20% of the fund's holdings. We also employ a rigorous due diligence process for each investment to minimize risk.\n",
      "Client: That sounds reasonable. And what are the minimum investment requirements and, yeah, I guess, associated fees?\n",
      "Bank Advisor: The minimum investment is $1 million. Management fees are 1.5% annually, charged on the assets under management. There are also performance-based fees, but only if the fund surpasses a predefined benchmark, which is clearly outlined in the prospectus.\n",
      "Client: Okay, the $1 million minimum is manageable. The fees are within our expectations. But before making a decision, I'd like to review the prospectus and discuss this further with our investment committee. Can you send me the relevant documentation?\n",
      "Bank Advisor: Absolutely. I'll email you the prospectus, fact sheet, and a more detailed presentation on the Venture Growth Fund immediately. I'm also happy to schedule a follow-up call to address any questions your committee might have. Would sometime next week work for you?\n",
      "Client: Yes, next Wednesday afternoon would be ideal.\n",
      "Bank Advisor: Perfect. I'll send you the documents and confirm the meeting time via email. Thank you for your time, Mr. Chen. I look forward to discussing this further with you and your committee.\n",
      "Client: Thank you, Marcus. Appreciate your time and the information. Bye-bye.\n",
      "Bank Advisor: Bye-bye.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generated_transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "04f75bdb19c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Reason for Consultation:** Beratung bezüglich Anlagemöglichkeiten für überschüssiges Kapital von Tech Nova Solutions.\n",
      "\n",
      "**Details of the Consultation Reason:**  Tech Nova Solutions verfügt über ca. 2 Millionen US-Dollar an überschüssigem Kapital und sucht nach strategischen Anlagen mit moderatem Risiko und angemessener Rendite innerhalb der nächsten drei bis fünf Jahre.  Das Hauptziel ist die Wertsteigerung zur Unterstützung zukünftiger Expansionen.  Erwähnt wurden eine angestrebte jährliche Rendite von 8-12%,  sowie die Vermeidung von Übergewicht in einzelnen Sektoren.  Ein Mindestanlagebetrag und die damit verbundenen Gebühren waren ebenfalls von Interesse.\n",
      "\n",
      "**Current Market Expectation and Market Forecast of the Client (if available):** Nicht explizit erwähnt.\n",
      "\n",
      "**Investment/Financing Horizon of the Client:** Drei bis fünf Jahre.\n",
      "\n",
      "**Priorities and Goals of the Client:** Kapitalwertsteigerung zur Unterstützung zukünftiger Expansionen; moderate Risikobereitschaft; Diversifikation des Portfolios um Übergewicht in einzelnen Sektoren zu vermeiden;  aktive Portfoliomanagement.\n",
      "\n",
      "**Existing Knowledge and Experience of the Client:** Der Kunde hat bereits ähnliche Fragebögen zur Risikobereitschaft ausgefüllt.\n",
      "\n",
      "**Risk Profile of the Client:** Moderate Risikobereitschaft.\n",
      "\n",
      "**Existing Products:** Nicht erwähnt.\n",
      "\n",
      "**Products Discussed:** Venture Growth Fund.\n",
      "\n",
      "**Recommended Product:** Venture Growth Fund.\n",
      "\n",
      "**Reason for the Recommended Product:**  Der Venture Growth Fund ist ein diversifiziertes Portfolio, das hauptsächlich in wachstumsstarke Technologieunternehmen investiert ist und eine potenzielle jährliche Rendite von 8 bis 12 % bietet.  Er passt zum Anlagehorizont (3-5 Jahre) und zur Risikobereitschaft des Kunden (moderat bis hoch).  Der Fonds wird aktiv gemanagt und an Marktveränderungen angepasst.\n",
      "\n",
      "**Functionality of the Proposed Product:** Der Fonds investiert diversifiziert in verschiedene Technologie-Subsektoren (Cloud Computing, KI, Cybersicherheit und SaaS).  Kein einzelner Sektor macht mehr als 20% des Fonds aus.  Es wird ein strenger Due-Diligence-Prozess für jede Investition angewendet.\n",
      "\n",
      "**Product Advantages:**  Potenzielle jährliche Rendite von 8 bis 12%; Diversifikation über verschiedene Technologie-Subsektoren; aktives Portfoliomanagement; strenger Due-Dili\n"
     ]
    }
   ],
   "source": [
    "print(generated_facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d3d3797784e"
   },
   "source": [
    "Then step 4 and 5 to generate the optimized summaries based on the transcript and facts generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4d7d0ecd83a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-691ca2c4-5461-404e-86dd-4fa4f76d2701\" href=\"#view-view-vertex-resource-691ca2c4-5461-404e-86dd-4fa4f76d2701\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-691ca2c4-5461-404e-86dd-4fa4f76d2701');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/summarization-quality/runs?project=oxydincdevproj1');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/summarization-quality/runs?project=oxydincdevproj1', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-3d84fec6-f0fc-459d-9516-85c0f8dbca57 to Experiment: summarization-quality\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-de7849a2-c404-4389-b694-021a8d831f4d\" href=\"#view-view-vertex-resource-de7849a2-c404-4389-b694-021a8d831f4d\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment Run</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-de7849a2-c404-4389-b694-021a8d831f4d');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/summarization-quality/runs/summarization-quality-gemini-summ-pairwise-3d84fec6-f0fc-459d-9516-85c0f8dbca57?project=oxydincdevproj1');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/summarization-quality/runs/summarization-quality-gemini-summ-pairwise-3d84fec6-f0fc-459d-9516-85c0f8dbca57?project=oxydincdevproj1', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Eval Experiment metadata: {'prompt_template': '{instruction} \\n {context}'}\n",
      "Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
      "Computing metrics with a total of 1 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1 metric requests are successfully computed.\n",
      "Evaluation Took:7.0789320139999745 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['instruction', 'context', 'response', 'baseline_model_response',\n",
      "       'prompt', 'pairwise_summarization_quality/explanation',\n",
      "       'pairwise_summarization_quality/pairwise_choice'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-229951f2-3b06-4a8f-b716-fc6b58eb02c4\" href=\"#view-view-vertex-resource-229951f2-3b06-4a8f-b716-fc6b58eb02c4\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-229951f2-3b06-4a8f-b716-fc6b58eb02c4');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/summarization-quality/runs?project=oxydincdevproj1');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/summarization-quality/runs?project=oxydincdevproj1', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-955029f9-29f1-41b3-b313-8885a00b1dc4 to Experiment: summarization-quality\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-d9e1c82b-12b2-4ee1-91dd-3cbe2d15b997\" href=\"#view-view-vertex-resource-d9e1c82b-12b2-4ee1-91dd-3cbe2d15b997\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment Run</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-d9e1c82b-12b2-4ee1-91dd-3cbe2d15b997');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/summarization-quality/runs/summarization-quality-gemini-summ-pairwise-955029f9-29f1-41b3-b313-8885a00b1dc4?project=oxydincdevproj1');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/summarization-quality/runs/summarization-quality-gemini-summ-pairwise-955029f9-29f1-41b3-b313-8885a00b1dc4?project=oxydincdevproj1', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Eval Experiment metadata: {'prompt_template': '{instruction} \\n {context}'}\n",
      "Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
      "Computing metrics with a total of 1 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1 metric requests are successfully computed.\n",
      "Evaluation Took:4.286335974999929 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['instruction', 'context', 'response', 'baseline_model_response',\n",
      "       'prompt', 'pairwise_summarization_quality/explanation',\n",
      "       'pairwise_summarization_quality/pairwise_choice'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-5773f7bf-c3b2-4047-b310-4cc3be48f300\" href=\"#view-view-vertex-resource-5773f7bf-c3b2-4047-b310-4cc3be48f300\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-5773f7bf-c3b2-4047-b310-4cc3be48f300');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/summarization-quality/runs?project=oxydincdevproj1');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/summarization-quality/runs?project=oxydincdevproj1', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-cd83766d-dcab-4dd4-983f-2d9f8cfa7101 to Experiment: summarization-quality\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-8fe47e6d-4a40-46f4-974d-2940538a19c1\" href=\"#view-view-vertex-resource-8fe47e6d-4a40-46f4-974d-2940538a19c1\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment Run</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-8fe47e6d-4a40-46f4-974d-2940538a19c1');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/summarization-quality/runs/summarization-quality-gemini-summ-pointwise-cd83766d-dcab-4dd4-983f-2d9f8cfa7101?project=oxydincdevproj1');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/summarization-quality/runs/summarization-quality-gemini-summ-pointwise-cd83766d-dcab-4dd4-983f-2d9f8cfa7101?project=oxydincdevproj1', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Eval Experiment metadata: {'prompt_template': '{instruction} \\n {context}'}\n",
      "Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
      "Computing metrics with a total of 2 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:06<00:00,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 2 metric requests are successfully computed.\n",
      "Evaluation Took:6.497270185999923 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Der Grund für unser Gespräch war die Beratung bezüglich Anlagemöglichkeiten für das überschüssige Kapital Ihrer Firma Tech Nova Solutions. Sie verfügen über circa zwei Millionen US-Dollar und suchen nach strategischen Anlagen mit moderatem Risiko und angemessener Rendite in den nächsten drei bis fünf Jahren.  Ich habe Ihnen den Venture Growth Fund empfohlen, der in verschiedene Technologiesektoren investiert und eine potenzielle jährliche Rendite von acht bis zwölf Prozent bietet. Die Mindestanlagesumme beträgt eine Million US-Dollar, und die jährlichen Managementgebühren belaufen sich auf eins Komma fünf Prozent des verwalteten Vermögens.  Sie erhalten von mir den Prospekt, ein Factsheet und eine detailliertere Präsentation zum Venture Growth Fund, damit Sie alles mit Ihrem Investmentkomitee besprechen können.\\n', {'summarization_quality/explanation': \"The response adheres to the prompt's length constraint, accurately reflects the conversation, maintains the requested format, and begins with the specified phrase. It includes the sums and interest rate details. It largely fulfils the prompt by addressing the client with 'Sie' in the following sentences. The only omissions are the existing products, which were not in the context provided; and clear differentiation between client and advisor statements. However, it includes product specifics that were mentioned by the advisor. Because the prompt instructs to start by addressing the reason for the conversation and use 'you' from there, this summary qualifies at least for 'ok'. It lacks fluency as it jumps between what was discussed without connecting statements.\", 'summarization_quality/score': 3.0, 'groundedness/explanation': 'The AI model successfully generated a 5-sentence summary based on the provided information without hallucinating. It incorporated specific details such as the investment amount ($2 million), the investment timeframe (3-5 years), the recommended product (Venture Growth Fund), the potential return (8-12%), the minimum investment ($1 million), and the management fees (1.5%). The AI adhered to instructions such as addressing the customer as \"you,\" avoiding abbreviations, correctly formulating the German response, and beginning the summary with \"The reason for our conversation was.\"', 'groundedness/score': 1.0})\n"
     ]
    }
   ],
   "source": [
    "context_summary = (\n",
    "    \"\"\"Transcript:\n",
    "{transcription}\n",
    "Excerpt from the transcript containing facts:\n",
    "{facts}\n",
    "\"\"\".format(\n",
    "        transcription=generated_transcription, facts=generated_facts\n",
    "    )\n",
    "    if use_facts_for_summaries\n",
    "    else \"\"\"Transcript:\n",
    "    {transcription}\n",
    "    \"\"\".format(\n",
    "        transcription=generated_transcription\n",
    "    )\n",
    ")\n",
    "\n",
    "summary_prompt, generated_summaries = generate_summaries(context_summary, 3)\n",
    "best_summary = select_best_response(\n",
    "    summary_prompt, context_summary, generated_summaries\n",
    ")\n",
    "print(best_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fbfe877bcb9"
   },
   "source": [
    "## Cleanup\n",
    "In this step we delete the temporary files and experiments generated during this colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9ea449f5e979"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment run gemini-summ-pointwise-cd83766d-dcab-4dd4-983f-2d9f8cfa7101 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pointwise-cd83766d-dcab-4dd4-983f-2d9f8cfa7101-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-cd83766d-dcab-4dd4-983f-2d9f8cfa7101\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-cd83766d-dcab-4dd4-983f-2d9f8cfa7101\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-cd83766d-dcab-4dd4-983f-2d9f8cfa7101\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-cd83766d-dcab-4dd4-983f-2d9f8cfa7101/operations/8125075816104067072\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-cd83766d-dcab-4dd4-983f-2d9f8cfa7101 deleted.\n",
      "Experiment run gemini-summ-pairwise-955029f9-29f1-41b3-b313-8885a00b1dc4 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-955029f9-29f1-41b3-b313-8885a00b1dc4-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-955029f9-29f1-41b3-b313-8885a00b1dc4\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-955029f9-29f1-41b3-b313-8885a00b1dc4\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-955029f9-29f1-41b3-b313-8885a00b1dc4\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-955029f9-29f1-41b3-b313-8885a00b1dc4/operations/2885137649658494976\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-955029f9-29f1-41b3-b313-8885a00b1dc4 deleted.\n",
      "Experiment run gemini-summ-pairwise-3d84fec6-f0fc-459d-9516-85c0f8dbca57 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-3d84fec6-f0fc-459d-9516-85c0f8dbca57-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-3d84fec6-f0fc-459d-9516-85c0f8dbca57\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-3d84fec6-f0fc-459d-9516-85c0f8dbca57\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-3d84fec6-f0fc-459d-9516-85c0f8dbca57\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-3d84fec6-f0fc-459d-9516-85c0f8dbca57/operations/6799328675796877312\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-3d84fec6-f0fc-459d-9516-85c0f8dbca57 deleted.\n",
      "Experiment run gemini-summ-pointwise-6799055e-0421-41ed-a193-84158893fc3c skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pointwise-6799055e-0421-41ed-a193-84158893fc3c-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-6799055e-0421-41ed-a193-84158893fc3c\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-6799055e-0421-41ed-a193-84158893fc3c\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-6799055e-0421-41ed-a193-84158893fc3c\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-6799055e-0421-41ed-a193-84158893fc3c/operations/4295327282978881536\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-6799055e-0421-41ed-a193-84158893fc3c deleted.\n",
      "Experiment run gemini-summ-pairwise-0e67e3c9-b9d4-46db-ad11-91a2e638c0a0 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-0e67e3c9-b9d4-46db-ad11-91a2e638c0a0-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-0e67e3c9-b9d4-46db-ad11-91a2e638c0a0\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-0e67e3c9-b9d4-46db-ad11-91a2e638c0a0\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-0e67e3c9-b9d4-46db-ad11-91a2e638c0a0\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-0e67e3c9-b9d4-46db-ad11-91a2e638c0a0/operations/7010434908329869312\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-0e67e3c9-b9d4-46db-ad11-91a2e638c0a0 deleted.\n",
      "Experiment run gemini-summ-pairwise-936eb8bd-b779-413b-8601-49c6c58ba45e skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-936eb8bd-b779-413b-8601-49c6c58ba45e-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-936eb8bd-b779-413b-8601-49c6c58ba45e\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-936eb8bd-b779-413b-8601-49c6c58ba45e\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-936eb8bd-b779-413b-8601-49c6c58ba45e\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-936eb8bd-b779-413b-8601-49c6c58ba45e/operations/5840061955166961664\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-936eb8bd-b779-413b-8601-49c6c58ba45e deleted.\n",
      "Experiment run gemini-summ-pairwise-844c260c-eea1-44d6-8bdd-e34ca60aa9e8 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-844c260c-eea1-44d6-8bdd-e34ca60aa9e8-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-844c260c-eea1-44d6-8bdd-e34ca60aa9e8\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-844c260c-eea1-44d6-8bdd-e34ca60aa9e8\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-844c260c-eea1-44d6-8bdd-e34ca60aa9e8\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-844c260c-eea1-44d6-8bdd-e34ca60aa9e8/operations/4367384877016809472\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-844c260c-eea1-44d6-8bdd-e34ca60aa9e8 deleted.\n",
      "Experiment run gemini-summ-pairwise-74957eb6-ea12-4a62-9460-238c03d0531d skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-74957eb6-ea12-4a62-9460-238c03d0531d-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-74957eb6-ea12-4a62-9460-238c03d0531d\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-74957eb6-ea12-4a62-9460-238c03d0531d\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-74957eb6-ea12-4a62-9460-238c03d0531d\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-74957eb6-ea12-4a62-9460-238c03d0531d/operations/6598355542425468928\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-74957eb6-ea12-4a62-9460-238c03d0531d deleted.\n",
      "Experiment run gemini-summ-pairwise-471f8762-21fe-4323-9f76-83db6ed44885 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-471f8762-21fe-4323-9f76-83db6ed44885-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-471f8762-21fe-4323-9f76-83db6ed44885\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-471f8762-21fe-4323-9f76-83db6ed44885\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-471f8762-21fe-4323-9f76-83db6ed44885\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-471f8762-21fe-4323-9f76-83db6ed44885/operations/4493485666583183360\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-471f8762-21fe-4323-9f76-83db6ed44885 deleted.\n",
      "Experiment run gemini-summ-pairwise-956b7b82-1da2-423d-ab56-920889e0d1a3 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-956b7b82-1da2-423d-ab56-920889e0d1a3-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-956b7b82-1da2-423d-ab56-920889e0d1a3\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-956b7b82-1da2-423d-ab56-920889e0d1a3\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-956b7b82-1da2-423d-ab56-920889e0d1a3\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-956b7b82-1da2-423d-ab56-920889e0d1a3/operations/4002030357246377984\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-956b7b82-1da2-423d-ab56-920889e0d1a3 deleted.\n",
      "Experiment run gemini-summ-pairwise-d7679a6e-e614-4bfd-9b75-232f92c73b28 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-d7679a6e-e614-4bfd-9b75-232f92c73b28-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-d7679a6e-e614-4bfd-9b75-232f92c73b28\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-d7679a6e-e614-4bfd-9b75-232f92c73b28\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-d7679a6e-e614-4bfd-9b75-232f92c73b28\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-d7679a6e-e614-4bfd-9b75-232f92c73b28/operations/5822047556657479680\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-d7679a6e-e614-4bfd-9b75-232f92c73b28 deleted.\n",
      "Experiment run gemini-summ-pairwise-76eda34b-2392-4bd6-849c-2b009e14c912 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-76eda34b-2392-4bd6-849c-2b009e14c912-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-76eda34b-2392-4bd6-849c-2b009e14c912\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-76eda34b-2392-4bd6-849c-2b009e14c912\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-76eda34b-2392-4bd6-849c-2b009e14c912\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-76eda34b-2392-4bd6-849c-2b009e14c912/operations/631086036159561728\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-76eda34b-2392-4bd6-849c-2b009e14c912 deleted.\n",
      "Experiment run gemini-summ-pairwise-41f6bda2-ed19-4f85-9a42-659ab4ee1b12 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-41f6bda2-ed19-4f85-9a42-659ab4ee1b12-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-41f6bda2-ed19-4f85-9a42-659ab4ee1b12\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-41f6bda2-ed19-4f85-9a42-659ab4ee1b12\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-41f6bda2-ed19-4f85-9a42-659ab4ee1b12\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-41f6bda2-ed19-4f85-9a42-659ab4ee1b12/operations/3516204547443785728\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-41f6bda2-ed19-4f85-9a42-659ab4ee1b12 deleted.\n",
      "Experiment run gemini-summ-pairwise-d86f43c9-90c1-49fe-93d5-b65b0491ce95 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-d86f43c9-90c1-49fe-93d5-b65b0491ce95-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-d86f43c9-90c1-49fe-93d5-b65b0491ce95\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-d86f43c9-90c1-49fe-93d5-b65b0491ce95\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-d86f43c9-90c1-49fe-93d5-b65b0491ce95\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-d86f43c9-90c1-49fe-93d5-b65b0491ce95/operations/2786621407809765376\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-d86f43c9-90c1-49fe-93d5-b65b0491ce95 deleted.\n",
      "Experiment run gemini-summ-pointwise-c87d7d4d-a60b-48f3-b2aa-0e7ec2fa510f skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pointwise-c87d7d4d-a60b-48f3-b2aa-0e7ec2fa510f-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-c87d7d4d-a60b-48f3-b2aa-0e7ec2fa510f\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-c87d7d4d-a60b-48f3-b2aa-0e7ec2fa510f\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-c87d7d4d-a60b-48f3-b2aa-0e7ec2fa510f\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-c87d7d4d-a60b-48f3-b2aa-0e7ec2fa510f/operations/8393602943886032896\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-c87d7d4d-a60b-48f3-b2aa-0e7ec2fa510f deleted.\n",
      "Experiment run gemini-summ-pointwise-aa1ac243-50c5-4f0b-968a-b31abb30249b skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pointwise-aa1ac243-50c5-4f0b-968a-b31abb30249b-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-aa1ac243-50c5-4f0b-968a-b31abb30249b\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-aa1ac243-50c5-4f0b-968a-b31abb30249b\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-aa1ac243-50c5-4f0b-968a-b31abb30249b\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-aa1ac243-50c5-4f0b-968a-b31abb30249b/operations/899613163941527552\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pointwise-aa1ac243-50c5-4f0b-968a-b31abb30249b deleted.\n",
      "Experiment run gemini-summ-pairwise-0003b58e-a7e9-4b84-aae4-d50e311cc5d4 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-0003b58e-a7e9-4b84-aae4-d50e311cc5d4-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-0003b58e-a7e9-4b84-aae4-d50e311cc5d4\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-0003b58e-a7e9-4b84-aae4-d50e311cc5d4\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-0003b58e-a7e9-4b84-aae4-d50e311cc5d4\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-0003b58e-a7e9-4b84-aae4-d50e311cc5d4/operations/7339760631081336832\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-0003b58e-a7e9-4b84-aae4-d50e311cc5d4 deleted.\n",
      "Experiment run gemini-summ-pairwise-b70510d5-cfd8-4e67-a2d8-c75856a2a56b skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-b70510d5-cfd8-4e67-a2d8-c75856a2a56b-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-b70510d5-cfd8-4e67-a2d8-c75856a2a56b\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-b70510d5-cfd8-4e67-a2d8-c75856a2a56b\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-b70510d5-cfd8-4e67-a2d8-c75856a2a56b\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-b70510d5-cfd8-4e67-a2d8-c75856a2a56b/operations/2424081637806440448\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-b70510d5-cfd8-4e67-a2d8-c75856a2a56b deleted.\n",
      "Experiment run gemini-summ-pairwise-cc41da4e-5f33-4c11-8079-5254fa8b7c41 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-cc41da4e-5f33-4c11-8079-5254fa8b7c41-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-cc41da4e-5f33-4c11-8079-5254fa8b7c41\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-cc41da4e-5f33-4c11-8079-5254fa8b7c41\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-cc41da4e-5f33-4c11-8079-5254fa8b7c41\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-cc41da4e-5f33-4c11-8079-5254fa8b7c41/operations/8907013301406269440\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-cc41da4e-5f33-4c11-8079-5254fa8b7c41 deleted.\n",
      "Experiment run gemini-summ-pairwise-2a6fc509-c4fa-4d85-8887-b83f3a7aa7c5 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-2a6fc509-c4fa-4d85-8887-b83f3a7aa7c5-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-2a6fc509-c4fa-4d85-8887-b83f3a7aa7c5\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-2a6fc509-c4fa-4d85-8887-b83f3a7aa7c5\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-2a6fc509-c4fa-4d85-8887-b83f3a7aa7c5\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-2a6fc509-c4fa-4d85-8887-b83f3a7aa7c5/operations/5242772054586949632\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-2a6fc509-c4fa-4d85-8887-b83f3a7aa7c5 deleted.\n",
      "Experiment run gemini-summ-pairwise-796601d7-6134-4449-9dd7-877f33078317 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summ-pairwise-796601d7-6134-4449-9dd7-877f33078317-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-796601d7-6134-4449-9dd7-877f33078317\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-796601d7-6134-4449-9dd7-877f33078317\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-796601d7-6134-4449-9dd7-877f33078317\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-796601d7-6134-4449-9dd7-877f33078317/operations/9105171685010571264\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summ-pairwise-796601d7-6134-4449-9dd7-877f33078317 deleted.\n",
      "Experiment run gemini-qa-pointwise-f8c69e7b-3c80-425e-9cd9-727552c21dec skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-qa-pointwise-f8c69e7b-3c80-425e-9cd9-727552c21dec-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-qa-pointwise-f8c69e7b-3c80-425e-9cd9-727552c21dec\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-qa-pointwise-f8c69e7b-3c80-425e-9cd9-727552c21dec\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-qa-pointwise-f8c69e7b-3c80-425e-9cd9-727552c21dec\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-qa-pointwise-f8c69e7b-3c80-425e-9cd9-727552c21dec/operations/8904198551639162880\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-qa-pointwise-f8c69e7b-3c80-425e-9cd9-727552c21dec deleted.\n",
      "Experiment run gemini-summarizationc2795bbf-3830-44ac-8500-19b6b9d2b533 skipped backing tensorboard run deletion.\n",
      "To delete backing tensorboard run, execute the following:\n",
      "tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"summarization-quality-gemini-summarizationc2795bbf-3830-44ac-8500-19b6b9d2b533-tb-run\")\n",
      "tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n",
      "tensorboard_run_resource.delete()\n",
      "tensorboard_run_artifact.delete()\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summarizationc2795bbf-3830-44ac-8500-19b6b9d2b533\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summarizationc2795bbf-3830-44ac-8500-19b6b9d2b533\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summarizationc2795bbf-3830-44ac-8500-19b6b9d2b533\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summarizationc2795bbf-3830-44ac-8500-19b6b9d2b533/operations/97972430269579264\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality-gemini-summarizationc2795bbf-3830-44ac-8500-19b6b9d2b533 deleted.\n",
      "Deleting Context : projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality\n",
      "Context deleted. . Resource name: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality\n",
      "Deleting Context resource: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality\n",
      "Delete Context backing LRO: projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality/operations/5857513403723022336\n",
      "Context resource projects/826268977030/locations/us-central1/metadataStores/default/contexts/summarization-quality deleted.\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "experiment = aiplatform.Experiment(experiment_name)\n",
    "experiment.delete()\n",
    "for url in url_audio_chunks:\n",
    "    bucket_name = url.replace(\"gs://\", \"\").split(\"/\")[0]\n",
    "    object_name = \"/\".join(url.replace(\"gs://\", \"\").split(\"/\")[1:])\n",
    "\n",
    "    # Get the bucket and delete the object\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(object_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "diarized_transcription_and_summarization.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
