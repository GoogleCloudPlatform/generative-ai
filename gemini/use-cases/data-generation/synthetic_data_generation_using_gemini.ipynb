{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijGzTHJJUCPY"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEqbX8OhE8y9"
      },
      "source": [
        "# Synthetic Data Generation using Gemini APIs\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/data-generation/synthetic_data_generation_using_gemini.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fuse-cases%2Fdata-generation%2Fsynthetic_data_generation_using_gemini.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/data-generation/synthetic_data_generation_using_gemini.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/data-generation/synthetic_data_generation_using_gemini.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://goo.gle/4jdNeuB\">\n",
        "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in  Cloud Skills Boost\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/data-generation/synthetic_data_generation_using_gemini.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/data-generation/synthetic_data_generation_using_gemini.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/data-generation/synthetic_data_generation_using_gemini.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/data-generation/synthetic_data_generation_using_gemini.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/data-generation/synthetic_data_generation_using_gemini.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fANaqaNOgK_N"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Madhup Sukoon](https://github.com/vagrantism) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkHPv2myT2cx"
      },
      "source": [
        "## Overview\n",
        "\n",
        "### Gemini\n",
        "\n",
        "Gemini is a family of generative AI models developed by Google DeepMind that is designed for multimodal use cases. The Gemini API gives you access to the Gemini Pro model.\n",
        "\n",
        "### Gemini API in Vertex AI\n",
        "\n",
        "The Gemini API in Vertex AI provides a unified interface for interacting with Gemini models.\n",
        "\n",
        "- **Gemini**: Designed to handle natural language tasks, multi-turn text and code chat, and code generation.\n",
        "\n",
        "You can interact with the Gemini API using the following methods:\n",
        "\n",
        "- Use [Vertex AI Studio](https://cloud.google.com/generative-ai-studio) for quick testing and command generation\n",
        "- Use cURL commands\n",
        "- Use the Vertex AI SDK\n",
        "\n",
        "This notebook focuses on using the **Vertex AI SDK for Python** to call the Gemini API in Vertex AI for the Gemini model.\n",
        "\n",
        "For more information, see the [Generative AI on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview) documentation.\n",
        "\n",
        "### Snowfakery\n",
        "\n",
        "[Snowfakery](https://snowfakery.readthedocs.io/en/docs/index.html) is a framework for generating complex fake data at scale. It has a lot of in-built plugins, and allows you to extend its functionality by writing your own plugins.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrkcqHrrwMAo"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "This repository demonstrates how Gemini can be leveraged as a Snowfakery plugin for generating synthetic data based on a set of predefined schemas and data generation strategies. The framework is based on [Snowfakery](https://snowfakery.readthedocs.io/) which is itself based on [Faker](https://faker.readthedocs.io/). It requires the expected outputs to be codified in a YAML file per Snowfakery specs, detailing all the required fields and their respective data generation strategies. The framework currently supports 3 such strategies:\n",
        "\n",
        "1. Static Values - can be included in the YAML file itself.\n",
        "2. Faker based values - Leverages the Faker library to generate fake data.\n",
        "3. LLM based values - Leverages an LLM call and a predefined prompt template to generate data\n",
        "\n",
        "It is also possible to use arbitrary python functions to generate data and augment the pipeline. Interrelated schemas are also supported where the value of a given field depends on an already defined field, which allows us to create hierarchical data and complex schemas. The data generated via this framework is saved to a CSV file for further analysis / consumption.\n",
        "\n",
        "Although this notebook can be used for any synthetic-data generation use-case and schema, the current examples shows the simple use case of generating long (blogs) and short (comments) format contents using a given Wikipedia page as the seed data. While the primary purpose of the synthetic data generation pipeline is to generate data for testing, this can also be used to support tangential use-cases like running prompt experiments and comparisons at scale, building few-shot examples, evaluating fine-tuned models, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9nEPojogw-g"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "- Vertex AI\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r11Gu7qNgx1p"
      },
      "source": [
        "## Getting Started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google_cloud_aiplatform-1.50.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google_cloud_storage-2.16.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fsspec-2024.3.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google_cloud_documentai_toolbox-0.12.2a0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google_cloud_documentai_toolbox-0.11.1a0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google_cloud_aiplatform-1.50.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google_cloud_storage-2.16.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.1 requires google-ai-generativelanguage==0.6.9, but you have google-ai-generativelanguage 0.6.16 which is incompatible.\n",
            "pyautogen 0.8.2 requires pydantic<3,>=2.6.1, but you have pydantic 1.10.14 which is incompatible.\n",
            "gradio 5.21.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "gradio 5.21.0 requires pydantic>=2.0, but you have pydantic 1.10.14 which is incompatible.\n",
            "langchain 0.3.21 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.14 which is incompatible.\n",
            "jiwer 3.1.0 requires click>=8.1.8, but you have click 8.1.7 which is incompatible.\n",
            "unstructured-client 0.18.0 requires requests>=2.31.0, but you have requests 2.29.0 which is incompatible.\n",
            "langchain-experimental 0.0.56 requires langchain<0.2.0,>=0.1.14, but you have langchain 0.3.21 which is incompatible.\n",
            "langchain-experimental 0.0.56 requires langchain-core<0.2.0,>=0.1.37, but you have langchain-core 0.3.46 which is incompatible.\n",
            "gradio-client 1.7.2 requires huggingface-hub>=0.19.3, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "rich-toolkit 0.13.2 requires typing-extensions>=4.12.2, but you have typing-extensions 4.10.0 which is incompatible.\n",
            "langchain-google-genai 2.0.11 requires pydantic<3,>=2, but you have pydantic 1.10.14 which is incompatible.\n",
            "unstructured 0.13.0 requires beautifulsoup4==4.12.3, but you have beautifulsoup4 4.13.3 which is incompatible.\n",
            "unstructured 0.13.0 requires dataclasses-json==0.6.4, but you have dataclasses-json 0.6.7 which is incompatible.\n",
            "unstructured 0.13.0 requires lxml==5.1.0, but you have lxml 5.2.2 which is incompatible.\n",
            "unstructured 0.13.0 requires marshmallow==3.20.2, but you have marshmallow 3.26.1 which is incompatible.\n",
            "unstructured 0.13.0 requires packaging==23.2, but you have packaging 24.2 which is incompatible.\n",
            "unstructured 0.13.0 requires python-dateutil==2.8.2, but you have python-dateutil 2.9.0.post0 which is incompatible.\n",
            "unstructured 0.13.0 requires rapidfuzz==3.6.1, but you have rapidfuzz 3.12.2 which is incompatible.\n",
            "unstructured 0.13.0 requires requests==2.31.0, but you have requests 2.29.0 which is incompatible.\n",
            "unstructured 0.13.0 requires soupsieve==2.5, but you have soupsieve 2.6 which is incompatible.\n",
            "unstructured 0.13.0 requires tqdm==4.66.2, but you have tqdm 4.67.1 which is incompatible.\n",
            "unstructured 0.13.0 requires typing-extensions==4.9.0, but you have typing-extensions 4.10.0 which is incompatible.\n",
            "arxiv 2.1.3 requires requests~=2.32.0, but you have requests 2.29.0 which is incompatible.\n",
            "google-genai 1.7.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.14 which is incompatible.\n",
            "google-genai 1.7.0 requires typing-extensions<5.0.0,>=4.11.0, but you have typing-extensions 4.10.0 which is incompatible.\n",
            "autogen-core 0.4.9.2 requires protobuf~=5.29.3, but you have protobuf 4.25.6 which is incompatible.\n",
            "autogen-core 0.4.9.2 requires pydantic<3.0.0,>=2.10.0, but you have pydantic 1.10.14 which is incompatible.\n",
            "streamlit 1.34.0 requires pillow<11,>=7.1.0, but you have pillow 11.1.0 which is incompatible.\n",
            "streamlit 1.34.0 requires tenacity<9,>=8.1.0, but you have tenacity 9.0.0 which is incompatible.\n",
            "poetry 1.6.1 requires build<0.11.0,>=0.10.0, but you have build 1.2.2.post1 which is incompatible.\n",
            "langchain-google-vertexai 2.0.15 requires pydantic<3.0,>=2.9, but you have pydantic 1.10.14 which is incompatible.\n",
            "pydantic-settings 2.8.1 requires pydantic>=2.7.0, but you have pydantic 1.10.14 which is incompatible.\n",
            "openai 1.67.0 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.10.0 which is incompatible.\n",
            "langchain-core 0.3.46 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.14 which is incompatible.\n",
            "langchain-google-community 1.0.7 requires langchain-community<0.3.0,>=0.2.1, but you have langchain-community 0.3.20 which is incompatible.\n",
            "langchain-google-community 1.0.7 requires langchain-core<0.3,>=0.2.9, but you have langchain-core 0.3.46 which is incompatible.\n",
            "langchain-google-community 1.0.7 requires tenacity<8.4.0,>=8.3.0, but you have tenacity 9.0.0 which is incompatible.\n",
            "google-cloud-documentai-toolbox 0.13.5a0 requires Pillow<11.0.0,>=10.0.0, but you have pillow 11.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google_cloud_aiplatform-1.50.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google_cloud_aiplatform-1.50.0.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --user -q google-cloud-aiplatform snowfakery==3.6.2 wikipedia-api==0.6.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXHfaVS66_01"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lslYAvw37JGQ"
      },
      "outputs": [],
      "source": [
        "from io import StringIO\n",
        "import logging\n",
        "import sys\n",
        "import types\n",
        "\n",
        "import jinja2\n",
        "from snowfakery import generate_data\n",
        "from snowfakery.plugins import SnowfakeryPlugin\n",
        "from vertexai.generative_models import GenerationConfig, GenerativeModel\n",
        "import wikipediaapi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK6TsnYghrQk"
      },
      "source": [
        "## Creating Plugins and Prompts\n",
        "\n",
        "The following cells create the 2 custom plugins we need for this use case along with the needed prompts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hg7cMyOIyP7"
      },
      "source": [
        "### Creating Plugins\n",
        "The first plugin gives us the ability to interact with Wikipedia and fetch the contents for a given page. The second plugin allows us to interact with the Gemini API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4-VrhlHuEfnJ"
      },
      "outputs": [],
      "source": [
        "class SyntheticDataGeneration:\n",
        "    \"\"\"\n",
        "    Implements all the extra functionality needed for this use-case\n",
        "    \"\"\"\n",
        "\n",
        "    class Plugins(types.ModuleType):\n",
        "        \"\"\"\n",
        "        Provides the plugins needed to extend Snowfakery\n",
        "        \"\"\"\n",
        "\n",
        "        class Gemini(SnowfakeryPlugin):\n",
        "            \"\"\"\n",
        "            Plugin for interacting with Gemini.\n",
        "            \"\"\"\n",
        "\n",
        "            class Functions:\n",
        "                \"\"\"\n",
        "                Functions to implement field / object level data generation\n",
        "                \"\"\"\n",
        "\n",
        "                model: GenerativeModel = GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "                def fill_prompt(self, prompt_name: str, **kwargs) -> str:\n",
        "                    \"\"\"\n",
        "                    Returns a formatted prompt\n",
        "                    \"\"\"\n",
        "                    return (\n",
        "                        jinja2.Environment(\n",
        "                            loader=jinja2.FileSystemLoader(searchpath=\"./\")\n",
        "                        )\n",
        "                        .get_template(prompt_name)\n",
        "                        .render(**kwargs)\n",
        "                    )\n",
        "\n",
        "                def generate(\n",
        "                    self,\n",
        "                    prompt_name: str,\n",
        "                    temperature=0.9,\n",
        "                    top_p=1,\n",
        "                    **kwargs,\n",
        "                ) -> str | None:\n",
        "                    \"\"\"\n",
        "                    A wrapper around Gemini plugin\n",
        "                    \"\"\"\n",
        "                    logging.info(\"Preparing Prompt %s with %s\", prompt_name, kwargs)\n",
        "                    prompt = self.fill_prompt(prompt_name, **kwargs)\n",
        "                    logging.info(\"Prompt %s Prepared\", prompt_name)\n",
        "                    try:\n",
        "                        logging.info(\"Calling Gemini For %s\", prompt_name)\n",
        "                        response = self.model.generate_content(\n",
        "                            prompt,\n",
        "                            generation_config=GenerationConfig(\n",
        "                                temperature=temperature,\n",
        "                                max_output_tokens=8192,\n",
        "                                top_p=top_p,\n",
        "                            ),\n",
        "                        )\n",
        "                    except Exception as e:\n",
        "                        logging.trace(\n",
        "                            (\n",
        "                                \"Unable to generate text using %s.\\n\"\n",
        "                                \"Prepared Prompt: \\n%s\\n\\nError: %s\"\n",
        "                            ),\n",
        "                            prompt_name,\n",
        "                            prompt,\n",
        "                            e,\n",
        "                        )\n",
        "                        return None\n",
        "\n",
        "                    try:\n",
        "                        return response.text\n",
        "                    except Exception as e:\n",
        "                        logging.trace(\n",
        "                            (\n",
        "                                \"Unable to generate text using %s.\\n\"\n",
        "                                \"Prepared Prompt: \\n%s\\n\\n\"\n",
        "                                \"Received Response: \\n%s\\n\\n\"\n",
        "                                \"Error: %s\"\n",
        "                            ),\n",
        "                            prompt_name,\n",
        "                            prompt,\n",
        "                            response,\n",
        "                            e,\n",
        "                        )\n",
        "                        return None\n",
        "\n",
        "        class Wikipedia(SnowfakeryPlugin):\n",
        "            \"\"\"\n",
        "            Plugin for interacting with Wikipedia.\n",
        "            \"\"\"\n",
        "\n",
        "            class Functions:\n",
        "                \"\"\"\n",
        "                Implements a single function to fetch a Wikipedia page\n",
        "                \"\"\"\n",
        "\n",
        "                def get_page(self, title: str):\n",
        "                    \"\"\"\n",
        "                    Returns the title, URL and sections of the given wikipedia page\n",
        "                    \"\"\"\n",
        "                    logging.info(\"Parsing Wikipedia Page %s\", title)\n",
        "                    page = wikipediaapi.Wikipedia(\n",
        "                        \"Snowfakery (example@google.com)\", \"en\"\n",
        "                    ).page(title)\n",
        "                    results = {\"sections\": {}, \"title\": page.title, \"url\": page.fullurl}\n",
        "                    sections = [(s.title, s) for s in page.sections]\n",
        "                    while sections:\n",
        "                        sec_title, sec_obj = sections.pop()\n",
        "                        if sec_title in [\n",
        "                            \"External links\",\n",
        "                            \"References\",\n",
        "                            \"See also\",\n",
        "                            \"Further reading\",\n",
        "                        ]:\n",
        "                            continue\n",
        "                        if sec_obj.text:\n",
        "                            results[\"sections\"][sec_title] = sec_obj.text\n",
        "                        for sub_sec in sec_obj.sections:\n",
        "                            sections.append((f\"{sec_title} - {sub_sec.title}\", sub_sec))\n",
        "                    logging.info(\"Parsing Wikipedia Page %s Complete\", title)\n",
        "                    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wDlaPt4I9lI"
      },
      "source": [
        "### Making plugins discoverable\n",
        "\n",
        "We add the created class to `sys.modules` to ensure Snowfakery can find them and import them as modules as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uDbBxdLQJFjg"
      },
      "outputs": [],
      "source": [
        "sys.modules[\"SyntheticDataGeneration.Plugins\"] = SyntheticDataGeneration.Plugins(\n",
        "    name=\"SyntheticDataGeneration.Plugins\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML96RDV6L-St"
      },
      "source": [
        "### Creating Prompt Templates\n",
        "\n",
        "We add the created class to `sys.modules` to ensure Snowfakery can find them and import them as modules as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "L05Um44dMFWN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing blog_generator.jinja\n"
          ]
        }
      ],
      "source": [
        "%%writefile blog_generator.jinja\n",
        "You are an expert content creator who writes detailed, factual blogs.\n",
        "You have been asked to write a blog about {{idea_title}}.\n",
        "To get you started, you have also been given the following context about the topic:\n",
        "\n",
        "{{idea_body}}\n",
        "\n",
        "Ensure the blog that you write is interesting,detailed and factual.\n",
        "Take a deep breath and start writing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PGa_a8GFO0dO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing comment_generator.jinja\n"
          ]
        }
      ],
      "source": [
        "%%writefile comment_generator.jinja\n",
        "You are {{first_name}} {{last_name}}. You are {{age}} years old. You are interested in {{interests}}. You work at {{organization}} as a {{profession}}.\n",
        "You came across the following article:\n",
        "\n",
        "{{blog_title}}\n",
        "\n",
        "{{blog_body}}\n",
        "\n",
        "Present your thoughts and feelings about the article in a short comment.\n",
        "\n",
        "Comment:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTMywdzUORIA"
      },
      "source": [
        "## Creating the Recipe\n",
        "In order to generate synthetic data, the schema of the synthetic data must be defined first. This is done by creating a `recipe` in a YAML format as demonstrated below, more details on writing recipes can be found [here](https://snowfakery.readthedocs.io/en/latest/#central-concepts)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lRyTw2iPhEXG"
      },
      "outputs": [],
      "source": [
        "recipe = \"\"\"\n",
        "- plugin: SyntheticDataGeneration.Plugins.Wikipedia\n",
        "- plugin: SyntheticDataGeneration.Plugins.Gemini\n",
        "- option: wiki_title\n",
        "- var: __seed\n",
        "  value:\n",
        "    - Wikipedia.get_page :\n",
        "      title : ${{wiki_title}}\n",
        "\n",
        "- object : users\n",
        "  count : ${{random_number(min=100, max=500)}}\n",
        "  fields :\n",
        "    first_name : ${{fake.FirstName}}\n",
        "    last_name : ${{fake.FirstName}}\n",
        "    age:\n",
        "      random_number:\n",
        "        min: 18\n",
        "        max: 95\n",
        "    email : ${{fake.Email}}\n",
        "    phone : ${{fake.PhoneNumber}}\n",
        "    interests : ${{fake.Bs}}\n",
        "    postal_code : ${{fake.Postalcode}}\n",
        "    organization : ${{fake.Company}}\n",
        "    profession : ${{fake.Job}}\n",
        "\n",
        "- object : seeds\n",
        "  fields :\n",
        "    title : ${{__seed['title']}}\n",
        "    url : ${{__seed['url']}}\n",
        "    section_count : ${{__seed['sections'] | length}}\n",
        "\n",
        "  friends:\n",
        "    - object : blog_ideas\n",
        "      count : ${{seeds.section_count}}\n",
        "      fields :\n",
        "        seed_id : ${{seeds.id}}\n",
        "        section : ${{(__seed.sections.keys() | list)[child_index]}}\n",
        "        body : ${{__seed.sections[section]}}\n",
        "\n",
        "      friends:\n",
        "        - object : blog_posts\n",
        "          fields :\n",
        "            blog_idea_id : ${{blog_ideas.id}}\n",
        "            title : ${{seeds.title}} - ${{blog_ideas.section}}\n",
        "            body :\n",
        "              - Gemini.generate:\n",
        "                prompt_name : blog_generator.jinja\n",
        "                idea_title : ${{title}}\n",
        "                idea_body : ${{blog_ideas.body}}\n",
        "            author : Gemini\n",
        "\n",
        "          friends:\n",
        "            - object : blog_post_comments\n",
        "              fields :\n",
        "                blog_post_id : ${{blog_posts.id}}\n",
        "                author_id :\n",
        "                  random_reference : users\n",
        "                author_email : ${{author_id.email}}\n",
        "                comment :\n",
        "                  - Gemini.generate:\n",
        "                    prompt_name : comment_generator.jinja\n",
        "                    first_name : ${{author_id.first_name}}\n",
        "                    last_name : ${{author_id.last_name}}\n",
        "                    age : ${{author_id.age}}\n",
        "                    interests : ${{author_id.interests}}\n",
        "                    organization : ${{author_id.organization}}\n",
        "                    profession : ${{author_id.profession}}\n",
        "                    blog_title : ${{blog_posts.title}}\n",
        "                    blog_body : ${{blog_posts.body | truncate(1000)}}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwKHSwZfPgXn"
      },
      "source": [
        "## Generating Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WhSganUbPive"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created outputs/users.csv\n",
            "Created outputs/blog_post_comments.csv\n",
            "Created outputs/blog_posts.csv\n",
            "Created outputs/blog_ideas.csv\n",
            "Created outputs/seeds.csv\n",
            "Created outputs/csvw_metadata.json\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mStringIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwiki_title\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPython_(programming_language)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/api.py:185\u001b[0m, in \u001b[0;36mgenerate_data\u001b[0;34m(yaml_file, parent_application, user_options, dburl, dburls, target_number, debug_internals, generate_cci_mapping_file, output_format, output_file, output_files, output_folder, continuation_file, generate_continuation_file, should_create_cci_record_type_tables, load_declarations, plugin_options, update_input_file, update_passthrough_fields)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# utf-8-sig and newline=\"\" are for Windows\u001b[39;00m\n\u001b[1;32m    181\u001b[0m _, open_update_input_file \u001b[38;5;241m=\u001b[39m open_with_cleanup(\n\u001b[1;32m    182\u001b[0m     update_input_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    183\u001b[0m )\n\u001b[0;32m--> 185\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopen_yaml_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopen_yaml_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_stream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_stream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent_application\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent_application\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerate_continuation_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopen_new_continue_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontinuation_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopen_continuation_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplugin_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_input_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopen_update_input_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_passthrough_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_passthrough_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m open_cci_mapping_file:\n\u001b[1;32m    199\u001b[0m     declarations \u001b[38;5;241m=\u001b[39m gather_declarations(yaml_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, load_declarations)\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator.py:192\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(open_yaml_file, user_options, output_stream, parent_application, stopping_criteria, generate_continuation_file, continuation_file, plugin_options, update_input_file, update_passthrough_fields)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# now do the output\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Interpreter(\n\u001b[1;32m    183\u001b[0m         output_stream\u001b[38;5;241m=\u001b[39moutput_stream,\n\u001b[1;32m    184\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m         continuing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(continuation_data),\n\u001b[1;32m    191\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m interpreter:\n\u001b[0;32m--> 192\u001b[0m         runtime_context \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m DataGenError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mfilename:\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime.py:387\u001b[0m, in \u001b[0;36mInterpreter.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m RowHistoryCV\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow_history)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_context \u001b[38;5;241m=\u001b[39m RuntimeContext(interpreter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 387\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop_over_templates_until_finished\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontinuing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobals\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime.py:406\u001b[0m, in \u001b[0;36mInterpreter.loop_over_templates_until_finished\u001b[0;34m(self, continuing)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_context \u001b[38;5;241m=\u001b[39m RuntimeContext(interpreter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m finished:\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop_over_templates_once\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontinuing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m     finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_context\u001b[38;5;241m.\u001b[39mcheck_if_finished()\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miteration_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime.py:415\u001b[0m, in \u001b[0;36mInterpreter.loop_over_templates_once\u001b[0;34m(self, statement_list, continuing)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloop_over_templates_once\u001b[39m(\u001b[38;5;28mself\u001b[39m, statement_list, continuing: \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m statement \u001b[38;5;129;01min\u001b[39;00m statement_list:\n\u001b[0;32m--> 415\u001b[0m         \u001b[43mstatement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontinuing\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime_object_model.py:307\u001b[0m, in \u001b[0;36mObjectTemplate.execute\u001b[0;34m(self, interp, context, continuing)\u001b[0m\n\u001b[1;32m    305\u001b[0m should_skip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjust_once \u001b[38;5;129;01mand\u001b[39;00m continuing\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_skip:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_context\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime_object_model.py:188\u001b[0m, in \u001b[0;36mObjectTemplate.generate_rows\u001b[0;34m(self, output_stream, parent_context)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(iterator_names, next_value_list):\n\u001b[1;32m    187\u001b[0m                 context\u001b[38;5;241m.\u001b[39minterpreter\u001b[38;5;241m.\u001b[39mregister_variable(name, value)\n\u001b[0;32m--> 188\u001b[0m             rc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rc\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime_object_model.py:272\u001b[0m, in \u001b[0;36mObjectTemplate._generate_row\u001b[0;34m(self, output_stream, context, index)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtablename\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    270\u001b[0m         output_stream\u001b[38;5;241m.\u001b[39mwrite_row(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtablename, context\u001b[38;5;241m.\u001b[39mfilter_row_values(row))\n\u001b[0;32m--> 272\u001b[0m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop_over_templates_once\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfriends\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sobj\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime.py:415\u001b[0m, in \u001b[0;36mInterpreter.loop_over_templates_once\u001b[0;34m(self, statement_list, continuing)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloop_over_templates_once\u001b[39m(\u001b[38;5;28mself\u001b[39m, statement_list, continuing: \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m statement \u001b[38;5;129;01min\u001b[39;00m statement_list:\n\u001b[0;32m--> 415\u001b[0m         \u001b[43mstatement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontinuing\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime_object_model.py:307\u001b[0m, in \u001b[0;36mObjectTemplate.execute\u001b[0;34m(self, interp, context, continuing)\u001b[0m\n\u001b[1;32m    305\u001b[0m should_skip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjust_once \u001b[38;5;129;01mand\u001b[39;00m continuing\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_skip:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_context\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime_object_model.py:188\u001b[0m, in \u001b[0;36mObjectTemplate.generate_rows\u001b[0;34m(self, output_stream, parent_context)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(iterator_names, next_value_list):\n\u001b[1;32m    187\u001b[0m                 context\u001b[38;5;241m.\u001b[39minterpreter\u001b[38;5;241m.\u001b[39mregister_variable(name, value)\n\u001b[0;32m--> 188\u001b[0m             rc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rc\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime_object_model.py:272\u001b[0m, in \u001b[0;36mObjectTemplate._generate_row\u001b[0;34m(self, output_stream, context, index)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtablename\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    270\u001b[0m         output_stream\u001b[38;5;241m.\u001b[39mwrite_row(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtablename, context\u001b[38;5;241m.\u001b[39mfilter_row_values(row))\n\u001b[0;32m--> 272\u001b[0m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop_over_templates_once\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfriends\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sobj\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime.py:415\u001b[0m, in \u001b[0;36mInterpreter.loop_over_templates_once\u001b[0;34m(self, statement_list, continuing)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloop_over_templates_once\u001b[39m(\u001b[38;5;28mself\u001b[39m, statement_list, continuing: \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m statement \u001b[38;5;129;01min\u001b[39;00m statement_list:\n\u001b[0;32m--> 415\u001b[0m         \u001b[43mstatement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontinuing\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime_object_model.py:307\u001b[0m, in \u001b[0;36mObjectTemplate.execute\u001b[0;34m(self, interp, context, continuing)\u001b[0m\n\u001b[1;32m    305\u001b[0m should_skip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjust_once \u001b[38;5;129;01mand\u001b[39;00m continuing\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_skip:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_context\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime_object_model.py:188\u001b[0m, in \u001b[0;36mObjectTemplate.generate_rows\u001b[0;34m(self, output_stream, parent_context)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(iterator_names, next_value_list):\n\u001b[1;32m    187\u001b[0m                 context\u001b[38;5;241m.\u001b[39minterpreter\u001b[38;5;241m.\u001b[39mregister_variable(name, value)\n\u001b[0;32m--> 188\u001b[0m             rc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rc\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime_object_model.py:260\u001b[0m, in \u001b[0;36mObjectTemplate._generate_row\u001b[0;34m(self, output_stream, context, index)\u001b[0m\n\u001b[1;32m    256\u001b[0m sobj \u001b[38;5;241m=\u001b[39m ObjectRow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtablename, row, index)\n\u001b[1;32m    258\u001b[0m context\u001b[38;5;241m.\u001b[39mregister_object(sobj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnickname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjust_once)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_fields\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m context\u001b[38;5;241m.\u001b[39mremember_row(\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtablename,\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnickname,\n\u001b[1;32m    265\u001b[0m     row,\n\u001b[1;32m    266\u001b[0m )\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception_handling(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot write row\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime_object_model.py:279\u001b[0m, in \u001b[0;36mObjectTemplate._generate_fields\u001b[0;34m(self, context, row)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfields:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception_handling(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProblem rendering value\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mfield\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, PluginResultIterator):\n\u001b[1;32m    281\u001b[0m             \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime_object_model.py:464\u001b[0m, in \u001b[0;36mFieldFactory.generate_value\u001b[0;34m(self, context)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, context) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FieldValue:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefinition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m fix_exception(\n\u001b[1;32m    467\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProblem rendering field \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{e}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, e, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname]\n\u001b[1;32m    468\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime_object_model.py:424\u001b[0m, in \u001b[0;36mStructuredValue.render\u001b[0;34m(self, context)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DataGenNameError(\n\u001b[1;32m    420\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobjname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    421\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename,\n\u001b[1;32m    422\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_num,\n\u001b[1;32m    423\u001b[0m         )\n\u001b[0;32m--> 424\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/snowfakery/data_generator_runtime.py:676\u001b[0m, in \u001b[0;36mevaluate_function\u001b[0;34m(func, args, kwargs, context)\u001b[0m\n\u001b[1;32m    671\u001b[0m     args \u001b[38;5;241m=\u001b[39m [arg\u001b[38;5;241m.\u001b[39mrender(context) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrender\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m    672\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    673\u001b[0m         name: arg\u001b[38;5;241m.\u001b[39mrender(context) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrender\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[1;32m    674\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    675\u001b[0m     }\n\u001b[0;32m--> 676\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[10], line 50\u001b[0m, in \u001b[0;36mSyntheticDataGeneration.Plugins.Gemini.Functions.generate\u001b[0;34m(self, prompt_name, temperature, top_p, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling Gemini For \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, prompt_name)\n\u001b[0;32m---> 50\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGenerationConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     59\u001b[0m     logging\u001b[38;5;241m.\u001b[39mtrace(\n\u001b[1;32m     60\u001b[0m         (\n\u001b[1;32m     61\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to generate text using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m         e,\n\u001b[1;32m     67\u001b[0m     )\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:695\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    687\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    688\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:820\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \n\u001b[1;32m    795\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    813\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    814\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    818\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    819\u001b[0m )\n\u001b[0;32m--> 820\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:2275\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2275\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/grpc/_interceptor.py:329\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m--> 329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interceptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mresult(), call\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/google/cloud/aiplatform_v1/services/prediction_service/transports/grpc.py:84\u001b[0m, in \u001b[0;36m_LoggingClientInterceptor.intercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     69\u001b[0m     grpc_request \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m: request_payload,\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequestMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrpc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[1;32m     73\u001b[0m     }\n\u001b[1;32m     74\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     76\u001b[0m         extra\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m         },\n\u001b[1;32m     82\u001b[0m     )\n\u001b[0;32m---> 84\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     response_metadata \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtrailing_metadata()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    306\u001b[0m (\n\u001b[1;32m    307\u001b[0m     new_method,\n\u001b[1;32m    308\u001b[0m     new_timeout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m     new_compression,\n\u001b[1;32m    313\u001b[0m ) \u001b[38;5;241m=\u001b[39m _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/grpc/_channel.py:1195\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_call\u001b[39m(\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1185\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, grpc\u001b[38;5;241m.\u001b[39mCall]:\n\u001b[1;32m   1192\u001b[0m     (\n\u001b[1;32m   1193\u001b[0m         state,\n\u001b[1;32m   1194\u001b[0m         call,\n\u001b[0;32m-> 1195\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
            "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "generate_data(\n",
        "    StringIO(recipe),\n",
        "    output_format=\"csv\",\n",
        "    output_folder=\"outputs\",\n",
        "    user_options={\"wiki_title\": \"Python_(programming_language)\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N4XC09Uc-oH"
      },
      "source": [
        "### Results\n",
        "\n",
        "The synthetic data has been generated and stored as CSV files in the `outputs` folder."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "synthetic_data_generation_using_gemini.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
