{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Prompt Optimization for Multimodal Prompts\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_multimodal_image.ipynb\">\n",
        "<img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fprompts%2Fprompt_optimizer%2Fvertex_ai_prompt_optimizer_sdk_multimodal_image.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_multimodal_image.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_multimodal_image.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_multimodal_image.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_multimodal_image.ipynb\" target=\"_blank\">\n",
        "<img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_multimodal_image.ipynb\" target=\"_blank\">\n",
        "<img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_multimodal_image.ipynb\" target=\"_blank\">\n",
        "<img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_multimodal_image.ipynb\" target=\"_blank\">\n",
        "<img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| Author(s) |  [Raj Sinha](https://github.com/raj-sinha) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "When developing Generative AI (Gen AI) applications, prompt engineering poses challenges due to its time-consuming and error-prone nature. Significant effort is involved when crafting and inputting prompts to achieve successful task completion. With the frequent release of foundational models, you face the added burden of migrating working prompts from one model version to another.\n",
        "\n",
        "Vertex AI prompt optimizer aims to alleviate these challenges by providing you with an intelligent prompt optimization tool. With this tool you can both translate and optimize system instruction in the prompts and the best demonstrations (examples) for prompt templates, empowering you to shape LLM responses from any source model to a target Google model.\n",
        "\n",
        "Vertex AI prompt optimizer currently supports the following modalities: text, image, video. Audio support is forthcoming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8BqRNCswb0A"
      },
      "source": [
        "## Objective\n",
        "\n",
        "This notebook demonstrates how to leverage Vertex AI prompt optimizer to optimize a simple multimodal prompt for a Gemini model with respect to a question-answering task. The goal is to use Vertex AI prompt optimizer to find the new multimodal prompt template that generates the most accurate and grounded responses.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services and resources:\n",
        "\n",
        "Generative AI on Vertex AI\n",
        "Vertex AI prompt optimizer\n",
        "Vertex AI Gen AI evaluation\n",
        "Vertex AI Custom job\n",
        "The steps performed include:\n",
        "\n",
        "Define the prompt template you want to optimize.\n",
        "Prepare the prompt optimization dataset.\n",
        "Set target model and evaluation metric.\n",
        "Set optimization mode and steps.\n",
        "Run the automatic prompt optimization job.\n",
        "Collect the best prompt template and evaluation metric.\n",
        "Validate the best prompt template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHX-mT4NWVsZ"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "The dataset that is used is the [MathVista dataset](https://mathvista.github.io/).\n",
        "\n",
        "```\n",
        "@inproceedings{lu2024mathvista,\n",
        "  author = {Lu, Pan and Bansal, Hritik and Xia, Tony and Liu, Jiacheng and Li, Chunyuan and Hajishirzi, Hannaneh and Cheng, Hao and Chang, Kai-Wei and Galley, Michel and Gao, Jianfeng},\n",
        "  title = {MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts},\n",
        "  booktitle = {International Conference on Learning Representations (ICLR)},\n",
        "  year = {2024}\n",
        "}```\n",
        "\n",
        "One sample of this dataset looks like:\n",
        "\n",
        "<code>\n",
        "{\"query\": \"Hint: Please answer the question and provide the correct option letter, e.g., A, B, C, D, at the end.\\nQuestion: As shown in the figure, CD is the diameter of \\u2299O, chord DE \\u2225 OA, if the degree of \\u2220D is 50.0, then the degree of \\u2220C is ()\\nChoices:\\n(A) 25\\u00b0\\n(B) 30\\u00b0\\n(C) 40\\u00b0\\n(D) 50\\u00b0\", \"image\": \"gs://bucket/path/to/math_vista/images/643.jpg\", \"target\": \"25\\u00b0\"}\n",
        "</code>\n",
        "\n",
        "The above sample reads as:\n",
        "<p>\n",
        "<html>\n",
        "<b>Query:</b>\n",
        "\n",
        "<i>Hint:</i> Please answer the question and provide the correct option letter, e.g., A, B, C, D, at the end.\n",
        "\n",
        "<i>Question:</i> As shown in the figure, CD is the diameter of &#x2299; O, chord DE &#x2225; OA, if the degree of &#x2220; D is 50.0, then the degree of &#x2220; C is ()\n",
        "\n",
        "<i>Choices:</i>\n",
        "(A) 25 &deg;\n",
        "(B) 30 &deg;\n",
        "(C) 40 &deg;\n",
        "(D) 50 &deg;\n",
        "</html>\n",
        "\n",
        "<b>Image:</b>\n",
        "gs://bucket/path/to/math_vista/images/643.jpg\n",
        "\n",
        "<b>Target:</b>\n",
        "25 &deg;\n",
        "\n",
        "The image in the above sample is:\n",
        "\n",
        "<img src=\"data:image/jpeg;base64,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\">\n",
        "\n",
        "**Preparation**\n",
        "\n",
        "You should prepare your multimodal dataset in JSONL format, where each sample has the format shown above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXDewg2-zzud"
      },
      "source": [
        "## Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "- Vertex AI\n",
        "- Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet 'google-cloud-aiplatform[evaluation]'\n",
        "%pip install --upgrade --quiet 'plotly' 'asyncio' 'tqdm' 'tenacity' 'etils' 'importlib_resources' 'fsspec' 'gcsfs' 'nbformat>=4.2.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKn-zl1Y0NDA"
      },
      "outputs": [],
      "source": [
        "! mkdir -p ./tutorial/utils && wget https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/prompts/prompt_optimizer/vapo_lib.py -P ./tutorial/utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. In Colab or Colab Enterprise, you might see an error message that says \"Your session crashed for an unknown reason.\" This is expected. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "# Use the environment variable if the user doesn't provide Project ID.\n",
        "import os\n",
        "\n",
        "import vertexai\n",
        "\n",
        "PROJECT_ID = (\n",
        "    \"\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        ")\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "REGION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "BUCKET_NAME = \"\"  # @param {type:\"string\"}\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfIUgj-mU8K9"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets and tuning results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-L1BH8TU9Gn"
      },
      "outputs": [],
      "source": [
        "!gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "set_service_account"
      },
      "source": [
        "### Service Account and permissions\n",
        "\n",
        "Vertex AI Automated Prompt Design requires a service account with the following permissions:\n",
        "\n",
        "-   `Vertex AI User` to call Vertex LLM API\n",
        "-   `Storage Object Admin` to read and write to your GCS bucket.\n",
        "-   `Artifact Registry Reader` to download the pipeline template from Artifact Registry.\n",
        "\n",
        "[Check out the documentation](https://cloud.google.com/iam/docs/manage-access-service-accounts#iam-view-access-sa-gcloud) to learn how to grant those permissions to a single service account."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX9tpdtuQI5L"
      },
      "source": [
        "> If you run following commands using Vertex AI Workbench, run directly in the terminal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VZ6ADo0vsQe"
      },
      "outputs": [],
      "source": [
        "PROJECT_NUMBER = !gcloud projects describe {PROJECT_ID} --format=\"get(projectNumber)\"[0]\n",
        "PROJECT_NUMBER = PROJECT_NUMBER[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssUJJqXJJHgC"
      },
      "outputs": [],
      "source": [
        "SERVICE_ACCOUNT = f\"{PROJECT_NUMBER}-compute@developer.gserviceaccount.com\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqOHg5aid6HP"
      },
      "outputs": [],
      "source": [
        "for role in ['aiplatform.user', 'storage.objectAdmin', 'artifactregistry.reader']:\n",
        "\n",
        "    ! gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "      --member=serviceAccount:{SERVICE_ACCOUNT} \\\n",
        "      --role=roles/{role} --condition=None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek1-iTbPjzdJ"
      },
      "source": [
        "### Set tutorial folder and workspace\n",
        "\n",
        "Set a local folder to collect and organize data and any tutorial artifacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbfKRabXj3la"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path as path\n",
        "\n",
        "ROOT_PATH = path.cwd()\n",
        "TUTORIAL_PATH = ROOT_PATH / \"tutorial\"\n",
        "TUTORIAL_PATH.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaNdfftpXTIX"
      },
      "source": [
        "Set an associated workspace to store prompt optimization results on Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joJPc3FmX1fk"
      },
      "outputs": [],
      "source": [
        "from etils import epath\n",
        "\n",
        "WORKSPACE_URI = epath.Path(BUCKET_URI) / \"optimization\"\n",
        "INPUT_DATA_URI = epath.Path(WORKSPACE_URI) / \"data\"\n",
        "\n",
        "WORKSPACE_URI.mkdir(parents=True, exist_ok=True)\n",
        "INPUT_DATA_URI.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### Import libraries\n",
        "\n",
        "Import required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "# Tutorial\n",
        "from argparse import Namespace\n",
        "import json\n",
        "\n",
        "# General\n",
        "import logging\n",
        "from typing import Final\n",
        "import warnings\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "from google.cloud import aiplatform\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tutorial.utils import vapo_lib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "820DIvw1o8tB"
      },
      "source": [
        "### Libraries logging\n",
        "\n",
        "Configure logging for libraries to display output within the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKc4ZdUBo_SM"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"urllib3.connectionpool\").setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxc7q4r-DFH4"
      },
      "source": [
        "### Define constants\n",
        "\n",
        "Define some tutorial constants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y5t67f3DHNm"
      },
      "outputs": [],
      "source": [
        "INPUT_DATA_FILE_URI = (\n",
        "    \"gs://github-repo/prompts/prompt_optimizer/mathvista_dataset/mathvista_input.jsonl\"\n",
        ")\n",
        "INPUT_DATA_IMAGES_URI = (\n",
        "    \"gs://github-repo/prompts/prompt_optimizer/mathvista_dataset/images\"\n",
        ")\n",
        "\n",
        "EXPERIMENT_NAME = \"mathvista-multimodal-prompt-eval\"\n",
        "INPUT_OPTIMIZATION_DATA_URI = epath.Path(WORKSPACE_URI) / \"prompt_optimization_data\"\n",
        "INPUT_OPTIMIZATION_DATA_FILE_URI = str(\n",
        "    INPUT_DATA_URI / \"prompt_optimization_dataset.jsonl\"\n",
        ")\n",
        "OUTPUT_OPTIMIZATION_DATA_URI = epath.Path(WORKSPACE_URI) / \"optimization_jobs\"\n",
        "APD_CONTAINER_URI: Final[str] = (\n",
        "    \"us-docker.pkg.dev/vertex-ai-restricted/builtin-algorithm/apd:preview_v1_0\"\n",
        ")\n",
        "CONFIG_FILE_URI = str(WORKSPACE_URI / \"config\" / \"config.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQMc2Uwf0fBQ"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdvJRUWRNGHE"
      },
      "source": [
        "## 3. Automated prompt design with Vertex AI prompt optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmTotjRAJplw"
      },
      "source": [
        "### Load the dataset\n",
        "\n",
        "Load the MathVista dataset from a Google Cloud Storage bucket. The dataset contains the following columns:\n",
        "\n",
        "*   `query`: The multiple-choice math question along with a hint and the choices.\n",
        "*   `image`: Relevant image to answer the question.\n",
        "*   `target`: The ground truth answer—the correct response that the user expects from the AI assistant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA7aG08wJtVm"
      },
      "outputs": [],
      "source": [
        "prompt_optimization_df = pd.read_json(INPUT_DATA_FILE_URI, lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xn-pz3v5HVK"
      },
      "outputs": [],
      "source": [
        "prompt_optimization_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2l7JwuDcPqX"
      },
      "source": [
        "Print an example of the MathVista dataset.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsXdJBJXiaVH"
      },
      "outputs": [],
      "source": [
        "vapo_lib.print_df_rows(prompt_optimization_df, n=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5SmBApC-WDg"
      },
      "source": [
        "### Evaluate the system instruction in the original prompt template\n",
        "\n",
        "Assess the original prompt's effectiveness for the MathVista Dataset task using Vertex AI's Gen AI Evaluation service. This service offers various metrics and methods to evaluate generative models, which enables comparing the model's performance against our own expectations and criteria.\n",
        "\n",
        "Specifically, you focus on the correctness of the answers generated in response to the prompt using a test dataset.\n",
        "\n",
        "To learn more, see [Gen AI evaluation service overview](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview).  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhWt4iaGRBdl"
      },
      "outputs": [],
      "source": [
        "train_prompt_optimization_df, test_prompt_optimization_df = train_test_split(\n",
        "    prompt_optimization_df, test_size=0.8, random_state=8\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF3XY_d_yB-K"
      },
      "source": [
        "#### Upload samples to bucket\n",
        "\n",
        "Once you prepare your prompt optimization dataset, you can upload them on Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "155paLgGUXOm"
      },
      "outputs": [],
      "source": [
        "train_prompt_optimization_df.to_json(\n",
        "    INPUT_OPTIMIZATION_DATA_FILE_URI, orient=\"records\", lines=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zA0wuXZRoPT0"
      },
      "outputs": [],
      "source": [
        "SYSTEM_INSTRUCTION_TEMPLATE = \"\"\"\n",
        "Solve the problem given the image.\n",
        "\"\"\"\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Problem: {{query}}\n",
        "Image: {{image}} @@@image/jpeg\n",
        "Answer: {{target}}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-FR6GF5lFrh"
      },
      "source": [
        "#### To evaluate the prompt template, follow the method outlined in other notebooks such as [gemini/evaluation/evaluate_multimodal_task_image.ipynb](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/evaluate_multimodal_task_image.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5RD0l2xX-FI"
      },
      "source": [
        "#### Configure optimization settings\n",
        "\n",
        "Vertex AI prompt optimizer lets you control the optimization process by specifying what to optimize (instructions only, demonstrations only, or both), providing a system instruction and prompt template, and selecting the target model.  You can optionally refine the optimization with some advanced settings like its duration and the number of optimization iterations it runs, which models the Vertex AI prompt optimizer uses, and other parameters to control the structure and content of prompts.\n",
        "\n",
        "Below are some common and recommended default configurations. For more advanced control, you can learn and explore more about all the parameters and how to best use them in the [detailed documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFHutXhgeqRx"
      },
      "outputs": [],
      "source": [
        "PROMPT_OPTIMIZATION_JOB = \"auto-multimodal-prompt-design-job-\" + vapo_lib.get_id()\n",
        "OUTPUT_OPTIMIZATION_RUN_URI = str(\n",
        "    OUTPUT_OPTIMIZATION_DATA_URI / PROMPT_OPTIMIZATION_JOB\n",
        ")\n",
        "\n",
        "args = Namespace(\n",
        "    # Basic configuration\n",
        "    system_instruction=SYSTEM_INSTRUCTION_TEMPLATE,  # System instructions for the target model. String.\n",
        "    prompt_template=PROMPT_TEMPLATE,  # Template for prompts,  String.\n",
        "    demo_and_query_template=PROMPT_TEMPLATE,\n",
        "    target_model=\"gemini-2.0-flash-001\",  # Target model for optimization. String. Supported models: \"gemini-2.0-flash-lite-001\", \"gemini-2.0-flash-001\", \"gemini-1.5-flash-002\", \"gemini-1.5-pro-002\", \"gemini-1.5-flash-001\", \"gemini-1.5-pro-001\", \"gemini-1.0-pro-001\", \"gemini-1.0-pro-002\", \"gemini-1.0-ultra-001\", \"text-bison@001\", \"text-bison@002\", \"text-bison32k@002\", \"text-unicorn@001\"\n",
        "    optimization_mode=\"instruction\",  # Optimization mode. String. Supported modes: \"instruction\", \"demonstration\", \"instruction_and_demo\"\n",
        "    eval_metrics_types=[\n",
        "        \"question_answering_correctness\",\n",
        "    ],  # List of evaluation metrics. List of strings. Supported metrics: \"bleu\", \"coherence\", \"comet\", \"exact_match\", \"fluency\", \"groundedness\", \"metricx\", \"rouge_1\", \"rouge_2\", \"rouge_l\", \"rouge_l_sum\", \"safety\", \"question_answering_correctness\", \"question_answering_quality\", \"summarization_quality\", \"text_quality\", \"verbosity\", \"tool_call_valid\", \"tool_name_match\", \"tool_parameter_key_match\", \"tool_parameter_kv_match\"\n",
        "    eval_metrics_weights=[\n",
        "        1.0,\n",
        "    ],  # Weights for evaluation metrics. List of floats.  Length must match eval_metrics_types.  Should sum to 1.\n",
        "    aggregation_type=\"weighted_sum\",  # Aggregation type for evaluation metrics. String. Supported aggregation types: \"weighted_sum\", \"weighted_average\"\n",
        "    input_data_path=INPUT_OPTIMIZATION_DATA_FILE_URI,  # Cloud Storage URI to input optimization data. String.\n",
        "    output_path=OUTPUT_OPTIMIZATION_RUN_URI,  # Cloud Storage URI to save optimization results. String.\n",
        "    project=PROJECT_ID,  # Google Cloud project ID. String.\n",
        "    # (Optional) Advanced configuration\n",
        "    num_steps=10,  # Number of iterations in instruction optimization mode. Integer between 10 and 20.\n",
        "    num_demo_set_candidates=10,  # Number of demonstrations evaluated in instruction and instruction_and_demo mode. Integer between 10 and 30.\n",
        "    demo_set_size=3,  # Number of demonstrations generated per prompt. Integer between 3 and 6.\n",
        "    target_model_location=\"us-central1\",  # Location of the target model. String. Default us-central1.\n",
        "    source_model=\"\",  # Google model that the system instructions and prompts were previously used with. String. Not needed if you provide target column.\n",
        "    source_model_location=\"\",  # Location of the source model. String. Default us-central1. Not needed if you provide target column.\n",
        "    target_model_qps=1,  # The queries per second (QPS) sent to the target model. Integer greater or equal than 1 depending on your quota.\n",
        "    optimizer_model_qps=1,  # The queries per second (QPS) sent to the optimization model. Integer greater or equal than 1 depending on your quota.\n",
        "    eval_qps=1,  # The queries per second (QPS) sent to the eval model. Integer greater or equal than 1 depending on your quota.\n",
        "    source_model_qps=\"\",  # The queries per second (QPS) sent to the source model. Integer greater or equal than 1 depending on your quota.\n",
        "    response_mime_type=\"text/plain\",  # MIME response type that the target model uses. String. Supported response: text/plain, text/x.enum, application/json.\n",
        "    response_schema=\"\",  # The Vertex AI's Controlled Generation response schema that the target model uses to generate answers. String.\n",
        "    language=\"English\",  # Language of the system instructions. String. Supported languages: \"English\", \"French\", \"German\", \"Hebrew\", \"Hindi\", \"Italian\", \"Japanese\", \"Korean\", \"Portuguese\", \"Simplified Chinese\", \"Spanish\", \"Traditional Chinese\"\n",
        "    placeholder_to_content=json.loads(\n",
        "        \"{}\"\n",
        "    ),  # Placeholder to replace any parameter in the system instruction. Dict.\n",
        "    data_limit=10,  # Amount of data used for validation. Integer between 5 and 100.\n",
        "    translation_source_field_name=\"\",  # Fill in with the corresponding field name of the source text in the data if translation metrics like Comet or MetricX are selected. Otherwise, leave it as empty.\n",
        "    has_multimodal_inputs=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd_uzQYQx6L7"
      },
      "source": [
        "#### Upload Vertex AI prompt optimizer config to Cloud Storage\n",
        "\n",
        "After define the Vertex AI prompt optimizer configuration, upload them on Cloud Storage bucket.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqiv8ApR_SAM"
      },
      "outputs": [],
      "source": [
        "args = vars(args)\n",
        "\n",
        "with epath.Path(CONFIG_FILE_URI).open(\"w\") as config_file:\n",
        "    json.dump(args, config_file)\n",
        "config_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spqgBT8hYAle"
      },
      "source": [
        "#### Run the automatic prompt optimization job\n",
        "\n",
        "Now you are ready to run your first Vertex AI prompt optimizer job using the Vertex AI SDK for Python.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmuRfNlCHuiw"
      },
      "source": [
        "> This prompt optimization job requires ~ 40 minutes to run.\n",
        "\n",
        "> Be sure you have provisioned enough queries per minute (QPM) quota implementing the recommended QPM for each model. If you configure the Vertex AI prompt optimizer with a QPM that is higher than the QPM than you have access to, the job might fail. [Check out](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer#before-you-begin) the documentation to know more.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtPnvKIpUQ3q"
      },
      "outputs": [],
      "source": [
        "WORKER_POOL_SPECS = [\n",
        "    {\n",
        "        \"machine_spec\": {\n",
        "            \"machine_type\": \"n1-standard-4\",\n",
        "        },\n",
        "        \"replica_count\": 1,\n",
        "        \"container_spec\": {\n",
        "            \"image_uri\": APD_CONTAINER_URI,\n",
        "            \"args\": [\"--config=\" + CONFIG_FILE_URI],\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "custom_job = aiplatform.CustomJob(\n",
        "    display_name=PROMPT_OPTIMIZATION_JOB,\n",
        "    worker_pool_specs=WORKER_POOL_SPECS,\n",
        ")\n",
        "\n",
        "custom_job.run(service_account=SERVICE_ACCOUNT, sync=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YwwKBhtJ4ut"
      },
      "source": [
        "### Collect and display the optimization results\n",
        "\n",
        "Vertex AI prompt optimizer returns both optimized templates and evaluation results for either instruction, or demostrations, or both depending on the optimization mode you define as JSONL files on Cloud Storage bucket. Those results help you understand the optimization process.\n",
        "\n",
        "In this case, you want to collect the optimized templates and evaluation results for the system instruction.\n",
        "\n",
        "Below you use a helper function to display those results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6ohF0LJIhvU"
      },
      "outputs": [],
      "source": [
        "results_ui = vapo_lib.ResultsUI(OUTPUT_OPTIMIZATION_RUN_URI)\n",
        "results_df_html = \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(results_df_html))\n",
        "display(results_ui.get_container())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrMrbcA5Gzep"
      },
      "source": [
        "### Examine the new prompt template with the optimized instruction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGRELw3U3I28"
      },
      "source": [
        "#### Generate new responses using the optimized system instruction.\n",
        "\n",
        "Set the optimized system instruction template you get from Vertex AI prompt optimizer job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVamCk10KYHu"
      },
      "outputs": [],
      "source": [
        "OPTIMIZED_SYSTEM_INSTRUCTION_TEMPLATE = \"Analyze the provided image carefully and extract all relevant information, including labels, measurements, and geometric relationships. Use this extracted information to solve the problem. Solve the problem given the image.\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U79bZ_KTM6T"
      },
      "source": [
        "Prepare optimized prompts using the optimized system instruction template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXDU_ydAG5ak"
      },
      "outputs": [],
      "source": [
        "OPTIMIZED_PROMPT_TEMPLATE = (\n",
        "    OPTIMIZED_SYSTEM_INSTRUCTION_TEMPLATE\n",
        "    + \"\\nProblem: {query}\"\n",
        "    + \"\\nImage: {image} @@@image/jpeg\"\n",
        "    + \"\\nAnswer:\"\n",
        ")\n",
        "\n",
        "optimized_prompts = [\n",
        "    OPTIMIZED_PROMPT_TEMPLATE.format(query=q, image=i)\n",
        "    for q, i in zip(\n",
        "        test_prompt_optimization_df.loc[:, \"query\"].to_list(),\n",
        "        test_prompt_optimization_df.loc[:, \"image\"].to_list(),\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sofPH74kT165"
      },
      "source": [
        "Leverage Gemini API on Vertex AI to send parallel generation requests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG6QJW8alttS"
      },
      "outputs": [],
      "source": [
        "gemini_llm = vapo_lib.init_new_model(model_name=\"gemini-1.5-flash-001\")\n",
        "\n",
        "gemini_predictions = [\n",
        "    vapo_lib.async_generate(p, model=gemini_llm) for p in optimized_prompts\n",
        "]\n",
        "\n",
        "gemini_predictions_col = await tqdm_asyncio.gather(*gemini_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEVi8m4gUMqP"
      },
      "source": [
        "Prepare the test data and visualize the resulting dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8khmj0oATV7O"
      },
      "outputs": [],
      "source": [
        "test_prompt_optimization_df[\"optimized_prompt_with_vapo\"] = optimized_prompts\n",
        "test_prompt_optimization_df[\"gemini_answer_with_vapo\"] = gemini_predictions_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s2pAKq4TaiJ"
      },
      "outputs": [],
      "source": [
        "vapo_lib.print_df_rows(test_prompt_optimization_df, n=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZY77CxTlgd9"
      },
      "source": [
        "#### To evaluate the prompt template, follow the method outlined in other notebooks such as [gemini/evaluation/evaluate_multimodal_task_image.ipynb](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/evaluate_multimodal_task_image.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a4e033321ad"
      },
      "source": [
        "## 4. Clean up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRY_3wh1GVNm"
      },
      "outputs": [],
      "source": [
        "delete_bucket = False\n",
        "delete_job = False\n",
        "delete_experiment = False\n",
        "delete_tutorial = False\n",
        "\n",
        "if delete_bucket:\n",
        "    ! gsutil rm -r $BUCKET_URI\n",
        "\n",
        "if delete_job:\n",
        "    custom_job.delete()\n",
        "\n",
        "if delete_experiment:\n",
        "    experiment = aiplatform.Experiment(experiment_name=EXPERIMENT_NAME)\n",
        "    experiment.delete()\n",
        "\n",
        "if delete_tutorial:\n",
        "    import shutil\n",
        "\n",
        "    shutil.rmtree(str(TUTORIAL_PATH))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "vertex_ai_prompt_optimizer_sdk_multimodal_image.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
