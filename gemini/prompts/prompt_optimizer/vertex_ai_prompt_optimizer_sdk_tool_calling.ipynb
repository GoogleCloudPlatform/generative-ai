{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Vertex Prompt Optimizer Notebook SDK (Preview) - Tool usage\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_tool_calling.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fprompts%2Fprompt_optimizer%2Fvertex_ai_prompt_optimizer_sdk_tool_calling.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_tool_calling.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_tool_calling.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_tool_calling.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_tool_calling.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_tool_calling.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/X_logo_2023_original.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_tool_calling.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vertex_ai_prompt_optimizer_sdk_tool_calling.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ccc35a93b9f"
      },
      "source": [
        "| | | |\n",
        "|-|-|-|\n",
        "| Author | [Ivan Nardini](https://github.com/inardini)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "##  I. Overview\n",
        "\n",
        "When developing Generative AI (Gen AI) applications, prompt engineering poses challenges due to its time-consuming and error-prone nature. Significant effort is involved when crafting and inputting prompts to achieve successful task completion. With the frequent release of foundational models, you face the added burden of migrating working prompts from one model version to another.\n",
        "\n",
        "Vertex AI prompt optimizer alleviates these challenges by providing an intelligent prompt optimization tool. With this tool you can both translate and optimize system instructions in the prompts and best demonstrations (examples) for prompt templates, which lets you shape LLM responses from any source model to a target Google model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HKyj5KwYePX"
      },
      "source": [
        "### Objective\n",
        "\n",
        "This notebook demonstrates how to leverage Vertex AI prompt optimizer to optimize for tool usage with a Gemini model. The goal is to use Vertex AI prompt optimizer to find a new prompt template which improves the model's ability to predict valid tool (function) calls given user's request.\n",
        "\n",
        "This tutorial uses the following Google Cloud services and resources:\n",
        "\n",
        "- Generative AI on Vertex AI\n",
        "- Vertex AI prompt optimizer\n",
        "- Vertex AI Gen AI evaluation\n",
        "- Vertex AI Custom job\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "1. Define the prompt template you want to optimize.\n",
        "2. Prepare the prompt optimization dataset.\n",
        "3. Configure tool function settings and validate them.\n",
        "4. Set optimization mode and steps.\n",
        "5. Run the automatic prompt optimization job.\n",
        "6. Collect the best prompt template and eval metric.\n",
        "7. Validate the best prompt template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08d289fa873f"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "The dataset is a question-answering dataset generated by a simple AI financial assistant that provides information about the top 25 Tech companies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed92deeb4a0"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## II. Before you start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet 'google-cloud-aiplatform[evaluation]'\n",
        "%pip install --upgrade --quiet 'plotly' 'asyncio' 'tqdm' 'tenacity' 'etils' 'importlib_resources' 'fsspec' 'gcsfs' 'nbformat>=4.2.0' 'jsonschema'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e55e2195ce2d"
      },
      "outputs": [],
      "source": [
        "! mkdir -p ./tutorial/utils && wget https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/prompts/prompt_optimizer/vapo_lib.py -P ./tutorial/utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "\n",
        "# if \"google.colab\" in sys.modules:\n",
        "#     from google.colab import auth\n",
        "\n",
        "#     auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the following APIs](https://console.cloud.google.com/flows/enableapi?apiid=cloudresourcemanager.googleapis.com,aiplatform.googleapis.com,cloudfunctions.googleapis.com,run.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### Set your project ID and project number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZpm-sL8f1z_"
      },
      "outputs": [],
      "source": [
        "PROJECT_NUMBER = !gcloud projects describe {PROJECT_ID} --format=\"get(projectNumber)\"[0]\n",
        "PROJECT_NUMBER = PROJECT_NUMBER[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6FmBV2_0fBP"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "#### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n",
        "\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIq7R4HZCfIc"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "set_service_account"
      },
      "source": [
        "#### Service Account and permissions\n",
        "\n",
        "Vertex AI Prompt optimizer requires a service account with the following permissions:\n",
        "\n",
        "-   `Vertex AI User` to call Vertex LLM API\n",
        "-   `Storage Object Admin` to read and write to your GCS bucket.\n",
        "\n",
        "[Check out the documentation](https://cloud.google.com/iam/docs/manage-access-service-accounts#iam-view-access-sa-gcloud) to learn how to grant those permissions to a single service account.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNRKI99_QtGR"
      },
      "source": [
        "> If you run following commands using Vertex AI Workbench, please directly run in the terminal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssUJJqXJJHgC"
      },
      "outputs": [],
      "source": [
        "SERVICE_ACCOUNT = f\"{PROJECT_NUMBER}-compute@developer.gserviceaccount.com\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqOHg5aid6HP"
      },
      "outputs": [],
      "source": [
        "for role in ['aiplatform.user', 'storage.objectAdmin']:\n",
        "\n",
        "    ! gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "      --member=serviceAccount:{SERVICE_ACCOUNT} \\\n",
        "      --role=roles/{role} --condition=None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek1-iTbPjzdJ"
      },
      "source": [
        "### Set workspace\n",
        "\n",
        "Set a workspace to store prompt optimization results on Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joJPc3FmX1fk"
      },
      "outputs": [],
      "source": [
        "from etils import epath\n",
        "\n",
        "WORKSPACE_URI = epath.Path(BUCKET_URI) / \"optimization\"\n",
        "INPUT_DATA_URI = epath.Path(WORKSPACE_URI) / \"data\"\n",
        "\n",
        "WORKSPACE_URI.mkdir(parents=True, exist_ok=True)\n",
        "INPUT_DATA_URI.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "# Tutorial\n",
        "from argparse import Namespace\n",
        "import json\n",
        "\n",
        "# General\n",
        "import logging\n",
        "from typing import Any\n",
        "import warnings\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "from google.cloud import aiplatform\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tutorial.utils import vapo_lib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "820DIvw1o8tB"
      },
      "source": [
        "### Libraries settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKc4ZdUBo_SM"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"urllib3.connectionpool\").setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxc7q4r-DFH4"
      },
      "source": [
        "### Define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y5t67f3DHNm"
      },
      "outputs": [],
      "source": [
        "INPUT_DATA_FILE_URI = (\n",
        "    \"gs://github-repo/prompts/prompt_optimizer/qa_tool_calls_dataset.jsonl\"\n",
        ")\n",
        "\n",
        "INPUT_OPTIMIZATION_DATA_URI = epath.Path(WORKSPACE_URI) / \"prompt_optimization_data\"\n",
        "INPUT_OPTIMIZATION_DATA_FILE_URI = str(\n",
        "    INPUT_DATA_URI / \"prompt_optimization_dataset.jsonl\"\n",
        ")\n",
        "OUTPUT_OPTIMIZATION_DATA_URI = epath.Path(WORKSPACE_URI) / \"optimization_jobs\"\n",
        "APD_CONTAINER_URI = (\n",
        "    \"us-docker.pkg.dev/vertex-ai-restricted/builtin-algorithm/apd:preview_v1_0\"\n",
        ")\n",
        "CONFIG_FILE_URI = str(WORKSPACE_URI / \"config\" / \"config.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVVkBruaULtp"
      },
      "source": [
        "### Set helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_D--hDZUQPx"
      },
      "outputs": [],
      "source": [
        "def get_company_information_api(content: dict[str, Any]) -> str:\n",
        "    \"A function to simulate an API call to collect company information.\"\n",
        "\n",
        "    company_overviews = {\n",
        "        \"AAPL\": \"Apple maintains a robust financial position with substantial cash reserves and consistent profitability, fueled by its strong brand and loyal customer base. However, growth is slowing and the company faces competition.\",\n",
        "        \"ADBE\": \"Adobe financials are robust, driven by its successful transition to a subscription-based model for its creative and document cloud software.  Profitability and revenue growth are strong.\",\n",
        "        \"AMD\": \"AMD exhibits strong financial performance, gaining market share in the CPU and GPU markets.  Revenue growth and profitability are healthy, driven by strong product offerings.\",\n",
        "        \"AMZN\": \"Amazon financials are mixed, with its e-commerce business facing margin pressure while its cloud computing division (AWS) delivers strong profitability and growth. Its overall revenue remains high but profitability is a concern.\",\n",
        "        \"ASML\": \"ASML boasts a strong financial position due to its monopoly in the extreme ultraviolet lithography market, essential for advanced semiconductor manufacturing.  High profitability and growth are key strengths.\",\n",
        "        \"AVGO\": \"Broadcom maintains healthy financials, driven by its semiconductor and infrastructure software solutions. Acquisitions have played a role in its growth strategy, with consistent profitability and cash flow.\",\n",
        "        \"BABA\": \"Alibaba financials are substantial but facing challenges from regulatory scrutiny in China and increased competition.  E-commerce revenue remains strong but growth is slowing.\",\n",
        "        \"BKNG\": \"Booking Holdings financials are closely tied to the travel industry.  Revenue growth is recovering post-pandemic but profitability can fluctuate based on global travel trends.\",\n",
        "        \"CRM\": \"Salesforce shows robust revenue growth from its cloud-based CRM solutions.  Profitability is improving but competition remains strong.\",\n",
        "        \"CSCO\": \"Cisco financials show moderate growth, transitioning from hardware to software and services.  Profitability is stable but the company faces competition in the networking market.\",\n",
        "        \"GOOGL\": \"Alphabet exhibits strong financials driven by advertising revenue, though facing regulatory scrutiny.  Diversification into other ventures provides growth opportunities but profitability varies.\",\n",
        "        \"IBM\": \"IBM financials are in a state of transformation, shifting focus to hybrid cloud and AI.  Revenue growth is modest, with profitability impacted by legacy businesses.\",\n",
        "        \"INTU\": \"Intuit showcases healthy financials, benefiting from its strong position in tax and financial management software.  Revenue growth and profitability are consistent, fueled by recurring subscription revenue.\",\n",
        "        \"META\": \"Meta Platforms financial performance is tied closely to advertising revenue, facing headwinds from competition and changing privacy regulations.  Investments in the metaverse represent a long-term, high-risk bet.\",\n",
        "        \"MSFT\": \"Microsoft demonstrates healthy financials, benefiting from diversified revenue streams including cloud computing (Azure), software, and hardware.  The company exhibits consistent growth and profitability.\",\n",
        "        \"NFLX\": \"Netflix exhibits strong revenue but faces challenges in maintaining subscriber growth and managing content costs. Profitability varies, and competition in the streaming market is intense.\",\n",
        "        \"NOW\": \"ServiceNow demonstrates strong financials, fueled by its cloud-based workflow automation platform.  Revenue growth and profitability are high, reflecting increased enterprise adoption.\",\n",
        "        \"NVDA\": \"NVIDIA boasts strong financials, driven by its dominance in the GPU market for gaming, AI, and data centers.  High revenue growth and profitability are key strengths.\",\n",
        "        \"ORCL\": \"Oracle financials are in transition, shifting towards cloud-based services. Revenue growth is moderate, and profitability remains stable.  Legacy businesses still contribute significantly.\",\n",
        "        \"QCOM\": \"QUALCOMM financials show strong performance driven by its leadership in mobile chipsets and licensing.  Profitability is high, and growth is tied to the mobile market and 5G adoption.\",\n",
        "        \"SAP\": \"SAP demonstrates steady financials with its enterprise software solutions.  Transition to the cloud is ongoing and impacting revenue growth and profitability.\",\n",
        "        \"SMSN\": \"Samsung financials are diverse, reflecting its presence in various sectors including mobile phones, consumer electronics, and semiconductors. Profitability varies across divisions but the company holds significant cash reserves.\",\n",
        "        \"TCEHY\": \"Tencent financials are driven by its dominant position in the Chinese gaming and social media market. Revenue growth is strong but regulatory risks in China impact its performance.\",\n",
        "        \"TSLA\": \"Tesla financials show strong revenue growth driven by electric vehicle demand, but profitability remains volatile due to production and investment costs. The company high valuation reflects market optimism for future growth.\",\n",
        "        \"TSM\": \"TSMC, a dominant player in semiconductor manufacturing, showcases robust financials fueled by high demand for its advanced chips. Profitability is strong and the company enjoys a technologically advanced position.\",\n",
        "    }\n",
        "    return company_overviews.get(content[\"ticker\"], \"No company overwiew found\")\n",
        "\n",
        "\n",
        "def get_stock_price_api(content: dict[str, Any]) -> str:\n",
        "    \"A function to simulate an API call to collect most recent stock price for a given company.\"\n",
        "    stock_prices = {\n",
        "        \"AAPL\": 225,\n",
        "        \"ADBE\": 503,\n",
        "        \"AMD\": 134,\n",
        "        \"AMZN\": 202,\n",
        "        \"ASML\": 658,\n",
        "        \"AVGO\": 164,\n",
        "        \"BABA\": 88,\n",
        "        \"BKNG\": 4000,\n",
        "        \"CRM\": 325,\n",
        "        \"CSCO\": 57,\n",
        "        \"GOOGL\": 173,\n",
        "        \"IBM\": 201,\n",
        "        \"INTU\": 607,\n",
        "        \"META\": 553,\n",
        "        \"MSFT\": 415,\n",
        "        \"NFLX\": 823,\n",
        "        \"NOW\": 1000,\n",
        "        \"NVDA\": 141,\n",
        "        \"ORCL\": 183,\n",
        "        \"QCOM\": 160,\n",
        "        \"SAP\": 228,\n",
        "        \"SMSN\": 38,\n",
        "        \"TCEHY\": 51,\n",
        "        \"TSLA\": 302,\n",
        "        \"TSM\": 186,\n",
        "    }\n",
        "    return stock_prices.get(content[\"ticker\"], \"No stock price found\")\n",
        "\n",
        "\n",
        "def get_company_news_api(content: dict[str, Any]) -> str:\n",
        "    \"A function to simulate an API call to collect recent news for a given company.\"\n",
        "    news_data = {\n",
        "        \"AAPL\": \"Apple unveils new iPhone, market reaction muted amid concerns about slowing growth.\",\n",
        "        \"ADBE\": \"Adobe integrates AI features into Creative Suite, attracting creative professionals.\",\n",
        "        \"AMD\": \"AMD gains market share in server CPUs, competing with Intel.\",\n",
        "        \"AMZN\": \"Amazon stock dips after reporting lower-than-expected Q3 profits due to increased shipping costs.\",\n",
        "        \"ASML\": \"ASML benefits from high demand for advanced chip manufacturing equipment.\",\n",
        "        \"AVGO\": \"Broadcom announces new acquisition in the semiconductor space.\",\n",
        "        \"BABA\": \"Alibaba stock faces uncertainty amid ongoing regulatory scrutiny in China.\",\n",
        "        \"BKNG\": \"Booking Holdings stock recovers as travel demand rebounds post-pandemic.\",\n",
        "        \"CRM\": \"Salesforce launches new AI-powered CRM tools for enterprise customers.\",\n",
        "        \"CSCO\": \"Cisco stock rises after positive earnings report, focus on networking solutions.\",\n",
        "        \"GOOGL\": \"Alphabet announces new AI-powered search features, aiming to compete with Microsoft.\",\n",
        "        \"IBM\": \"IBM focuses on hybrid cloud solutions, showing steady growth in enterprise segment.\",\n",
        "        \"INTU\": \"Intuit stock dips after announcing price increases for its tax software.\",\n",
        "        \"META\": \"Meta shares rise after positive user growth figures in emerging markets.\",\n",
        "        \"MSFT\": \"Microsoft expands AI integration across its product suite, boosting investor confidence.\",\n",
        "        \"NFLX\": \"Netflix subscriber growth slows, competition heats up in streaming landscape.\",\n",
        "        \"NOW\": \"ServiceNow sees strong growth in its cloud-based workflow automation platform.\",\n",
        "        \"NVDA\": \"Nvidia stock jumps on strong earnings forecast, driven by AI demand.\",\n",
        "        \"ORCL\": \"Oracle cloud revenue continues strong growth, exceeding market expectations.\",\n",
        "        \"QCOM\": \"Qualcomm expands its 5G modem business, partnering with major smartphone manufacturers.\",\n",
        "        \"SAP\": \"SAP cloud transition continues, but faces challenges in attracting new clients.\",\n",
        "        \"SMSN\": \"Samsung unveils new foldable phones, looking to gain market share.\",\n",
        "        \"TCEHY\": \"Tencent faces regulatory pressure in China, impacting investor sentiment.\",\n",
        "        \"TSLA\": \"Tesla stock volatile after price cuts and production increases announced.\",\n",
        "        \"TSM\": \"TSMC reports record chip demand but warns of potential supply chain disruptions.\",\n",
        "    }\n",
        "    return news_data.get(content[\"ticker\"], \"No news available\")\n",
        "\n",
        "\n",
        "def get_company_sentiment_api(content: dict[str, Any]) -> str:\n",
        "    \"A function to simulate an API call to collect market company sentiment for a given company.\"\n",
        "\n",
        "    company_sentiment = {\n",
        "        \"AAPL\": \"Neutral\",\n",
        "        \"ADBE\": \"Neutral\",\n",
        "        \"AMD\": \"Neutral\",\n",
        "        \"AMZN\": \"Neutral\",\n",
        "        \"ASML\": \"Bearish/Undervalued\",\n",
        "        \"AVGO\": \"Neutral\",\n",
        "        \"BABA\": \"Neutral\",\n",
        "        \"BKNG\": \"Neutral\",\n",
        "        \"CRM\": \"Neutral\",\n",
        "        \"CSCO\": \"Neutral\",\n",
        "        \"GOOGL\": \"Neutral\",\n",
        "        \"IBM\": \"Neutral\",\n",
        "        \"INTU\": \"Mixed/Bullish\",\n",
        "        \"META\": \"Neutral\",\n",
        "        \"MSFT\": \"Neutral\",\n",
        "        \"NFLX\": \"Neutral\",\n",
        "        \"NOW\": \"Bullish/Overvalued\",\n",
        "        \"NVDA\": \"Neutral\",\n",
        "        \"ORCL\": \"Neutral\",\n",
        "        \"QCOM\": \"Neutral\",\n",
        "        \"SAP\": \"Neutral\",\n",
        "        \"SMSN\": \"Neutral\",\n",
        "        \"TCEHY\": \"Neutral\",\n",
        "        \"TSLA\": \"Slightly Overvalued\",\n",
        "        \"TSM\": \"Neutral\",\n",
        "    }\n",
        "    return company_sentiment.get(content[\"ticker\"], \"No sentiment available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQMc2Uwf0fBQ"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdvJRUWRNGHE"
      },
      "source": [
        "## III. Automated prompt design with Vertex AI prompt optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmTotjRAJplw"
      },
      "source": [
        "### Load the dataset\n",
        "\n",
        "Load the AI financial assistant's question-answer dataset from a Google Cloud Storage bucket. The dataset contains the following columns:\n",
        "\n",
        "* **question:** User's query regarding about company.\n",
        "* **tool_names:** Specifies tool names used to answer the question.\n",
        "* **tool_call:** Details the input parameters passed to the specified tools.\n",
        "* **tool_call_response:** Raw output from the tool.\n",
        "* **answer:**  A refined and human-readable response grounded in the tool's output, answering the user's question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA7aG08wJtVm"
      },
      "outputs": [],
      "source": [
        "prompt_optimization_df = pd.read_json(INPUT_DATA_FILE_URI, lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xn-pz3v5HVK"
      },
      "outputs": [],
      "source": [
        "prompt_optimization_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2l7JwuDcPqX"
      },
      "source": [
        "Print an example of the cooking question-answer dataset.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8zgOTZVa6xa"
      },
      "outputs": [],
      "source": [
        "vapo_lib.print_df_rows(prompt_optimization_df, n=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp1n1aMACzSW"
      },
      "source": [
        "### Optimize the prompt template with Vertex AI prompt optimizer with custom metric\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1650lf3X8xW"
      },
      "source": [
        "#### Prepare the prompt template you want to optimize\n",
        "\n",
        "A prompt consists of two key parts:\n",
        "\n",
        "* **System Instruction Template** which is a fixed part of the prompt that control or alter the model's behavior across all queries for a given task.\n",
        "\n",
        "* **Prompt Template** which is a dynamic part of the prompt that changes based on the task. Prompt template includes examples, context, task and more. To learn more, see [components of a prompt](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-design-strategies#components-of-a-prompt) in the official documentation.\n",
        "\n",
        "In this scenario, you use Vertex AI prompt optimizer to optimize a simple system instruction template.\n",
        "\n",
        "And you use some examples in the remaining prompt template for evaluating different instruction templates along the optimization process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_vLpXX2HDe1"
      },
      "source": [
        "> **Note**: Having the `target` placeholder in the prompt template is optional. It represents the prompt's ground truth response in your prompt optimization dataset that you aim to optimize for your templates. If you don't have the prompt's ground truth response, remember to set the `source_model` parameter to your prompt optimizer configuration (see below) instead of adding ground truth responses. Vertex AI prompt optimizer would run your sample prompts on the source model to generate the ground truth responses for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Db8rHNC6DmtY"
      },
      "outputs": [],
      "source": [
        "SYSTEM_INSTRUCTION_TEMPLATE = \"\"\"\n",
        "Answer the question using correct tools.\n",
        "\"\"\"\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Some examples of correct tools associated to a question are:\n",
        "Question: {question}\n",
        "Target tools: {target}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1TCgXsrXztm"
      },
      "source": [
        "#### Prepare the prompt optimization dataset\n",
        "\n",
        "To use Vertex AI prompt optimizer, you'll need a CSV or JSONL file with labeled examples.  These examples should follow a specific naming convention. For details see [Optimize prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYV-fansHMM_"
      },
      "source": [
        "> **Note**: For effective **prompt optimization**, provide a dataset of examples where your model is poor in performance when using current system instruction template. For reliable results, use 50-100 distinct samples.\n",
        "\n",
        "> In case of **prompt migration**, consider using the source model to label examples that the target model struggles with, helping to identify areas for improvement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBWLrWKil6jK"
      },
      "outputs": [],
      "source": [
        "train_prompt_optimization_df, test_prompt_optimization_df = train_test_split(\n",
        "    prompt_optimization_df, test_size=0.3, random_state=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTIl_v9Ig1F-"
      },
      "outputs": [],
      "source": [
        "prepared_train_prompt_optimization_df = train_prompt_optimization_df.copy()\n",
        "\n",
        "# Prepare target column\n",
        "prepared_train_prompt_optimization_df[\"target\"] = (\n",
        "    prepared_train_prompt_optimization_df.apply(vapo_lib.create_target_column, axis=1)\n",
        ")\n",
        "\n",
        "# Remove uneccessary columns\n",
        "prepared_train_prompt_optimization_df = prepared_train_prompt_optimization_df.drop(\n",
        "    columns=[\"tool_names\", \"tool_arguments\", \"tool_call_response\", \"answer\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbTqB2o5ZslT"
      },
      "source": [
        "Print some examples of the prompt optimization dataset.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DUFEAb82eEi"
      },
      "outputs": [],
      "source": [
        "prepared_train_prompt_optimization_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF3XY_d_yB-K"
      },
      "source": [
        "#### Upload samples to bucket\n",
        "\n",
        "Once you prepare your prompt optimization dataset, you can upload them on Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "155paLgGUXOm"
      },
      "outputs": [],
      "source": [
        "prepared_train_prompt_optimization_df.to_json(\n",
        "    INPUT_OPTIMIZATION_DATA_FILE_URI, orient=\"records\", lines=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82VNGt07_erb"
      },
      "source": [
        "#### Configure tool settings and validate them\n",
        "\n",
        "To optimize prompts for using external tools with the Vertex AI SDK, define the tools' functionalities using the `FunctionDeclaration` class. This class uses an OpenAPI-compatible schema to structure the tool definitions.  Your system prompt should be designed to effectively leverage these defined functions.  See the [Introduction to function calling](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling) for more information.  \n",
        "\n",
        "Example function definitions for a financial assistant are provided below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gEJ5Dd9rsOX"
      },
      "outputs": [],
      "source": [
        "get_company_information = FunctionDeclaration(\n",
        "    name=\"get_company_information\",\n",
        "    description=\"Retrieves financial performance to provide an overview for a company.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"ticker\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Stock ticker for a given company\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"ticker\"],\n",
        "    },\n",
        ")\n",
        "\n",
        "get_stock_price = FunctionDeclaration(\n",
        "    name=\"get_stock_price\",\n",
        "    description=\"Only returns the current stock price (in dollars) for a company.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"ticker\": {\n",
        "                \"type\": \"integer\",\n",
        "                \"description\": \"Stock ticker for a company\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"ticker\"],\n",
        "    },\n",
        ")\n",
        "\n",
        "get_company_news = FunctionDeclaration(\n",
        "    name=\"get_company_news\",\n",
        "    description=\"Get the latest news headlines for a given company.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"ticker\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Stock ticker for a company.\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"ticker\"],\n",
        "    },\n",
        ")\n",
        "\n",
        "get_company_sentiment = FunctionDeclaration(\n",
        "    name=\"get_company_sentiment\",\n",
        "    description=\"Returns the overall market sentiment for a company.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"ticker\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Stock ticker for a company\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"ticker\"],\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52T9TTwu4LbW"
      },
      "source": [
        "After implementing your functions, wrap each one as a `Tool` object. This allows the Gemini model to discover and execute these functions.  `ToolConfig` provides additional parameters to control how the model interacts with the tools and chooses which function to call.  \n",
        "\n",
        "Further information can be found in the [Introduction to function calling](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq9M_-jt4KoB"
      },
      "outputs": [],
      "source": [
        "tools = Tool(\n",
        "    function_declarations=[\n",
        "        get_company_information,\n",
        "        get_stock_price,\n",
        "        get_company_news,\n",
        "        get_company_sentiment,\n",
        "    ]\n",
        ")\n",
        "\n",
        "tool_config = ToolConfig(\n",
        "    function_calling_config=ToolConfig.FunctionCallingConfig(\n",
        "        mode=ToolConfig.FunctionCallingConfig.Mode.ANY,\n",
        "        allowed_function_names=[\n",
        "            \"get_company_information\",\n",
        "            \"get_stock_price\",\n",
        "            \"get_company_news\",\n",
        "            \"get_company_sentiment\",\n",
        "        ],\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nMEMYU6sNUA"
      },
      "source": [
        "To use Vertex AI Prompt Optimizer for tool calling optimization, provide `FunctionDeclaration` and `ToolConfig` as JSON structures (see example below). Vertex AI Prompt Optimizer uses those structures along the optimization process.\n",
        "\n",
        "Tool Calls json:\n",
        "```\n",
        "{\"tools\": [{\"function_declarations\": [{\"name\": \"function_1\", \"description\": \"My function 1\", \"parameters\": {\"type\": \"OBJECT\", \"properties\": {\"argument_1\": {\"type\": \"STRING\", \"description\": \"My argument 1\"}}, \"required\": [\"argument_1\"], \"property_ordering\": [\"argument_1\"]}}, ...]}]}\n",
        "```\n",
        "Function Calling Configuration json:\n",
        "```\n",
        "{\"function_calling_config\": {\"mode\": \"your_mode\", \"allowed_function_names\": [\"tool_name_1\", ...]}}\n",
        "```\n",
        "\n",
        "Below you have some helper functions to get those structures and validate them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxHLX921xdHJ"
      },
      "outputs": [],
      "source": [
        "vapo_tools = json.dumps({\"tools\": [vapo_lib.replace_type_key(tools.to_dict())]})\n",
        "\n",
        "vapo_tool_config = json.dumps(vapo_lib.tool_config_to_dict(tool_config))\n",
        "\n",
        "vapo_lib.validate_tools(vapo_tools)\n",
        "vapo_lib.validate_tool_config(vapo_tool_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5RD0l2xX-FI"
      },
      "source": [
        "#### Configure optimization settings\n",
        "\n",
        "Vertex AI prompt optimizer lets you control the optimization process by specifying what to optimize (instructions only, demonstrations only, or both), providing a system instruction and prompt template, and selecting the target model.  You can optionally refine the optimization with some advanced settings like its duration and the number of optimization iterations it runs, which models the Vertex AI prompt optimizer uses, and other parameters to control the structure and content of prompts. Below you have some common and recommended default configurations.\n",
        "\n",
        "In this scenario, you set two additional parameters:\n",
        "\n",
        "* `tools` parameter to pass tool definitions\n",
        "\n",
        "* `tool_config` parameter to pass tool configuration\n",
        "\n",
        "For more advanced control, you can learn and explore more about all the parameters and how to best use them in the [detailed documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFHutXhgeqRx"
      },
      "outputs": [],
      "source": [
        "PROMPT_OPTIMIZATION_JOB = \"auto-prompt-design-job-\" + vapo_lib.get_id()\n",
        "OUTPUT_OPTIMIZATION_RUN_URI = str(\n",
        "    OUTPUT_OPTIMIZATION_DATA_URI / PROMPT_OPTIMIZATION_JOB\n",
        ")\n",
        "\n",
        "args = Namespace(\n",
        "    # Basic configuration\n",
        "    system_instruction=SYSTEM_INSTRUCTION_TEMPLATE,  # System instructions for the target model. String.\n",
        "    prompt_template=PROMPT_TEMPLATE,  # Template for prompts,  String.\n",
        "    target_model=\"gemini-1.5-flash-001\",  # Target model for optimization. String. Supported models: \"gemini-1.5-flash-002\", \"gemini-1.5-pro-002\", \"gemini-1.5-flash-001\", \"gemini-1.5-pro-001\", \"gemini-1.0-pro-001\", \"gemini-1.0-pro-002\", \"gemini-1.0-ultra-001\", \"text-bison@001\", \"text-bison@002\", \"text-bison32k@002\", \"text-unicorn@001\"\n",
        "    optimization_mode=\"instruction\",  # Optimization mode. String. Supported modes: \"instruction\", \"demonstration\", \"instruction_and_demo\"\n",
        "    tools=vapo_tools,\n",
        "    tool_config=vapo_tool_config,\n",
        "    eval_metrics_types=[\n",
        "        \"tool_name_match\",\n",
        "        \"tool_parameter_key_match\",\n",
        "        \"tool_parameter_kv_match\",\n",
        "    ],  # List of evaluation metrics. List of strings. Supported metrics: \"bleu\", \"coherence\", \"exact_match\", \"fluidity\", \"fulfillment\", \"groundedness\", \"rouge_1\", \"rouge_2\", \"rouge_l\", \"rouge_l_sum\", \"safety\", \"question_answering_correctness\", \"question_answering_helpfulness\", \"question_answering_quality\", \"question_answering_relevance\", \"summarization_helpfulness\", \"summarization_quality\", \"summarization_verbosity\", \"tool_name_match\", \"tool_parameter_key_match\", \"tool_parameter_kv_match\"\n",
        "    eval_metrics_weights=[\n",
        "        0.4,\n",
        "        0.3,\n",
        "        0.3,\n",
        "    ],  # Weights for evaluation metrics. List of floats.  Length must match eval_metrics_types.  Should sum to 1.\n",
        "    aggregation_type=\"weighted_sum\",  # Aggregation type for evaluation metrics. String. Supported aggregation types: \"weighted_sum\", \"weighted_average\"\n",
        "    input_data_path=INPUT_OPTIMIZATION_DATA_FILE_URI,  # Cloud Storage URI to input optimization data. String.\n",
        "    output_path=OUTPUT_OPTIMIZATION_RUN_URI,  # Cloud Storage URI to save optimization results. String.\n",
        "    project=PROJECT_ID,  # Google Cloud project ID. String.\n",
        "    # (Optional) Advanced configuration\n",
        "    num_steps=10,  # Number of iterations in instruction optimization mode. Integer between 10 and 20.\n",
        "    num_template_eval_per_step=2,  # Number of system instructions generated and evaluated in instruction and instruction_and_demo mode. Integer between 1 and 4.\n",
        "    num_demo_set_candidates=10,  # Number of demonstrations evaluated in instruction and instruction_and_demo mode. Integer between 10 and 30.\n",
        "    demo_set_size=3,  # Number of demonstrations generated per prompt. Integer between 3 and 6.\n",
        "    target_model_location=\"us-central1\",  # Location of the target model. String. Default us-central1.\n",
        "    optimizer_model=\"gemini-1.5-pro-001\",  # Optimization model. String. Supported models: \"gemini-1.5-flash-002\", \"gemini-1.5-pro-002\", \"gemini-1.5-flash-001\", \"gemini-1.5-pro-001\", \"gemini-1.0-pro-001\", \"gemini-1.0-pro-002\", \"gemini-1.0-ultra-001\", \"text-bison@001\", \"text-bison@002\", \"text-bison32k@002\", \"text-unicorn@001\"\n",
        "    optimizer_model_location=\"us-central1\",  # Location of the optimization model. String. Default us-central1.\n",
        "    eval_model=\"gemini-1.5-pro-001\",  # Evaluation model. String. Supported models: \"gemini-1.5-flash-002\", \"gemini-1.5-pro-002\", \"gemini-1.5-flash-001\", \"gemini-1.5-pro-001\", \"gemini-1.0-pro-001\", \"gemini-1.0-pro-002\", \"gemini-1.0-ultra-001\", \"text-bison@001\", \"text-bison@002\", \"text-bison32k@002\", \"text-unicorn@001\"\n",
        "    eval_model_location=\"us-central1\",  # Location of the evaluation model. String. Default us-central1.\n",
        "    source_model=\"\",  # Google model that the system instructions and prompts were previously used with. String. Not needed if you provide target column.\n",
        "    source_model_location=\"\",  # Location of the source model. String. Default us-central1. Not needed if you provide target column.\n",
        "    target_model_qps=1,  # The queries per second (QPS) sent to the target model. Integer greater or equal than 1 depending on your quota.\n",
        "    optimizer_model_qps=1,  # The queries per second (QPS) sent to the optimization model. Integer greater or equal than 1 depending on your quota.\n",
        "    eval_qps=1,  # The queries per second (QPS) sent to the eval model. Integer greater or equal than 1 depending on your quota.\n",
        "    source_model_qps=\"\",  # The queries per second (QPS) sent to the source model. Integer greater or equal than 1 depending on your quota.\n",
        "    response_mime_type=\"text/plain\",  # MIME response type that the target model uses. String. Supported response: text/plain, application/json.\n",
        "    response_schema=\"\",  # Response schema that the target model uses to generate answers. String.\n",
        "    language=\"English\",  # Language of the system instructions. String. Supported languages: \"English\", \"French\", \"German\", \"Hebrew\", \"Hindi\", \"Japanese\", \"Korean\", \"Portuguese\", \"Simplified Chinese\", \"Spanish\", \"Traditional Chinese\"\n",
        "    placeholder_to_content=json.loads(\n",
        "        \"{}\"\n",
        "    ),  # Placeholder to replace any parameter in the system instruction. Dict.\n",
        "    data_limit=50,  # Amount of data used for validation. Integer between 5 and 100.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd_uzQYQx6L7"
      },
      "source": [
        "#### Upload Vertex AI prompt optimizer Cloud Storage\n",
        "\n",
        "After you define Vertex AI prompt optimizer configuration, you upload them on Cloud Storage bucket.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqiv8ApR_SAM"
      },
      "outputs": [],
      "source": [
        "args = vars(args)\n",
        "\n",
        "with epath.Path(CONFIG_FILE_URI).open(\"w\") as config_file:\n",
        "    json.dump(args, config_file)\n",
        "config_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spqgBT8hYAle"
      },
      "source": [
        "#### Run the automatic prompt optimization job\n",
        "\n",
        "Now you are ready to run your first Vertex AI prompt optimizer job using the Vertex AI SDK for Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlNQ_UrFH9ne"
      },
      "source": [
        "> This prompt optimization job requires ~ 40 minutes to run.\n",
        "\n",
        "> Be sure you have provisioned enough queries per minute (QPM) quota implementing the recommended QPM for each model. If you configure the Vertex AI prompt optimizer with a QPM that is higher than the QPM than you have access to, the job might fail. [Check out](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer#before-you-begin) the documentation to know more.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtPnvKIpUQ3q"
      },
      "outputs": [],
      "source": [
        "WORKER_POOL_SPECS = [\n",
        "    {\n",
        "        \"machine_spec\": {\n",
        "            \"machine_type\": \"n1-standard-4\",\n",
        "        },\n",
        "        \"replica_count\": 1,\n",
        "        \"container_spec\": {\n",
        "            \"image_uri\": APD_CONTAINER_URI,\n",
        "            \"args\": [\"--config=\" + CONFIG_FILE_URI],\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "custom_job = aiplatform.CustomJob(\n",
        "    display_name=PROMPT_OPTIMIZATION_JOB,\n",
        "    worker_pool_specs=WORKER_POOL_SPECS,\n",
        ")\n",
        "\n",
        "custom_job.submit(service_account=SERVICE_ACCOUNT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YwwKBhtJ4ut"
      },
      "source": [
        "### Collect and display the optimization results\n",
        "\n",
        "Vertex AI prompt optimizer returns both optimized templates and evaluation results for either instruction, or demostrations, or both depending on the optimization mode you define as JSONL files on Cloud Storage bucket. Those results help you understand the optimization process.\n",
        "\n",
        "In this case, you want to collect the optimized templates and evaluation results for the system instruction.\n",
        "\n",
        "Below you use a helper function to display those results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6ohF0LJIhvU"
      },
      "outputs": [],
      "source": [
        "results_ui = vapo_lib.ResultsUI(OUTPUT_OPTIMIZATION_RUN_URI)\n",
        "results_df_html = \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(results_df_html))\n",
        "display(results_ui.get_container())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrMrbcA5Gzep"
      },
      "source": [
        "### Evaluate the quality of generated responses with the optimized instruction\n",
        "\n",
        "Finally, you evaluate generated responses with the optimized instruction qualitatively.\n",
        "\n",
        "If you want to know how to evaluate the new generated responses quantitatively, check out the [`vertex_ai_prompt_optimizer_sdk` notebook](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/prompts/prompt_optimizer) in the official repository.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJK4KD0VkSuz"
      },
      "source": [
        "#### Generate new responses using the optimized system instruction.\n",
        "\n",
        "Set the optimized system instruction template you get from Vertex AI prompt optimizer job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVamCk10KYHu"
      },
      "outputs": [],
      "source": [
        "OPTIMIZED_SYSTEM_INSTRUCTION_TEMPLATE = \"To provide the most accurate response to the given question, determine and employ the most suitable tools.\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U79bZ_KTM6T"
      },
      "source": [
        "Prepare optimized prompts using the optimized system instruction template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfouWkLPkSu1"
      },
      "outputs": [],
      "source": [
        "OPTIMIZED_PROMPT_TEMPLATE = (\n",
        "    OPTIMIZED_SYSTEM_INSTRUCTION_TEMPLATE + \"\\nQuestion: \\n{question}\" + \"\\nAnswer:\"\n",
        ")\n",
        "\n",
        "optimized_prompts = [\n",
        "    OPTIMIZED_PROMPT_TEMPLATE.format(question=q)\n",
        "    for q in zip(\n",
        "        test_prompt_optimization_df[\"question\"].to_list(),\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sofPH74kT165"
      },
      "source": [
        "Leverage Gemini API on Vertex AI to send parallel generation requests.\n",
        "\n",
        "In this scenario, you have to define a function map which allows you to handle function calling in parallel. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZfPgrmZ0jub"
      },
      "outputs": [],
      "source": [
        "function_map = {\n",
        "    \"get_company_information\": get_company_information_api,\n",
        "    \"get_stock_price\": get_stock_price_api,\n",
        "    \"get_company_news\": get_company_news_api,\n",
        "    \"get_company_sentiment\": get_company_sentiment_api,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM5-8FzpkSu1"
      },
      "outputs": [],
      "source": [
        "gemini_llm = vapo_lib.init_new_model(model_name=\"gemini-1.5-flash-001\")\n",
        "\n",
        "gemini_predictions = [\n",
        "    vapo_lib.async_generate(p, gemini_llm, function_map, tools, tool_config)\n",
        "    for p in optimized_prompts\n",
        "]\n",
        "\n",
        "gemini_predictions_col = await tqdm_asyncio.gather(*gemini_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BA9wRQnsHg0"
      },
      "source": [
        "#### Evaluate new responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEVi8m4gUMqP"
      },
      "source": [
        "Prepare the test dataset and inspect new responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8khmj0oATV7O"
      },
      "outputs": [],
      "source": [
        "test_prompt_optimization_df[\"optimized_prompt_with_vapo\"] = optimized_prompts\n",
        "test_prompt_optimization_df[\"gemini_answer_with_vapo\"] = gemini_predictions_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s2pAKq4TaiJ"
      },
      "outputs": [],
      "source": [
        "vapo_lib.print_df_rows(test_prompt_optimization_df, n=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a4e033321ad"
      },
      "source": [
        "## IV. Clean up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRY_3wh1GVNm"
      },
      "outputs": [],
      "source": [
        "delete_bucket = False\n",
        "delete_job = False\n",
        "delete_tutorial = False\n",
        "\n",
        "if delete_bucket:\n",
        "    ! gsutil rm -r {BUCKET_URI}\n",
        "\n",
        "if delete_job:\n",
        "    custom_job.delete()\n",
        "\n",
        "if delete_tutorial:\n",
        "    import shutil\n",
        "\n",
        "    shutil.rmtree(str(TUTORIAL_PATH))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "vertex_ai_prompt_optimizer_sdk_tool_calling.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
