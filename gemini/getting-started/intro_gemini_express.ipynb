{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCIMTPB1WoTq"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yVV6txOmNMn"
      },
      "source": [
        "# Getting started with Gemini using Vertex AI in Express Mode\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_express.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_express.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_express.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_express.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_express.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/X_logo_2023_original.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_express.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_express.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EExYZvij2ve"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Holt Skinner](https://github.com/holtskinner) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1DnOs6rkbOy"
      },
      "source": [
        "## Overview\n",
        "\n",
        "[Vertex AI in express mode](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview) lets you quickly try out core generative AI features that are available on Vertex AI.\n",
        "\n",
        "- Send API requests to the Gemini API in Vertex AI:\n",
        "  - Non-streaming request\n",
        "  - Streaming request\n",
        "  - Function calling request"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Google Gen AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Get an API Key and create client\n",
        "\n",
        "Refer to the [documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview#eligibility) for how to create an API Key for Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "API_KEY = \"[your-api-key]\"  # @param {type: \"string\", placeholder: \"[your-api-key]\" isTemplate: true}\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(vertexai=True, api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXHfaVS66_01"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lslYAvw37JGQ"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "from google.genai.types import (\n",
        "    FunctionDeclaration,\n",
        "    GenerateContentConfig,\n",
        "    SafetySetting,\n",
        "    Tool,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY1nfXrqRxVX"
      },
      "source": [
        "### Load the Gemini 1.5 Flash model\n",
        "\n",
        "To learn more about all [Gemini API models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7ExWmuLBdIA"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-1.5-flash\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9OKM0-4SQf8"
      },
      "source": [
        "## Vertex AI SDK basic usage\n",
        "\n",
        "Below is a simple example that demonstrates how to prompt the Gemini 1.5 Flash model using the Vertex AI SDK. Learn more about the [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini#gemini-pro).\n",
        "\n",
        "You can send either streaming or non-streaming requests to the API.\n",
        "\n",
        "- Streaming requests return the response in chunks as the request is being processed.\n",
        "  - To a human user, streamed responses reduce the perception of latency. \n",
        "- Non-streaming requests return the response in one chunk after the request is processed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f45d58f79eeb"
      },
      "source": [
        "### Streaming request\n",
        "\n",
        "To send a streaming request, use `client.models.generate_content_stream()` and print the response in chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhFxrtfdSwOP"
      },
      "outputs": [],
      "source": [
        "responses = client.models.generate_content_stream(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"\"\"Explain bubble sort to me.\"\"\",\n",
        ")\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94477e81503c"
      },
      "source": [
        "### Non-streaming request\n",
        "\n",
        "The following code sample defines a function that sends a non-streaming request\n",
        "to the `gemini-1.5-flash`.\n",
        "\n",
        "It shows you how to configure basic request parameters and safety settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f9d13a81412"
      },
      "outputs": [],
      "source": [
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        threshold=\"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "        threshold=\"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        threshold=\"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        threshold=\"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "config = GenerateContentConfig(\n",
        "    max_output_tokens=8192,\n",
        "    temperature=1,\n",
        "    top_p=0.95,\n",
        "    safety_settings=safety_settings,\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"\"\"Explain bubble sort to me.\"\"\",\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "735e061b780e"
      },
      "source": [
        "### Function calling request\n",
        "\n",
        "The following code sample outputs the JSON that's required to make a function call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89db04dbdb53"
      },
      "outputs": [],
      "source": [
        "# Specify a function declaration and parameters for an API request.\n",
        "get_current_weather_func = FunctionDeclaration(\n",
        "    name=\"get_current_weather\",\n",
        "    description=\"Get the current weather in a given location\",\n",
        "    # Function parameters are specified in OpenAPI JSON schema format.\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\"location\": {\"type\": \"STRING\", \"description\": \"Location\"}},\n",
        "    },\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the weather in Boston?\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[\n",
        "            # Define a tool that includes the above get_current_weather_func.\n",
        "            Tool(\n",
        "                function_declarations=[get_current_weather_func],\n",
        "            )\n",
        "        ],\n",
        "        temperature=0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_gemini_express.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
