{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCIMTPB1WoTq"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yVV6txOmNMn"
   },
   "source": [
    "# Getting started with Vertex AI Gemini 1.5 Flash\n",
    "\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_1_5_flash.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_1_5_flash.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_1_5_flash.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_1_5_flash.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EExYZvij2ve"
   },
   "source": [
    "| | |\n",
    "|-|-|\n",
    "|Author(s) | [Eric Dong](https://github.com/gericdong), [Holt Skinner](https://github.com/holtskinner) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1DnOs6rkbOy"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Gemini 1.5 Flash is a new language model from the Gemini family. This model includes the long context window of up to 1 million tokens from Gemini 1.5 Pro and is optimized for low-latency tasks. It can process text, images, audio, video, and code all together for deeper insights. Learn more about [Gemini 1.5 Flash](https://deepmind.google/technologies/gemini/flash/).\n",
    "\n",
    "With this tutorial, you learn how to use the Vertex AI Gemini API and the Vertex AI SDK to work with the Gemini 1.5 Flash model to:\n",
    "\n",
    "- analyze audio for insights.\n",
    "- understand videos (including their audio components).\n",
    "- extract information from PDF documents.\n",
    "- process images, video, audio, and text simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Install Vertex AI SDK for Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFy3H3aPgx12"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --user --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRvKdaPDTznN"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, run the cell below to authenticate your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyKGtVQjgx13"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqwi-5ufWp_B"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXHfaVS66_01"
   },
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lslYAvw37JGQ"
   },
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from vertexai.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    "    Part,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BY1nfXrqRxVX"
   },
   "source": [
    "### Load the Gemini 1.5 Flash model\n",
    "\n",
    "To learn more about all [Gemini API models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7ExWmuLBdIA"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-1.5-flash-001\"  # @param {type:\"string\"}\n",
    "\n",
    "model = GenerativeModel(MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9OKM0-4SQf8"
   },
   "source": [
    "### Vertex AI SDK basic usage\n",
    "\n",
    "Below is a simple example that demonstrates how to prompt the Gemini 1.5 Flash model using the Vertex AI SDK. Learn more about the [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini#gemini-pro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhFxrtfdSwOP"
   },
   "outputs": [],
   "source": [
    "# Load a example model with system instructions\n",
    "example_model = GenerativeModel(\n",
    "    MODEL_ID,\n",
    "    system_instruction=[\n",
    "        \"You are a helpful language translator.\",\n",
    "        \"Your mission is to translate text in English to French.\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Set model parameters\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0.9,\n",
    "    top_p=1.0,\n",
    "    top_k=32,\n",
    "    candidate_count=1,\n",
    "    max_output_tokens=8192,\n",
    ")\n",
    "\n",
    "# Set safety settings\n",
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "}\n",
    "\n",
    "prompt = \"\"\"\n",
    "  User input: I like bagels.\n",
    "  Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Set contents to send to the model\n",
    "contents = [prompt]\n",
    "\n",
    "# Counts tokens\n",
    "print(example_model.count_tokens(contents))\n",
    "\n",
    "# Prompt the model to generate content\n",
    "response = example_model.generate_content(\n",
    "    contents,\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings,\n",
    ")\n",
    "\n",
    "# Print the model response\n",
    "print(f\"\\nAnswer:\\n{response.text}\")\n",
    "print(f'\\nUsage metadata:\\n{response.to_dict().get(\"usage_metadata\")}')\n",
    "print(f\"\\nFinish reason:\\n{response.candidates[0].finish_reason}\")\n",
    "print(f\"\\nSafety settings:\\n{response.candidates[0].safety_ratings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acRxKRA-sr0j"
   },
   "source": [
    "## Audio understanding\n",
    "\n",
    "Gemini 1.5 Flash can directly process audio for long-context understanding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10hgCOIA4E5_"
   },
   "outputs": [],
   "source": [
    "audio_file_path = \"cloud-samples-data/generative-ai/audio/pixel.mp3\"\n",
    "audio_file_uri = f\"gs://{audio_file_path}\"\n",
    "audio_file_url = f\"https://storage.googleapis.com/{audio_file_path}\"\n",
    "\n",
    "IPython.display.Audio(audio_file_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sXM19QQ4vj1"
   },
   "source": [
    "#### Example 1: Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPQ1fBk44E6L"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Please provide a summary for the audio.\n",
    "  Provide chapter titles, be concise and short, no need to provide chapter summaries.\n",
    "  Do not make up any information that is not part of the audio and do not be verbose.\n",
    "\"\"\"\n",
    "\n",
    "audio_file = Part.from_uri(audio_file_uri, mime_type=\"audio/mpeg\")\n",
    "contents = [audio_file, prompt]\n",
    "\n",
    "response = model.generate_content(contents)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzA8vKgQATGL"
   },
   "source": [
    "#### Example 2: Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buziSRMG-42a"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    Can you transcribe this interview, in the format of timecode, speaker, caption.\n",
    "    Use speaker A, speaker B, etc. to identify the speakers.\n",
    "\"\"\"\n",
    "\n",
    "audio_file = Part.from_uri(audio_file_uri, mime_type=\"audio/mpeg\")\n",
    "contents = [audio_file, prompt]\n",
    "\n",
    "responses = model.generate_content(contents, stream=True)\n",
    "\n",
    "for response in responses:\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_U36v4TmswAG"
   },
   "source": [
    "## Video with audio understanding\n",
    "\n",
    "Try out Gemini 1.5 Flash's native multimodal and long context capabilities on video interleaving with audio inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDswcPI0tSRk"
   },
   "outputs": [],
   "source": [
    "video_file_path = \"cloud-samples-data/generative-ai/video/pixel8.mp4\"\n",
    "video_file_uri = f\"gs://{video_file_path}\"\n",
    "video_file_url = f\"https://storage.googleapis.com/{video_file_path}\"\n",
    "\n",
    "IPython.display.Video(video_file_url, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9isZfjzCYxw"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Provide a description of the video.\n",
    "  The description should also contain anything important which people say in the video.\n",
    "\"\"\"\n",
    "\n",
    "video_file = Part.from_uri(video_file_uri, mime_type=\"video/mp4\")\n",
    "contents = [video_file, prompt]\n",
    "\n",
    "response = model.generate_content(contents)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcBZZ-bJe2yS"
   },
   "source": [
    "Gemini 1.5 Flash model is able to process the video with audio, retrieve and extract textual and audio information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dTcKyoutS7U"
   },
   "source": [
    "## PDF document analysis\n",
    "\n",
    "You can use Gemini 1.5 Flash to process PDF documents, and analyze content, retain information, and provide answers to queries regarding the documents.\n",
    "\n",
    "The PDF document example used here is the Gemini 1.5 paper (https://arxiv.org/pdf/2403.05530.pdf).\n",
    "\n",
    "![image.png](https://storage.googleapis.com/cloud-samples-data/generative-ai/image/gemini1.5-paper-2403.05530.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgKDIZUstYwV"
   },
   "outputs": [],
   "source": [
    "pdf_file_uri = \"gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "  You are a very professional document summarization specialist.\n",
    "  Please summarize the given document.\n",
    "\"\"\"\n",
    "\n",
    "pdf_file = Part.from_uri(pdf_file_uri, mime_type=\"application/pdf\")\n",
    "contents = [pdf_file, prompt]\n",
    "\n",
    "response = model.generate_content(contents)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52ltdcv5EsaM"
   },
   "outputs": [],
   "source": [
    "image_file_path = \"cloud-samples-data/generative-ai/image/cumulative-average.png\"\n",
    "image_file_url = f\"https://storage.googleapis.com/{image_file_path}\"\n",
    "image_file_uri = f\"gs://{image_file_path}\"\n",
    "\n",
    "IPython.display.Image(image_file_url, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEmrMpRMHyel"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Task: Answer the following questions based on a PDF document and image file provided in the context.\n",
    "\n",
    "Instructions:\n",
    "- Look through the image and the PDF document carefully and answer the question.\n",
    "- Give a short and terse answer to the following question.\n",
    "- Do not paraphrase or reformat the text you see in the image.\n",
    "- Cite the source of page number for the PDF document provided as context.\n",
    "\n",
    "  Questions:\n",
    "  - What is in the given image?\n",
    "  - Is there a similar graph in the given document?\n",
    "\n",
    "Context:\n",
    "\"\"\"\n",
    "\n",
    "image_file = Part.from_uri(image_file_uri, mime_type=\"image/png\")\n",
    "\n",
    "contents = [\n",
    "    pdf_file,\n",
    "    image_file,\n",
    "    prompt,\n",
    "]\n",
    "\n",
    "response = model.generate_content(contents)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIwBUZTyLJh0"
   },
   "source": [
    "Gemini 1.5 Flash is able to identify and locate the graph on page 10 from the PDF document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3vu8ogWs7iZ"
   },
   "source": [
    "## All modalities (images, video, audio, text) at once\n",
    "\n",
    "Gemini 1.5 Flash is natively multimodal and supports interleaving of data from different modalities, it can support a mix of audio, visual, text, and\n",
    "code inputs in the same input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gp216wxgiKg4"
   },
   "outputs": [],
   "source": [
    "video_file_path = \"cloud-samples-data/generative-ai/video/behind_the_scenes_pixel.mp4\"\n",
    "video_file_uri = f\"gs://{video_file_path}\"\n",
    "video_file_url = f\"https://storage.googleapis.com/{video_file_path}\"\n",
    "\n",
    "IPython.display.Video(video_file_url, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qS7KSwvbjhFh"
   },
   "outputs": [],
   "source": [
    "image_file_path = \"cloud-samples-data/generative-ai/image/a-man-and-a-dog.png\"\n",
    "image_file_uri = f\"gs://{image_file_path}\"\n",
    "image_file_url = f\"https://storage.googleapis.com/{image_file_path}\"\n",
    "\n",
    "IPython.display.Image(image_file_url, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRdzwDi9iLGn"
   },
   "outputs": [],
   "source": [
    "video_file = Part.from_uri(video_file_uri, mime_type=\"video/mp4\")\n",
    "image_file = Part.from_uri(image_file_uri, mime_type=\"image/png\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "  Look through each frame in the video carefully and answer the questions.\n",
    "  Only base your answers strictly on what information is available in the video attached.\n",
    "  Do not make up any information that is not part of the video and do not be too\n",
    "  verbose, be to the point.\n",
    "\n",
    "  Questions:\n",
    "  - When is the moment in the image happening in the video? Provide a timestamp.\n",
    "  - What is the context of the moment and what does the narrator say about it?\n",
    "\"\"\"\n",
    "\n",
    "contents = [video_file, image_file, prompt]\n",
    "\n",
    "response = model.generate_content(contents)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3iovYxOwOT7"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, you've learned how to use Gemini 1.5 Flash with the Vertex AI SDK to:\n",
    "\n",
    "- analyze audio for insights.\n",
    "- understand videos (including their audio components).\n",
    "- extract information from PDF documents.\n",
    "- process images, video, audio, and text simultaneously."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_gemini_1_5_pro.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
