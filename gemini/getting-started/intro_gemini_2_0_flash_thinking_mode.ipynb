{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqi5B7V_Rjim"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyPmicX9RlZX"
      },
      "source": [
        "# Getting Started with Gemini 2.0 Flash Thinking Model\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash_thinking_mode.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_2_0_flash_thinking_mode.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_2_0_flash_thinking_mode.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash_thinking_mode.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://goo.gle/42q3ZwP\">\n",
        "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in Cloud Skills Boost\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash_thinking_mode.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash_thinking_mode.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash_thinking_mode.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/X_logo_2023_original.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash_thinking_mode.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_0_flash_thinking_mode.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MqT58L6Rm_q"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| Author(s) |  [Guillaume Vernade](https://github.com/giom-v), [Eric Dong](https://github.com/gericdong) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w14yjWnPVD-"
      },
      "source": [
        "## Overview\n",
        "\n",
        "[Gemini 2.0 Flash Thinking](https://cloud.google.com/vertex-ai/generative-ai/docs/thinking-mode) is an experimental model that's trained to generate the \"thinking process\" the model goes through as part of its response. As a result, the Flash Thinking model is capable of stronger reasoning capabilities in its responses than the Gemini 2.0 Flash model.\n",
        "\n",
        "This tutorial demonstrates how to access the Gemini 2.0 Flash Thinking model and use the model to solve the following complex tasks that require multiple rounds of strategizing and iteratively solving.\n",
        "\n",
        "- Example 1: Code simplification\n",
        "- Example 2: Geometry problem (with image)\n",
        "- Example 3: Mathematical brain teaser\n",
        "- Example 4: Generating question for a specific level of knowledge\n",
        "- Example 5: Statistics\n",
        "- Example 6: Brain teaser with a twist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPiTOAHURvTM"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHRZUpfWSEpp"
      },
      "source": [
        "### Install Google Gen AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG3_LKsWSD3A"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlMVjiAWSMNX"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12fnq4V0SNV3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ef0zVX-X9Bg"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xBCH3hnAX9Bh"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Iterator\n",
        "import os\n",
        "\n",
        "from IPython.display import Image, Markdown, display\n",
        "from google import genai\n",
        "from google.genai.types import (\n",
        "    GenerateContentConfig,\n",
        "    GenerateContentResponse,\n",
        "    Part,\n",
        "    ThinkingConfig,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LymmEN6GSTn-"
      },
      "source": [
        "### Set Google Cloud project information and create client\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\"}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "T-tiytzQE0uM"
      },
      "outputs": [],
      "source": [
        "client = genai.Client(\n",
        "    vertexai=True,\n",
        "    project=PROJECT_ID,\n",
        "    location=LOCATION,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0u6hYSleE0H"
      },
      "source": [
        "## Use Gemini 2.0 Flash Thinking Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M7EKckIYVFy"
      },
      "source": [
        "### Set model ID\n",
        "\n",
        "See the [Google models](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models) page for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-coEslfWPrxo"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash-thinking-exp-01-21\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72e846835b84"
      },
      "source": [
        "### Helper functions\n",
        "\n",
        "Create methods to print out the thoughts and answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51e2ab48b44a"
      },
      "outputs": [],
      "source": [
        "def print_thoughts(response: GenerateContentResponse) -> None:\n",
        "    for part in response.candidates[0].content.parts:\n",
        "        header = \"Thoughts\" if part.thought else \"Answer\"\n",
        "        display(Markdown(f\"\"\"## {header}:\\n{part.text}\"\"\"))\n",
        "\n",
        "\n",
        "def print_thoughts_stream(response: Iterator[GenerateContentResponse]) -> None:\n",
        "    display(Markdown(\"## Thoughts:\\n\"))\n",
        "    answer_shown = False\n",
        "\n",
        "    for chunk in response:\n",
        "        for part in chunk.candidates[0].content.parts:\n",
        "            if not part.thought and not answer_shown:\n",
        "                display(Markdown(\"## Answer:\\n\"))\n",
        "                answer_shown = True\n",
        "            display(Markdown(part.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7103e527293a"
      },
      "source": [
        "### Enable thoughts\n",
        "\n",
        "You set the flag `include_thoughts` in the `ThinkingConfig` to indicate whether to return thoughts in the model response. The flag is set to `False` by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "869bd363d8fc"
      },
      "outputs": [],
      "source": [
        "config = GenerateContentConfig(thinking_config=ThinkingConfig(include_thoughts=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5fc462efc55"
      },
      "source": [
        "### Generate content with thoughts\n",
        "\n",
        "Then use the `generate_content` method to send a request to generate content with thoughts. The model responds with multiple parts, the thoughts and the model response. You can check the `part.thought` field to determine if a part is a thought or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c55bf1df11ea"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the next number in this sequence: 2, 4, 8, 16, __?\",\n",
        "    config=config,\n",
        ")\n",
        "print_thoughts(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c9a466d65d0"
      },
      "source": [
        "### Generate content stream with thoughts\n",
        "\n",
        "You can also use the `generate_content_stream` method to stream the response and thoughts as they are being generated, and the model will return chunks of the response as soon as they are generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "425f08594870"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content_stream(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Does the Monty Hall Problem change if all the doors are made of transparent glass?\",\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print_thoughts_stream(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrRBg9UGC9nn"
      },
      "source": [
        "## Thinking Model examples\n",
        "\n",
        "The following examples are some complex tasks that require multiple rounds of strategizing and iteratively solving.\n",
        "\n",
        "### **Example 1**: Code simplification\n",
        "\n",
        "First, try with a simple code comprehension and simplification example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLhhffx2C9nn"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "How can I simplify this?\n",
        "`(Math.round(radius/pixelsPerMile * 10) / 10).toFixed(1);`\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print_thoughts(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6cOmdVPC9nn"
      },
      "source": [
        "As a comparison here's what you'd get with the [Gemini 2.0 Flash](https://cloud.google.com/vertex-ai/generative-ai/docs/gemini-v2) base model.\n",
        "\n",
        "Unlike thinking mode, the normal model does not articulate its thoughts and tries to answer right away which can lead to more simple answers to complex problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "027b7d9a6134"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    contents=prompt,\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4080cc17f5d9"
      },
      "source": [
        "### **Example 2**: Geometry problem (with image)\n",
        "\n",
        "This geometry problem requires complex reasoning and is also using Gemini multimodal capabilities to read the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bd02dff35d0"
      },
      "outputs": [],
      "source": [
        "image_file_path = \"generativeai-downloads/images/geometry.png\"\n",
        "image_file_uri = f\"gs://{image_file_path}\"\n",
        "image_file_url = f\"https://storage.googleapis.com/{image_file_path}\"\n",
        "\n",
        "display(Image(url=image_file_url, width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80f2vzWxC9no"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(image_file_uri, mime_type=\"image/png\"),\n",
        "        \"What's the area of the overlapping region?\",\n",
        "    ],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print_thoughts(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_WlcJZjC9np"
      },
      "source": [
        "### **Example 3**: Mathematical brain teaser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5411dfb9e8b"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Add mathematical operations (additions, subtractions, multiplications)\n",
        "to get 746 using these numbers only once: 8, 7, 50, and 4\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print_thoughts(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "655ba02d9bda"
      },
      "source": [
        "### **Example 4**: Generating question for a specific level of knowledge\n",
        "\n",
        "This time, the questions require a few types of knowledge, including what is relevant to the [Physics C: Mechanics exam](https://apcentral.collegeboard.org/courses/ap-physics-c-mechanics/exam). The questions generated are not the interesting part, but the reasoning to come up with them shows they are not just randomly generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU3FAUqcC9np"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Give me a practice question I can use for the AP Physics C: Mechanics exam?\",\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print_thoughts(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnDwUxI-fRWo"
      },
      "source": [
        "### **Example 5**: Statistics\n",
        "\n",
        "Here's a new mathematical problem. Once again, what's interesting is not the answer (as you might know it already) but how the model is coming up with it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQozYPZzgXRE"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"You repeatedly flipped a coin until you either flip three heads, or heads tails heads. Which is more likely to happen first?\",\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print_thoughts(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9RG4DRCm1vY"
      },
      "source": [
        "### **Example 6**:  Brain teaser with a twist\n",
        "\n",
        "Here's another brain teaser based on an image, this time it looks like a mathematical problem, but it cannot actually be solved mathematically. If you check the thoughts of the model you'll see that it will realize it and come up with an out-of-the-box solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b26b9ebd2d5d"
      },
      "outputs": [],
      "source": [
        "image_file_path = \"generativeai-downloads/images/pool.png\"\n",
        "image_file_uri = f\"gs://{image_file_path}\"\n",
        "image_file_url = f\"https://storage.googleapis.com/{image_file_path}\"\n",
        "\n",
        "display(Image(url=image_file_url, width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0_4uP5Wm6yx"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(image_file_uri, mime_type=\"image/png\"),\n",
        "        \"How do I use three of the pool balls to sum up to 30?\",\n",
        "    ],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print_thoughts(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lND4jB6MrsSk"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "- Explore the Vertex AI [Cookbook](https://cloud.google.com/vertex-ai/generative-ai/docs/cookbook) for a curated, searchable gallery of notebooks for Generative AI.\n",
        "- Explore other notebooks and samples in the [Google Cloud Generative AI repository](https://github.com/GoogleCloudPlatform/generative-ai)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_gemini_2_0_flash_thinking_mode.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
