{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Forced Function Calling with Tool Configurations in Gemini\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/forced_function_calling.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Ffunction-calling%2Fforced_function_calling.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/function-calling/forced_function_calling.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/forced_function_calling.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/forced_function_calling.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/forced_function_calling.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/forced_function_calling.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/forced_function_calling.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/forced_function_calling.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Kristopher Overholt](https://github.com/koverholt) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates the use of forced Function Calling in the Gemini model.\n",
        "\n",
        "### Gemini\n",
        "\n",
        "Gemini is a family of generative AI models developed by Google DeepMind that is designed for multimodal use cases.\n",
        "\n",
        "### Function Calling in Gemini\n",
        "\n",
        "[Function Calling in Gemini](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling) lets developers create a description of a function in their code, then pass that description to a language model in a request. The response from the model includes the name of a function that matches the description and the arguments to call it with.\n",
        "\n",
        "### Forced Function Calling\n",
        "\n",
        "[Forced Function Calling in Gemini](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling#tool-config) allows you to place constraints on how the model should use the function declarations that you provide it with. Using tool configurations, you can force the Gemini model to only predict function calls. You can also choose to provide the model with a full set of function declarations, but restrict its responses to a subset of these functions.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "In this tutorial, you will learn how to use the Vertex AI SDK for Python to use different function calling modes, including forced function calling, via the Gemini model.\n",
        "\n",
        "You will complete the following tasks:\n",
        "\n",
        "- Read through an overview of forced function calling and when to use it\n",
        "- Use the default function calling behavior in `AUTO` mode\n",
        "- Enable forced function calling using the `ANY` mode\n",
        "- Disable function calling using the `NONE` mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Google Gen AI SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet google-genai arxiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and create client\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23a24049e443"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc6278ff6e55"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "import arxiv\n",
        "from google.genai.types import (\n",
        "    FunctionCallingConfig,\n",
        "    FunctionCallingConfigMode,\n",
        "    FunctionDeclaration,\n",
        "    GenerateContentConfig,\n",
        "    Part,\n",
        "    Schema,\n",
        "    Tool,\n",
        "    ToolConfig,\n",
        "    Type,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d091edc81048"
      },
      "source": [
        "### Choose a model\n",
        "\n",
        "For more information about all AI models and APIs on Vertex AI, see [Google Models](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models) and [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models).\n",
        "\n",
        "Refer to the [Gemini Function Calling documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling) for more information on which models and model versions support forced function calling and tool configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8922eacdb2d"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash-001\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0505b45fa754"
      },
      "source": [
        "## Define a function to search for scientific papers in arXiv\n",
        "\n",
        "Since this notebook focuses on using different tool configurations and modes in Gemini Function Calling, you'll define a function declaration to use throughout the examples.\n",
        "\n",
        "The purpose of this function is to extract a parameter to send as a query to search for relevant papers in [arXiv](https://arxiv.org/).\n",
        "\n",
        "arXiv is an open-access repository of electronic preprints and postprints that consists of scientific papers in various fields."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72440503b923"
      },
      "outputs": [],
      "source": [
        "search_arxiv = FunctionDeclaration(\n",
        "    name=\"search_arxiv\",\n",
        "    description=\"Search for articles and publications in arXiv\",\n",
        "    parameters=Schema(\n",
        "        type=Type.OBJECT,\n",
        "        properties={\n",
        "            \"query\": Schema(\n",
        "                type=Type.STRING, description=\"Query to search for in arXiv\"\n",
        "            )\n",
        "        },\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17f31eb30c46"
      },
      "source": [
        "Define a tool that wraps the above function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4d7150e5b03"
      },
      "outputs": [],
      "source": [
        "search_tool = Tool(\n",
        "    function_declarations=[\n",
        "        search_arxiv,\n",
        "    ],\n",
        ")\n",
        "config = GenerateContentConfig(temperature=0, tools=[search_tool])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a12e1e637c7"
      },
      "source": [
        "You'll use this function declaration and tool throughout the next few sections of the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a043e118735"
      },
      "source": [
        "## Overview of Forced Function Calling in Gemini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d17a45fcea5"
      },
      "source": [
        "The default behavior for Function Calling allows the Gemini model to decide whether to predict a function call or a natural language response. This is because the default Function Calling mode in Gemini is set to `AUTO`.\n",
        "\n",
        "In most cases this is the desired behavior when you want the Gemini model to use information from the prompt to determine if it should call a function, and which function it should call. However, you might have specific use cases where you want to **force** the Gemini model to call a function (or a set of functions) in a given model generation request.\n",
        "\n",
        "Tool configurations in the Gemini API allow you to specify different Function Calling modes in Gemini. Refer to the [Gemini Function Calling documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling) for more information on forced function calling and tool configurations.\n",
        "\n",
        "The following code example for `tool_config` shows various modes that you can set and pass to the Gemini model either globally when you initialize the model or for a given model generation request:\n",
        "\n",
        "```py\n",
        "tool_config = ToolConfig(\n",
        "    function_calling_config=ToolConfig.FunctionCallingConfig(\n",
        "        mode=ToolConfig.FunctionCallingConfig.Mode.AUTO,  # The default model behavior. The model decides whether to predict a function call or a natural language response.\n",
        "        mode=ToolConfig.FunctionCallingConfig.Mode.ANY,  # ANY mode forces the model to predict a function call from a subset of function names.\n",
        "        mode=ToolConfig.FunctionCallingConfig.Mode.NONE,  # NONE mode instructs the model to not predict function calls. Equivalent to a model request without any function declarations.\n",
        "        allowed_function_names=[\n",
        "            \"function_to_call\"\n",
        "        ],  # Allowed functions to call when mode is ANY, if empty any one of the provided functions will be called.\n",
        "    )\n",
        ")\n",
        "```\n",
        "\n",
        "Using these Function Calling modes, you can configure the model to behave in one of the following ways:\n",
        "\n",
        "- Allow the model to choose whether to predict a function call or natural language response (`AUTO` mode)\n",
        "- Force the model to predict a function call on one function or a set of functions (`ANY` mode)\n",
        "- Disable function calling and return a natural language response as if no functions or tools were defined (`NONE` mode)\n",
        "\n",
        "In the following sections, you'll walk through examples and sample code for each Function Calling mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ab06d57a134"
      },
      "source": [
        "## Example: Default Function Calling mode (`AUTO`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a3b8124f0fc"
      },
      "source": [
        "In this example, you'll specify the function calling mode as `AUTO`. Note that `AUTO` mode is the default model behavior, therefore the Gemini model will also use this mode when there is no `tool_config` specified:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50b1009e342b"
      },
      "outputs": [],
      "source": [
        "config.tool_config = ToolConfig(\n",
        "    function_calling_config=FunctionCallingConfig(\n",
        "        mode=FunctionCallingConfigMode.AUTO,  # The default model behavior. The model decides whether to predict a function call or a natural language response.\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1c7e020ee38"
      },
      "source": [
        "Ask a question about a topic related to publications in arXiv and include the `tool_config` kwarg. Note that you can also set the `tool_config` kwarg globally in the model rather than with every request to generate content:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c22b8e9a99a"
      },
      "outputs": [],
      "source": [
        "prompt = \"Explain the Schrodinger equation in a few sentences and give me papers from arXiv to learn more.\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "display(Markdown(response.candidates[0].content.parts[0].text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63ee50104549"
      },
      "source": [
        "The response includes a natural language summary to the prompt. However, you were probably hoping to make a function call along the way to search for actual papers in arXiv and return them to the end user!\n",
        "\n",
        "We'll make that happen in the next section by using the forced function calling mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec647eed5130"
      },
      "source": [
        "## Example: Using Forced Function Calling mode (`ANY`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f76d1bb4b4c9"
      },
      "source": [
        "In this example, you'll set the tool configuration to `ANY`, and (optionally) specify one or more `allowed_function_names` that will force Gemini to make a function call against a function or subset of functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "992c70f9a9b8"
      },
      "outputs": [],
      "source": [
        "config.tool_config = ToolConfig(\n",
        "    function_calling_config=FunctionCallingConfig(\n",
        "        mode=FunctionCallingConfigMode.ANY,  # ANY mode forces the model to predict a function call from a subset of function names.\n",
        "        allowed_function_names=[\n",
        "            \"search_arxiv\"\n",
        "        ],  # Allowed functions to call when mode is ANY, if empty any one of the provided functions will be called.\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60a33d7fff56"
      },
      "source": [
        "Now you can ask the same question publications in arXiv with our newly defined `tool_config` that is set to `ANY` function calling mode, which will force the Gemini model to call our search function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "753d7d208f77"
      },
      "outputs": [],
      "source": [
        "prompt = \"Explain the Schrodinger equation in a few sentences and give me papers from arXiv to learn more\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.function_calls[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f4715146eca"
      },
      "source": [
        "You can extract the parameters from the model response so that we can use them to make an API call to search papers in arXiv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10754b0a94ba"
      },
      "outputs": [],
      "source": [
        "params = {}\n",
        "for key, value in response.function_calls[0].args.items():\n",
        "    params[key] = value\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffc6cc2033f3"
      },
      "outputs": [],
      "source": [
        "if response.function_calls[0].name == \"search_arxiv\":\n",
        "    arxiv_client = arxiv.Client()\n",
        "\n",
        "    search = arxiv.Search(\n",
        "        query=params[\"query\"], max_results=10, sort_by=arxiv.SortCriterion.SubmittedDate\n",
        "    )\n",
        "\n",
        "    results = arxiv_client.results(search)\n",
        "    results = str([r for r in results])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f4e8482dcc2"
      },
      "source": [
        "Print a sample of the API response from arXiv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9ef5bebc0eb"
      },
      "outputs": [],
      "source": [
        "results[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fae1aaee9fe3"
      },
      "outputs": [],
      "source": [
        "config.tool_config = None\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        prompt,\n",
        "        Part.from_function_call(\n",
        "            name=response.function_calls[0].name, args=response.function_calls[0].args\n",
        "        ),  # Function call response\n",
        "        Part.from_function_response(\n",
        "            name=\"search_arxiv\",\n",
        "            response={\n",
        "                \"content\": results,  # Return the API response to the Gemini model\n",
        "            },\n",
        "        ),\n",
        "    ],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a97b13c2a45b"
      },
      "source": [
        "In this case, the natural language response contains information about relevant papers based on our function call to the arXiv API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a64301e40297"
      },
      "source": [
        "## Example: Disabling Function Calling (`NONE`)\n",
        "\n",
        "In this example, you'll set the tool configuration to `NONE`, which will instruct the Gemini model to behave as if no tools or functions were defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc0c43b9a696"
      },
      "outputs": [],
      "source": [
        "config.tool_config = ToolConfig(\n",
        "    function_calling_config=FunctionCallingConfig(\n",
        "        mode=FunctionCallingConfigMode.NONE,  # NONE mode instructs the model to not predict function calls. Equivalent to a model request without any function declarations.\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7678f426d195"
      },
      "outputs": [],
      "source": [
        "prompt = \"Explain the Schrodinger equation in a few sentences and give me papers from arXiv to learn more\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dc4ee73d814"
      },
      "source": [
        "Note that the natural language response only contains content that was generated by the Gemini model and within the scope of its training data rather than real-time information from the arXiv API."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "forced_function_calling.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
