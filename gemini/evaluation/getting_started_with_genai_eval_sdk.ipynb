{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uXjAhOcnoJ9"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Getting Started with the new Vertex AI Gen AI Eval SDK \n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/getting_started_with_genai_eval_sdk.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fevaluation%2Fgetting_started_with_genai_eval_sdk.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/evaluation/getting_started_with_genai_eval_sdk.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/getting_started_with_genai_eval_sdk.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/getting_started_with_genai_eval_sdk.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/getting_started_with_genai_eval_sdk.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/getting_started_with_genai_eval_sdk.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/getting_started_with_genai_eval_sdk.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/getting_started_with_genai_eval_sdk.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za9aFGhcpTdh"
      },
      "source": [
        "| Author(s) |\n",
        "| --- |\n",
        "| [Jason Dai](https://github.com/jsondai) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm9UNNiBpSEv"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook introduces the new Vertex AI Gen AI Eval SDK, a powerful framework for evaluating generative AI models in Vertex AI with a streamlined, client-side workflow that offers expanded model support and flexible data handling.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**What's New in the Vertex AI Gen AI Eval SDK?**\n",
        "\n",
        "*   **A Simpler Two-Step Workflow**: The evaluation process is now a simple, two-step procedure using `run_inference()` and `evaluate()`.\n",
        "\n",
        "*   **Native Third-Party Model Support**: You can now evaluate and compare models from other providers, like OpenAI and HuggingFace, directly within the SDK.\n",
        "\n",
        "*   **Flexible Data Handling**: The SDK automatically detects and handles multiple data formats, including Pandas DataFrames, the Gemini format, and the OpenAI Chat Completion format, reducing the need for data preprocessing.\n",
        "\n",
        "*   **Flexible, Multi-Candidate Evaluation**: Easily analyze and compare the performance of multiple AI models, agents, or configurations in a single run. The SDK provides a unified report with comprehensive results and win-rate calculations for all contenders.\n",
        "\n",
        "*   **Simplified and Powerful Metrics**: The SDK introduces two main classes, `Metric` and `LLMMetric`, a library of pre-built metrics like `TEXT_QUALITY`, and extensive customization options for your specific needs.\n",
        "\n",
        "*   **Asynchronous Batch-style Evaluation**: For large datasets, you can now use `batch_evaluate()` to run evaluations as a long-running operation, which is ideal for large-scale jobs. It is parameter-compatible with `evaluate()` for a seamless transition.\n",
        "\n",
        "*   **Rich In-Notebook Visualization**: Use the `.show()` method on evaluation results to render detailed HTML reports directly within your Colab or Jupyter notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**LEGAL NOTICE**\n",
        "\n",
        "This is an Experimental release. Experiments are focused on validating a prototype and are not guaranteed to be released. Experiments are covered by the [Pre-GA Offerings Terms](https://cloud.google.com/terms/service-terms) of the Google Cloud Platform Terms of Service. They are not intended for production use or covered by any SLA, support obligation, or deprecation policy and might be subject to backward-incompatible changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkDYSIWFt6fw"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "- Vertex AI\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdHJLCsknfo3"
      },
      "source": [
        "## Getting Started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7h68r494LQx"
      },
      "source": [
        "### Install Vertex AI Gen AI Eval SDK fand other required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUvV0SoQUyPr"
      },
      "outputs": [],
      "source": [
        "%pip install google-cloud-aiplatform[evaluation]==1.100.0 --force-reinstall --quiet --no-warn-conflicts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DsrG4Was-VP"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDVjOzdns_3n"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ngm3-mtCQ5"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ab29VQ96e4Hf"
      },
      "outputs": [],
      "source": [
        "# Use the environment variable if the user doesn't provide Project ID.\n",
        "import os\n",
        "\n",
        "PROJECT_ID = \"\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION= \"us-central1\"  # @param {type: \"string\", placeholder: \"us-central1\", isTemplate: true}\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", LOCATION)\n",
        "\n",
        "from vertexai import Client, types\n",
        "\n",
        "client = Client(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY2ky19CzR00"
      },
      "source": [
        "## Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0ThmEPte2TS"
      },
      "source": [
        "### Generate Responses with `run_inference`\n",
        "\n",
        "The eval workflow starts with `run_inference()` to generate model responses for your dataset. The SDK can directly handle data in a `pandas.DataFrame` format, or a GCS file URI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "a4qGyFqUub2i",
        "outputId": "611079f7-091e-4ac3-b295-be64e9346045"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "eval_df = pd.DataFrame({\n",
        "    \"prompt\": [\n",
        "        \"What is the capital of France?\",\n",
        "        \"Write a haiku about a cat.\",\n",
        "    ],\n",
        "    \"reference\": [\n",
        "        \"Paris\",\n",
        "        \"Sunbeam on the floor,\\nA furry puddle sleeping,\\nTwitching tail tells tales.\",\n",
        "    ]\n",
        "})\n",
        "\n",
        "eval_dataset = client.evals.run_inference(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    src=eval_df,\n",
        ")\n",
        "\n",
        "eval_dataset.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAVEnQwhe7Se"
      },
      "source": [
        "### Evaluate with Pre-built Metrics\n",
        "\n",
        "Use the `evaluate()` method to assess the generated responses. The SDK provides a library of pre-built metrics for common evaluation tasks. You can combine different types of metrics in a single evaluation run. LLM-based metrics like `PrebuiltMetric.TEXT_QUALITY` use an LLM as a \"judge\" to score the response, while computation-based metrics like `Metric('rouge_1')` calculate scores using traditional algorithms by measuring the overlap between the generated response and a ground-truth reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "cjzVo3YufAcT",
        "outputId": "6d074de7-b894-45f5-b295-67171b9e5eb0"
      },
      "outputs": [],
      "source": [
        "eval_result = client.evals.evaluate(\n",
        "    dataset=eval_dataset,\n",
        "    metrics=[\n",
        "        types.PrebuiltMetric.TEXT_QUALITY,\n",
        "        types.PrebuiltMetric.QUESTION_ANSWERING_QUALITY,\n",
        "        types.Metric(name='bleu'),\n",
        "        types.Metric(name='rouge_1'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "eval_result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7CXho7XfT2U"
      },
      "source": [
        "### Compare Multiple Candidates\n",
        "\n",
        "A key feature of the new SDK is the ability to easily compare multiple candidates. Simply generate responses for each candidate and pass them as a list to evaluate(). For instance, here is an example that compares the performance of `gemini-2.0-flash` against `gemini-2.5-flash`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4ZluPetifSkU",
        "outputId": "0716add6-73fc-4ce3-fb44-91f96ef2751f"
      },
      "outputs": [],
      "source": [
        "prompts_df = pd.DataFrame({\n",
        "    \"prompt\": [\n",
        "        \"You are an ancient, sentient library. Describe the process of a new book being cataloged and placed on your shelves, but do so in the style of a sonnet (14 lines, iambic pentameter, specific rhyme scheme). Within the sonnet, include a metaphor for the book as a 'newcomer' or 'immigrant' and mention the distinct scent of old paper and ink.\",\n",
        "        \"Write a dialogue between two AI models discussing the philosophical implications of creating art. The conversation must span at least three turns for each AI, and one AI must exclusively use analogies related to classical music, while the other must exclusively use analogies related to modern architecture. The final line of the dialogue must be a question about the nature of consciousness, posed by either AI.\",\n",
        "        \"Explain the concept of quantum entanglement to a five-year-old, but you can only use words that are two syllables or less. Additionally, integrate a short, fantastical narrative about two magical socks that are entangled. Your explanation must be no longer than 150 words and include at least one rhetorical question posed to the child.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "inference_result_1 = client.evals.run_inference(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    src=prompts_df,\n",
        "    config={\n",
        "        \"generate_content_config\": {\n",
        "            \"temperature\": 0.8,\n",
        "            \"max_output_tokens\": 256,\n",
        "        }\n",
        "    }\n",
        ")\n",
        "inference_result_2 = client.evals.run_inference(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    src=prompts_df,\n",
        ")\n",
        "\n",
        "# Compare the responses against each other\n",
        "comparison_result = client.evals.evaluate(\n",
        "    dataset=[inference_result_1, inference_result_2],\n",
        "    metrics=[\n",
        "        types.PrebuiltMetric.TEXT_QUALITY,\n",
        "        types.PrebuiltMetric.INSTRUCTION_FOLLOWING,\n",
        "    ]\n",
        ")\n",
        "\n",
        "comparison_result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3D6h9xCUNWp"
      },
      "source": [
        "### Define and Use a Custom LLM-based Metric\n",
        "\n",
        "For use cases requiring specialized criteria, you can define your own metric using `LLMMetric` and the `MetricPromptBuilder` helper class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "rEd161LTruV-",
        "outputId": "16412df7-4ad5-4e78-ece1-5dbf758f1c53"
      },
      "outputs": [],
      "source": [
        "# Define a custom metric for language simplicity\n",
        "simplicity_metric = types.LLMMetric(\n",
        "    name='language_simplicity',\n",
        "    prompt_template=types.MetricPromptBuilder(\n",
        "        instruction=\"Evaluate the story's language simplicity for a 5-year-old.\",\n",
        "        criteria={\n",
        "            \"Simple Vocabulary\": \"Uses words easily understandable by a 5-year-old.\",\n",
        "            \"Simple Sentences\": \"Primarily uses short, simple sentence structures.\",\n",
        "        },\n",
        "        rating_scores={\n",
        "            \"5\": \"Excellent: The language is perfectly simple and suitable for a 5-year-old. Vocabulary is very basic and sentences are short and clear.\",\n",
        "            \"4\": \"Good: The language is mostly simple, with only minor instances of complex words or sentence structures that might be slightly challenging.\",\n",
        "            \"3\": \"Fair: The language is a mix of simple and complex elements. A 5-year-old would understand parts but would likely struggle with others.\",\n",
        "            \"2\": \"Poor: The language is largely too complex. It contains many difficult words and long, complicated sentences for a 5-year-old.\",\n",
        "            \"1\": \"Very Poor: The language is very complex and completely unsuitable for a 5-year-old. It is difficult for even an older child to understand.\"\n",
        "        }\n",
        "    )\n",
        ")\n",
        "\n",
        "# Use the custom metric in an evaluation\n",
        "custom_eval_result = client.evals.evaluate(\n",
        "    dataset=inference_result_1,\n",
        "    metrics=[simplicity_metric]\n",
        ")\n",
        "\n",
        "custom_eval_result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgefjJLCOW7g"
      },
      "source": [
        "### Evaluate Third-Party Models (e.g., OpenAI)\n",
        "\n",
        "The new SDK natively supports generating responses from and evaluating third-party models like OpenAI's GPT models. The SDK uses litellm in the backend and requires the appropriate API key to be set as an environment variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zU589eHQsdKP",
        "outputId": "21a7af9c-516b-4bb2-f963-768413443e9f"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Make sure your OPENAI_API_KEY environment variable is set.\n",
        "os.environ['OPENAI_API_KEY'] = \"\"  # @param {type:\"string\", placeholder: \"[your-openai-api-key]\"} \n",
        "# WARNING: Setting API keys directly in code is insecure. Use environment variables or secure storage.\n",
        "\n",
        "# Alternative, use your OPENAI_API_KEY from Colab Secrets manager\n",
        "# from google.colab import userdata\n",
        "# os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "openai_responses = client.evals.run_inference(\n",
        "    model=\"gpt-4o\",\n",
        "    src=\"gs://vertex-evaluation-llm-dataset-us-central1/genai_eval_sdk/test_prompts.jsonl\",\n",
        ")\n",
        "openai_responses.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "id": "0Mcuvno94hPU",
        "outputId": "3d06df33-a2e4-4b98-d028-abecab227438"
      },
      "outputs": [],
      "source": [
        "# The resulting dataset can then be evaluated\n",
        "eval_result = client.evals.evaluate(\n",
        "    dataset=openai_responses,\n",
        "    metrics=[\n",
        "        types.PrebuiltMetric.TEXT_QUALITY,\n",
        "        types.PrebuiltMetric.FLUENCY,\n",
        "        types.Metric(name='rouge_1')\n",
        "    ]\n",
        ")\n",
        "\n",
        "eval_result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGKplIC6dJbU"
      },
      "source": [
        "### Asynchronous Batch-style Evaluation\n",
        "\n",
        "\n",
        "For large datasets, you can use `batch_evaluate()` to run evaluations as a long-running, asynchronous operation, which is ideal for large-scale jobs. This method provides an SDK interface for the batch-style `EvaluateDataset` API and is distinct from the synchronous, online `evaluate()` method.\n",
        "\n",
        "The `batch_evaluate()` method returns a job object that you can poll to track its progress. Once the job completes successfully, you can retrieve and visualize the results. The parameters for `batch_evaluate()` are compatible with the `evaluate()` method, allowing for a seamless transition between the two.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uv0K7A7LdnW3"
      },
      "outputs": [],
      "source": [
        "GCS_DEST_BUCKET = \"\"  # @param {type:\"string\", placeholder: \"[your-gcs-bucket]\"}\n",
        "\n",
        "inference_result_saved = client.evals.run_inference(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    src=\"gs://vertex-evaluation-llm-dataset-us-central1/genai_eval_sdk/test_prompts.jsonl\",\n",
        "    config={'dest': GCS_DEST_BUCKET}\n",
        ")\n",
        "print(f\"Eval Dataset uploaded to: {inference_result_saved.gcs_source}\")\n",
        "\n",
        "batch_eval_job  = client.evals.batch_evaluate(\n",
        "   dataset = inference_result_saved,\n",
        "   metrics = [\n",
        "        types.PrebuiltMetric.TEXT_QUALITY,\n",
        "        types.PrebuiltMetric.INSTRUCTION_FOLLOWING,\n",
        "        types.PrebuiltMetric.FLUENCY,\n",
        "        types.Metric(name='bleu'),\n",
        "    ],\n",
        "   dest=GCS_DEST_BUCKET\n",
        ")\n",
        "batch_eval_job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl8-2IF_t_OK"
      },
      "source": [
        "View results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKb9FgUOgJMG",
        "outputId": "60b48d27-5f7d-4f92-f761-b8ee41c86c03"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "def gcs_path_to_console_url(gcs_path: str) -> str:\n",
        "    if not gcs_path.startswith(\"gs://\"):\n",
        "        raise ValueError(\"Invalid GCS path. Must start with 'gs://'\")\n",
        "\n",
        "    # Remove the 'gs://' prefix\n",
        "    bucket_and_path = gcs_path[5:]\n",
        "\n",
        "    # Construct the console URL\n",
        "    console_url = f\"https://console.cloud.google.com/storage/browser/{bucket_and_path}\"\n",
        "    return console_url\n",
        "\n",
        "url = gcs_path_to_console_url(GCS_DEST_BUCKET)\n",
        "print(f\"Results will be written to your GCS destination path: {GCS_DEST_BUCKET}\\n\", url)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
