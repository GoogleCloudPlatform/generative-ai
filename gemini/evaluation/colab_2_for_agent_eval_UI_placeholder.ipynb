{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZUGfIJwT-H2"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NulM87jyTWJG"
      },
      "source": [
        "# Placeholder of Gen AI Agent Eval SDK (Colab 2 for UI)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WARNING:**\n",
        "\n",
        "This colab contains features under development. Please don't use it for production work."
      ],
      "metadata": {
        "id": "8jQF39UMNpLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goals:**\n",
        "\n",
        "This Colab notebook demonstrates how to use the Gen AI Eval SDK to retrieve an Evaluation Run and view the results."
      ],
      "metadata": {
        "id": "dvmXm-tBNzM-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTK2Y3bRUMce"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authenticate"
      ],
      "metadata": {
        "id": "mqNKLziY0mr3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nax0k_afTVKc"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4_NugC0UFCU"
      },
      "source": [
        "## Install Vertex AI SDK for Gen AI Evaluation Service"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --force-reinstall -q google-cloud-aiplatform[evaluation]"
      ],
      "metadata": {
        "id": "lWaDe8WN0sKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Variables"
      ],
      "metadata": {
        "id": "a1r_ha0J69yQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8-HbNKnUQD3"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "import pandas as pd\n",
        "from vertexai.preview import reasoning_engines\n",
        "from vertexai import agent_engines\n",
        "import os\n",
        "\n",
        "PROJECT_ID = \"\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "LOCATION= \"\"  # @param {type: \"string\", placeholder: \"us-central1\", isTemplate: true}\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", LOCATION)\n",
        "EVAL_RUN_ID= \"\"  # @param {type: \"string\", placeholder: \"[your-eval-run-id]\", isTemplate: true}\n",
        "\n",
        "\n",
        "from vertexai import Client, types\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "client = Client(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display Gen AI Agent Evaluation Results"
      ],
      "metadata": {
        "id": "S_i7sS3mMu_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_run = client.evals.get_evaluation_run(\n",
        "    name=EVAL_RUN_ID,\n",
        "    include_evaluation_items=True\n",
        ")\n",
        "evaluation_run.show()"
      ],
      "metadata": {
        "id": "rCb8quDHMfIm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
