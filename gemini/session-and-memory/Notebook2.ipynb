{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aada2b3",
   "metadata": {
    "id": "XqAp8OzQRwgW"
   },
   "source": [
    "# Building Intelligent Agents: Google ADK Memory - Long-Term Knowledge (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820bc72a",
   "metadata": {
    "id": "CQecS8q7RwgX"
   },
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "This section covers the initial setup required to run the notebook, including installing libraries and configuring the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1137a868",
   "metadata": {
    "id": "cZh_oosDRwgX"
   },
   "source": [
    "#### 1.1. Install Dependencies\n",
    "\n",
    "Install necessary Python packages: google-adk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6441f6d2",
   "metadata": {
    "id": "QOSBNcI_RwgY"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet google-adk==1.16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0b365",
   "metadata": {
    "id": "EVCnulv_RwgY"
   },
   "source": [
    "#### 1.2. Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce318f79",
   "metadata": {
    "id": "MPitc9uoRwgY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT_ID = \"[your-project-name]\"  # @param {type:\"string\"}\n",
    "if not PROJECT_ID:\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
    "GOOGLE_GENAI_USE_VERTEXAI = \"1\" # Use Vertex AI API\n",
    "\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = LOCATION\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = GOOGLE_GENAI_USE_VERTEXAI # Use Vertex AI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e4baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Authentication - only required for Google Colab Notebooks\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e424a49",
   "metadata": {
    "id": "M64uOep5RwgY"
   },
   "source": [
    "#### Overview: From Conversations to Knowledge\n",
    "\n",
    "In Part 1, we transformed stateless LLMs into conversational agents using **Sessions** - giving them the ability to remember within a single conversation. But there's a limitation: when you start a new session, all those valuable insights about user preferences, learned patterns, and important context vanish like morning mist.\n",
    "\n",
    "**The Challenge:** Imagine a personal assistant who forgets everything about you every time you start a new conversation. They wouldn't remember that you prefer concise answers, that you're learning Python, or that you mentioned being colorblind last week. This is the gap between conversation-level memory (Sessions) and true personalization.\n",
    "\n",
    "**The Solution:** In this notebook, we'll give our agents **long-term memory** - a persistent, searchable knowledge store that transcends individual conversations. Think of it as upgrading from sticky notes (Sessions) to a well-organized filing system (Memory) that your agent can reference across all interactions.\n",
    "\n",
    "**What you'll learn:**\n",
    "- The fundamental difference between Sessions and Memory in agent architecture\n",
    "- How to implement persistent memory using ADK's Memory Services\n",
    "- Strategies for extracting and storing valuable information from conversations\n",
    "- Best practices for searching and utilizing stored memories\n",
    "- The relationship between working memory (Session State) and long-term memory\n",
    "\n",
    "**Time:** 20-25 minutes\n",
    "\n",
    "By the end of this notebook, your agents will be able to learn from past interactions and provide truly personalized experiences that improve over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a8243",
   "metadata": {
    "id": "7lSCKGy-mOW3"
   },
   "source": [
    "## 2. Understanding ADK Memory Services\n",
    "\n",
    "### 2.1. The Architecture of Memory\n",
    "\n",
    "In the previous notebook, we learned that Sessions are containers for conversations. Now, let's understand how Memory fits into the bigger picture:\n",
    "\n",
    "```\n",
    "ðŸ“± Application\n",
    "  â””â”€â”€ ðŸ‘¤ Users\n",
    "       â””â”€â”€ ðŸ’¬ Sessions (Conversations)\n",
    "            â”œâ”€â”€ ðŸ“ Events (User messages & Agent responses)\n",
    "            â””â”€â”€ ðŸ§  State (Working memory for current conversation)\n",
    "\n",
    "       â””â”€â”€ ðŸ—„ï¸ Memory (Long-term knowledge across sessions)\n",
    "            â”œâ”€â”€ ðŸ“š Extracted insights from past sessions\n",
    "            â”œâ”€â”€ ðŸ” Searchable knowledge base\n",
    "            â””â”€â”€ ðŸŽ¯ User preferences and patterns\n",
    "```\n",
    "\n",
    "ADK memory services implement the [`BaseMemoryService`](https://github.com/google/adk-python/blob/main/src/google/adk/memory/base_memory_service.py) interface, which provides methods for:\n",
    "- **Storing memories**: Converting session events into searchable knowledge\n",
    "- **Searching memories**: Finding relevant information based on queries\n",
    "- **Managing lifecycle**: Handling memory persistence and retrieval\n",
    "\n",
    "### 2.2. Sessions vs Memory: Key Differences\n",
    "\n",
    "| Aspect | Sessions | Memory |\n",
    "|--------|----------|---------|\n",
    "| **Scope** | Single conversation | Across all conversations |\n",
    "| **Lifespan** | Temporary (conversation duration) | Persistent (indefinite) |\n",
    "| **Content** | Full conversation history | Extracted, curated knowledge |\n",
    "| **Purpose** | Maintain context in conversation | Build long-term understanding |\n",
    "| **Search** | Sequential access | Semantic/keyword search |\n",
    "| **Storage Size** | Limited by context window | Can be extensive |\n",
    "\n",
    "Think of it this way:\n",
    "- **Sessions** = Your agent's short-term memory (like remembering a phone number while dialing)\n",
    "- **Memory** = Your agent's long-term memory (like remembering a friend's birthday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6272a",
   "metadata": {
    "id": "HbfOhKeJNjMk"
   },
   "source": [
    "### Imports & Helper functions\n",
    "\n",
    "Helper function(`run_session`) job is to prepare a session and run user queries using the runner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2792c59e",
   "metadata": {
    "id": "5zrT0tycRwgZ"
   },
   "outputs": [],
   "source": [
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import BaseSessionService\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.memory import InMemoryMemoryService\n",
    "from google.adk.tools import load_memory\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "\n",
    "async def run_session(runner_instance: Runner, user_queries: list[str] | str = None, session_name: str = \"default\"):\n",
    "    \"\"\"\n",
    "    Helper function that manages a complete conversation session, handling session\n",
    "    creation/retrieval, query processing, and response streaming. It supports\n",
    "    both single queries and multiple queries in sequence.\n",
    "\n",
    "    Args:\n",
    "        runner_instance (Runner): The ADK Runner instance that manages the\n",
    "            conversation flow between user and agent.\n",
    "        user_queries (list[str] | str | None): Either a single query string,\n",
    "            a list of query strings to process sequentially, or None if no\n",
    "            queries are provided.\n",
    "        session_name (str): A unique identifier for the session. Defaults to\n",
    "            \"default\". Used to resume previous conversations or start new ones.\n",
    "\n",
    "    Returns:\n",
    "        None: This function prints the conversation to stdout rather than\n",
    "            returning values.\n",
    "\n",
    "    Example:\n",
    "        >>> await run_session(runner, \"What is the capital of France?\", \"geography-session\")\n",
    "        >>> await run_session(runner, [\"Hello!\", \"What's my name?\"], \"user-intro-session\")\n",
    "\n",
    "    Note:\n",
    "        - If a session with the given name already exists, it will be resumed.\n",
    "    \"\"\"\n",
    "    # Display the session identifier for tracking\n",
    "    print(f\"\\n ### Session: {session_name}\")\n",
    "\n",
    "    # Attempt to create a new session or retrieve an existing one\n",
    "    try:\n",
    "        session = await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=session_name)\n",
    "    except:\n",
    "        session = await session_service.get_session(app_name=APP_NAME, user_id=USER_ID, session_id=session_name)\n",
    "\n",
    "    # Process queries if provided\n",
    "    if user_queries:\n",
    "        # Convert single query to list for uniform processing\n",
    "        if type(user_queries) == str:\n",
    "            user_queries = [user_queries]\n",
    "\n",
    "        # Process each query in the list sequentially\n",
    "        for query in user_queries:\n",
    "            # Display the user's query\n",
    "            print(f\"\\nUser > {query}\")\n",
    "\n",
    "            # Convert the query string to the ADK Content format\n",
    "            query = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "\n",
    "            # Stream the agent's response asynchronously\n",
    "            async for event in runner_instance.run_async(user_id=USER_ID, session_id=session.id, new_message=query):\n",
    "                # Check if the event contains valid content\n",
    "                if event.content and event.content.parts:\n",
    "                    # Filter out empty or \"None\" responses before printing\n",
    "                    if event.content.parts[0].text != \"None\" and event.content.parts[0].text:\n",
    "                        # Display the model's response with the model name prefix\n",
    "                        print(f\"{MODEL_NAME} > \", event.content.parts[0].text)\n",
    "    else:\n",
    "        print(\"No queries!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa654c",
   "metadata": {
    "id": "HAw5Ve50N_Pd"
   },
   "source": [
    "## 3. Building Our First Memory-Enabled Agent\n",
    "\n",
    "### 3.1. Starting Simple: Agent Without Memory\n",
    "\n",
    "Let's first create a basic agent setup. Notice that we're initializing both a `SessionService` (for conversation history) and a `MemoryService` (for long-term knowledge), but our agent doesn't yet know how to use the memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db80079e",
   "metadata": {
    "id": "_PN1wl91RwgZ"
   },
   "outputs": [],
   "source": [
    "APP_NAME = \"MemoryExampleApp\"\n",
    "USER_ID = \"user-123\"\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "\n",
    "session_service = InMemorySessionService()\n",
    "memory_service = InMemoryMemoryService()\n",
    "\n",
    "user_agent = LlmAgent(\n",
    "    model=MODEL_NAME,\n",
    "    instruction=\"Answer the user's questions in simple words.\",\n",
    "    name=APP_NAME,\n",
    ")\n",
    "\n",
    "runner = Runner(\n",
    "    agent=user_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecef080",
   "metadata": {
    "id": "GS-QTV87sV9v"
   },
   "source": [
    "### 3.2. Testing Session Memory (Within Conversation)\n",
    "\n",
    "First, let's verify that our agent can remember information within a single session, just like we learned in Part 1. This establishes our baseline - the agent remembers because both queries are in the same conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8630aa2",
   "metadata": {
    "id": "FEzbl4KtRwgZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: test-run-01\n",
      "\n",
      "User > My favorite color is BlueGreen. Can you write a Haiku\n",
      "gemini-2.5-flash-lite >  BlueGreen is a fun color,\n",
      "Like the ocean and the trees,\n",
      "Nature's lovely blend.\n",
      "\n",
      "User > What is my favorite color\n",
      "gemini-2.5-flash-lite >  Your favorite color is BlueGreen.\n"
     ]
    }
   ],
   "source": [
    "user_queries = [\n",
    "    \"My favorite color is BlueGreen. Can you write a Haiku\",\n",
    "    \"What is my favorite color\",\n",
    "]\n",
    "\n",
    "await run_session(runner, user_queries, \"test-run-01\")\n",
    "\n",
    "## Example response: ##\n",
    "# User > My favorite color is BlueGreen. Can you write a Haiku\n",
    "# Model > A color so rare,\n",
    "# Blue meets green, a lovely blend,\n",
    "# Nature's soft embrace.\n",
    "#\n",
    "# User > What is my favorite color\n",
    "# Model > Your favorite color is BlueGreen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f4d785-899c-458c-8035-6bfc41e047a1",
   "metadata": {},
   "source": [
    "## 4. From Sessions to Memory: The Transfer Process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc8648b",
   "metadata": {
    "id": "4ikwQswKUR5o"
   },
   "source": [
    "### 4.1. Understanding the Memory Creation Workflow\n",
    "\n",
    "Now comes the crucial part - converting conversation history into searchable long-term memory. This is like taking notes from a meeting and filing them in a knowledge base for future reference.\n",
    "\n",
    "The workflow looks like this:\n",
    "1. **Conversation happens** â†’ Events stored in Session\n",
    "2. **Extract valuable information** â†’ Identify what's worth remembering\n",
    "3. **Store in Memory** â†’ Make it searchable across sessions\n",
    "4. **Future conversations** â†’ Agent can access this knowledge\n",
    "\n",
    "Let's walk through this process step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b59f851",
   "metadata": {
    "id": "r_PC0wrWUhlU"
   },
   "source": [
    "### 4.2. Step 1: Retrieving Session Events\n",
    "\n",
    "First, let's fetch the conversation we just had. Remember, at this point, the information only exists in the session - not in long-term memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a24a843c",
   "metadata": {
    "id": "0TylRErJLiJA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user > My favorite color is BlueGreen. Can you write a Haiku\n",
      "model > BlueGreen is a fun color,\n",
      "Like the ocean and the trees,\n",
      "Nature's lovely blend.\n",
      "user > What is my favorite color\n",
      "model > Your favorite color is BlueGreen.\n"
     ]
    }
   ],
   "source": [
    "session = await session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=\"test-run-01\"\n",
    ")\n",
    "\n",
    "for each in session.events:\n",
    "    print(f'{each.content.role} > {each.content.parts[0].text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5e089",
   "metadata": {},
   "source": [
    "### 4.3. Step 2: Checking Memory Status\n",
    "\n",
    "Let's verify that our memory service is currently empty. The `_session_events` is an internal structure that shows what's stored in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f0e802",
   "metadata": {
    "id": "Fd6mnZWtYFOl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if memory service has any stored memories yet\n",
    "memory_service._session_events\n",
    "\n",
    "# Example response:\n",
    "# {}  # Empty dictionary - no memories stored yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2603663c",
   "metadata": {},
   "source": [
    "### 4.4. Step 3: Transferring Session to Memory\n",
    "\n",
    "Now for the key moment - we'll transfer our conversation history from the temporary session storage to permanent memory. This is where the magic happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dce559e",
   "metadata": {
    "id": "3MX5tfyTO4Ge"
   },
   "outputs": [],
   "source": [
    "# Transfer the entire conversation from session to long-term memory\n",
    "# This makes the conversation searchable across future sessions\n",
    "await memory_service.add_session_to_memory(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ed3e5",
   "metadata": {},
   "source": [
    "### 4.5. Step 4: Verifying Memory Storage\n",
    "\n",
    "Let's verify that our conversation has been successfully stored in memory. Notice how the memory is organized by app, user, and session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8977c06",
   "metadata": {
    "id": "1N-RV8uIKRPb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "App: MemoryExampleApp/user-123, User: test-run-01\n",
      "Role: user > My favorite color is BlueGreen. Can you write a Haiku\n",
      "Role: model > BlueGreen is a fun color,\n",
      "Like the ocean and the trees,\n",
      "Nature's lovely blend.\n",
      "Role: user > What is my favorite color\n",
      "Role: model > Your favorite color is BlueGreen.\n"
     ]
    }
   ],
   "source": [
    "# Inspect what's now stored in the memory service\n",
    "# This shows the hierarchical structure: App -> User -> Session -> Events\n",
    "\n",
    "for app_user, user_sessions in memory_service._session_events.items():\n",
    "    for user_session, session_events in user_sessions.items():\n",
    "        print('----------------------')\n",
    "        print(f'App: {app_user}, User: {user_session}')\n",
    "        for each in session_events:\n",
    "            print(f'Role: {each.content.role} > {each.content.parts[0].text}')\n",
    "\n",
    "# Example response:\n",
    "# ----------------------\n",
    "# App: MemoryExampleApp/user-123, User: test-run-01\n",
    "# Role: user > My favorite color is BlueGreen. Can you write a Haiku\n",
    "# Role: model > Sure, I can write a haiku about your favorite color, BlueGreen!\n",
    "# ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a5ca7",
   "metadata": {},
   "source": [
    "### 4.6. Step 5: Testing Memory Search\n",
    "\n",
    "Now that we have memories stored, let's test the search functionality. This is what allows agents to find relevant information from past conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc7e41e",
   "metadata": {
    "id": "0mIs3JybXtfq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SearchMemoryResponse(memories=[MemoryEntry(content=Content(\n",
       "  parts=[\n",
       "    Part(\n",
       "      text='My favorite color is BlueGreen. Can you write a Haiku'\n",
       "    ),\n",
       "  ],\n",
       "  role='user'\n",
       "), author='user', timestamp='2025-10-25T20:08:56.784402'), MemoryEntry(content=Content(\n",
       "  parts=[\n",
       "    Part(\n",
       "      text=\"\"\"BlueGreen is a fun color,\n",
       "Like the ocean and the trees,\n",
       "Nature's lovely blend.\"\"\"\n",
       "    ),\n",
       "  ],\n",
       "  role='model'\n",
       "), author='MemoryExampleApp', timestamp='2025-10-25T20:08:56.785076'), MemoryEntry(content=Content(\n",
       "  parts=[\n",
       "    Part(\n",
       "      text='What is my favorite color'\n",
       "    ),\n",
       "  ],\n",
       "  role='user'\n",
       "), author='user', timestamp='2025-10-25T20:08:58.642574'), MemoryEntry(content=Content(\n",
       "  parts=[\n",
       "    Part(\n",
       "      text='Your favorite color is BlueGreen.'\n",
       "    ),\n",
       "  ],\n",
       "  role='model'\n",
       "), author='MemoryExampleApp', timestamp='2025-10-25T20:08:58.643092')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for memories related to \"favorite color\"\n",
    "# The search looks through all stored conversations for this user\n",
    "\n",
    "await memory_service.search_memory(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    query=\"favorite color\",\n",
    ")\n",
    "# Example response:\n",
    "# SearchMemoryResponse(memories=[MemoryEntry(content=Content(\n",
    "#   parts=[\n",
    "#     Part(\n",
    "#       text='My favorite color is BlueGreen. Can you write a Haiku'\n",
    "#     ),\n",
    "#   ],\n",
    "#   role='user'\n",
    "#  ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b206065",
   "metadata": {},
   "source": [
    "Let's test searching for something that wasn't discussed - this should return empty results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa90bb67",
   "metadata": {
    "id": "w_ukxLxNYr6n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SearchMemoryResponse(memories=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for memories about \"trip plan\" - which we never discussed\n",
    "# This demonstrates that search only returns relevant memories\n",
    "\n",
    "await memory_service.search_memory(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    query=\"trip plan\",\n",
    ")\n",
    "\n",
    "# Example response\n",
    "# SearchMemoryResponse(memories=[])  # Empty - no memories about trip plans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e645efdd",
   "metadata": {
    "id": "Q9war9LKZSvA"
   },
   "source": [
    "**Key Insight:** The `search_memory` function only returns memories that actually exist and match the query. This helps keep agent responses relevant and grounded in actual past conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e1b7d2",
   "metadata": {
    "id": "EtfHyKC1jQIQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method search_memory in module google.adk.memory.in_memory_memory_service:\n",
      "\n",
      "async search_memory(*, app_name: 'str', user_id: 'str', query: 'str') -> 'SearchMemoryResponse' method of google.adk.memory.in_memory_memory_service.InMemoryMemoryService instance\n",
      "    Searches for sessions that match the query.\n",
      "\n",
      "    Args:\n",
      "        app_name: The name of the application.\n",
      "        user_id: The id of the user.\n",
      "        query: The query to search for.\n",
      "\n",
      "    Returns:\n",
      "        A SearchMemoryResponse containing the matching memories.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(memory_service.search_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4872d6",
   "metadata": {
    "id": "lB-G6uxHsUdO"
   },
   "source": [
    "## 5. Empowering Agents with Memory Tools\n",
    "\n",
    "There are two main architectural patterns for retrieving or loading memories into an agent's context within the Agent Development Kit (ADK): **Proactive Retrieval (Static Loading)** and **Reactive Retrieval (Memory-as-a-Tool)**.\n",
    "\n",
    "1. **Proactive Retrieval** ensures context is always available by automatically loading memories at the beginning of every conversation turn. This uses the `PreloadMemoryTool` built into ADK. Although this pattern guarantees the context is present, it can introduce **unnecessary latency for turns that do not require memory**.\n",
    "\n",
    "2. **Reactive Retrieval**, often referred to as `Memory-as-a-Tool`, grants the agent the autonomy to decide when memory access is necessary. This is implemented using the LoadMemoryTool, which the agent invokes when its reasoning determines that past context is needed to answer a query. This approach is generally more efficient as the latency and cost of retrieval are incurred only when required.\n",
    "\n",
    "How to build custom implementations for Proactive and Reactive retrievals:\n",
    "â€¢ Proactive Retrieval can be implemented via a `custom callback` to manually retrieve memories and append them to the system instructions.\n",
    "â€¢ Reactive Retrieval can be implemented via a `custom tool` where the developer defines what type of information might be available, enabling a more informed decision by the LLM on when to query.\n",
    "\n",
    "\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    subgraph A[\"Memories Retrieval Patterns\"];\n",
    "        subgraph BB[\"Proactive Retrieval (Static Loading)\" ]\n",
    "            B1[\"--> 1. PreloadMemoryTool\"]\n",
    "            B2[\"--> 2. Custom callback (on_before_agent_call)\"]\n",
    "        end\n",
    "        subgraph CC[\"Reactive Retrieval (Memory-as-a-Tool)\"]\n",
    "            C1[\"--> 1. LoadMemoryTool\"];\n",
    "            C2[\"--> 2. Custom Tool Implementation\"];\n",
    "        end\n",
    "    end\n",
    "```\n",
    "\n",
    "### 5.1. The Problem: Agent Can't Access Memory Yet\n",
    "\n",
    "So far, we've stored memories, but our agent doesn't know how to use them. It's like having a filing cabinet full of valuable information but no way to access it. Let's fix that by giving our agent the `load_memory` tool.\n",
    "\n",
    "### 5.2. Upgrading the Agent with Memory Access\n",
    "\n",
    "The `load_memory` tool allows agents to search through stored memories during conversations. This is the key to making agents truly personalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8f4e578",
   "metadata": {
    "id": "S1oKDpYEZsBP"
   },
   "outputs": [],
   "source": [
    "from google.adk.tools import load_memory # Tool to query memory\n",
    "\n",
    "user_agent = LlmAgent(\n",
    "    model=MODEL_NAME,\n",
    "    instruction=\"Answer the user's questions in simple words.\",\n",
    "    name=APP_NAME,\n",
    "    tools=[load_memory] # Equip Agent with Tools to call memory\n",
    ")\n",
    "\n",
    "runner = Runner(\n",
    "    agent=user_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134d60a8",
   "metadata": {},
   "source": [
    "### 5.3. Testing Memory Access Across Sessions\n",
    "\n",
    "Now for the moment of truth - let's start a **completely new session** and see if our agent can remember information from the previous conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6debc471",
   "metadata": {
    "id": "XwZ5R1JmZr94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: test-run-02\n",
      "\n",
      "User > What is my favorite color\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.5-flash-lite >  \n",
      "Your favorite color is BlueGreen.\n"
     ]
    }
   ],
   "source": [
    "# Start a NEW session - this is crucial!\n",
    "# The agent has no conversation history from test-run-01\n",
    "# But it DOES have access to memories via the load_memory tool\n",
    "\n",
    "user_queries = [\n",
    "    \"What is my favorite color\",\n",
    "]\n",
    "\n",
    "await run_session(runner, user_queries, \"test-run-02\") # Note: New session\n",
    "\n",
    "# Expected behavior:\n",
    "# The agent will use the load_memory tool to search for information\n",
    "# about favorite color, find the memory from test-run-01,\n",
    "# and correctly answer \"BlueGreen\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3653e8-7ed4-4ca6-aa30-3d5b6b60d1d2",
   "metadata": {},
   "source": [
    "### 5.4. Proactive Memory Loading (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d018defb-94ee-48bf-b090-47fbda74ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.tools.preload_memory_tool import PreloadMemoryTool # Tool to query memory\n",
    "\n",
    "user_agent = LlmAgent(\n",
    "    model=MODEL_NAME,\n",
    "    instruction=\"Answer the user's questions in simple words.\",\n",
    "    name=APP_NAME,\n",
    "    tools=[load_memory] # Equip Agent with Tools to call memory\n",
    ")\n",
    "\n",
    "runner = Runner(\n",
    "    agent=user_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9079919-b0a5-4499-8cf6-2de3aa8fac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: test-run-04\n",
      "\n",
      "User > What is my favorite color\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.5-flash-lite >  Your favorite color is BlueGreen.\n"
     ]
    }
   ],
   "source": [
    "user_queries = [\n",
    "    \"What is my favorite color\",\n",
    "]\n",
    "\n",
    "await run_session(runner, user_queries, \"test-run-04\") # Note: New session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b928528-ee20-4b84-b9ef-d31e485ab03a",
   "metadata": {},
   "source": [
    "As you have noticed, we are able to recall information using a pro-active approach. Now lets query the model with information, which does not need to do memory loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b8d5533-b9bc-455a-a4bd-35109f7a7386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: test-run-04\n",
      "\n",
      "User > What is the capital of India?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.5-flash-lite >  The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "user_queries = [\n",
    "    \"What is the capital of India?\",\n",
    "]\n",
    "\n",
    "await run_session(runner, user_queries, \"test-run-04\") # Note: New session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f016182b-5b07-495c-b37f-44dbecd0f12c",
   "metadata": {},
   "source": [
    "Expected logging messages from the above executions: `Warning: there are non-text parts in the response:..`\n",
    "\n",
    "The `PreloadMemoryTool` loads information independent of the query's need. To load memories from active chat conversations check https://google.github.io/adk-docs/sessions/memory/#using-memory-in-your-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7cf076",
   "metadata": {
    "id": "t0VUUOLJnrx_"
   },
   "source": [
    "## 6. What You've Built\n",
    "\n",
    "ðŸŽ‰ **Congratulations!** You've successfully transformed a stateless LLM into an intelligent agent with persistent memory that spans across conversations.\n",
    "\n",
    "### Your Journey Recap:\n",
    "\n",
    "1. **Understood the Challenge**: Recognized how Sessions provide only temporary memory within a single conversation\n",
    "2. **Implemented Memory Storage**: Used `InMemoryMemoryService` to create a searchable knowledge base\n",
    "3. **Transferred Knowledge**: Learned how to extract valuable information from sessions and store it as memories\n",
    "4. **Enabled Memory Access**: Equipped your agent with the `load_memory` tool to access past conversations\n",
    "5. **Achieved Persistence**: Created an agent that remembers user preferences across different sessions\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **Sessions vs Memory**: Sessions handle conversation flow; Memory provides long-term knowledge\n",
    "- **Memory is Searchable**: Unlike sessions, memories can be queried semantically\n",
    "- **Tools Enable Access**: The `load_memory` tool bridges the gap between stored memories and agent capabilities\n",
    "- **User-Specific**: Memories are segregated by user, ensuring privacy and personalization\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In production environments, you'll want to:\n",
    "- Use **Vertex AI Memory Bank** for scalable, persistent memory storage\n",
    "- Implement memory curation strategies to extract the most valuable insights\n",
    "- Add memory expiration policies for data governance\n",
    "- Consider using artifacts for storing structured data and files\n",
    "\n",
    "Your agents can now build relationships with users over time, learning preferences and providing increasingly personalized experiences. This is the foundation of truly intelligent conversational AI!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e3f15",
   "metadata": {
    "id": "QqZck2gnRwgZ"
   },
   "source": [
    "#### Read more\n",
    "* [Google ADK Memory](https://google.github.io/adk-docs/sessions/memory/)\n",
    "* [Google ADK - Vertex AI Memory Bank](https://github.com/GoogleCloudPlatform/generative-ai/blob/62efa4db92dd6aeff735e8f0f29bffa7c016eba4/gemini/agent-engine/memory/get_started_with_memory_bank_adk.ipynb)\n",
    "* [Google ADK - Artifacts](https://google.github.io/adk-docs/artifacts/#what-are-artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826634e7-d745-4e41-aebb-354129471a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
