{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "068fcf807336"
   },
   "source": [
    "# Search tuning in Vertex AI Search\n",
    "\n",
    "<table align=\"center\">\n",
    "  <td style=\"text-align: center\" width=\"25%\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/search/tuning/vertexai-search-tuning.ipynb\">\n",
    "      <img width=\"32\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\" width=\"25%\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fsearch%2Ftuning%2Fvertexai-search-tuning.ipynb\">\n",
    "      <img width=\"32\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\" width=\"25%\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/search/tuning/vertexai-search-tuning.ipynb\">\n",
    "      <img width=\"32\" src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\" width=\"25%\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/search/tuning/vertexai-search-tuning.ipynb\">\n",
    "      <img width=\"32\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    " \n",
    "<b>Share to:</b>\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\" width=\"10%\">\n",
    "    <a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/search/tuning/vertexai-search-tuning.ipynb\" target=\"_blank\">\n",
    "        <img width=\"20\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "    </a>\n",
    "   </td>\n",
    "  <td style=\"text-align: center\" width=\"10%\">\n",
    "    <a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/search/tuning/vertexai-search-tuning.ipynb\" target=\"_blank\">\n",
    "        <img width=\"20\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\" width=\"10%\">\n",
    "    <a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/search/tuning/vertexai-search-tuning.ipynb\" target=\"_blank\">\n",
    "        <img width=\"20\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/X_logo_2023_original.svg\" alt=\"X logo\">\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\" width=\"10%\">\n",
    "    <a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/search/tuning/vertexai-search-tuning.ipynb\" target=\"_blank\">\n",
    "        <img width=\"20\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\" width=\"10%\">\n",
    "    <a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/search/tuning/vertexai-search-tuning.ipynb\" target=\"_blank\">\n",
    "        <img width=\"20\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "    </a>\n",
    "  </td>\n",
    "</table>            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ca3c8a638e33"
   },
   "source": [
    "| Author |\n",
    "| --- |\n",
    "| [Jincheol Kim](https://github.com/JincheolKim) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80c810fbe603"
   },
   "source": [
    "When users try to provide a search service over their archived documents and data, search performance may not meet the performance expectation all the time. The performance of Vertex AI Search can be measured in two aspects: the accuracy and the relevance of the search results, and the correctness of the summarized responses from the search results with correct annotations and references to the source document. Among the two aspects of the search performances, the accuracy and the relevance of the search results should be enhanced by generating embedding vectors which are more relevant semantically with document chunking and other document processing methods. The correctness of the summarized responses generated from the backend LLM (Gemini) behind the Vertex AI Search endpoint can be enhanced by tuning the backend LLM with some additional relevant data. The process of tuning the backend LLM with some domain-specific data is what Vertex AI Search Tuning is for.\n",
    "  \n",
    "Before we tune the backend LLM behind Vertex AI Search, we should the prepare the raw text data in a specific JSONL format with a question-answer mapping file in the tab-separated table format. We will use some FAQ documents from an open source project (Kubernetes) to tune the backend LLM to enhance answers on the questions on Kubernetes. After we learn how we prepare the tuning data in JSONL and TSV format, we will learn how we can configure a search tuning job and submit it to Vertex AI.\n",
    "     \n",
    "To learn more about the search tuning process, please refer to the following documents in the Google Cloud Documentation.\n",
    "     \n",
    "- [Improve search results with search tuning](https://cloud.google.com/generative-ai-app-builder/docs/tune-search)\n",
    "- [Create a search data store](https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es)\n",
    "- [Create a search app](https://cloud.google.com/generative-ai-app-builder/docs/create-engine-es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11198a79d42c"
   },
   "source": [
    "## Overview\n",
    "\n",
    "![Key user journey of the search tuning in Vertex AI Search](https://storage.googleapis.com/github-repo/generative-ai/search/tuning/images/key_user_journey_search_tuning.png)\n",
    "\n",
    "* Prepare your data for tuning\n",
    "    - The datasets should be prepared in JSONL format with identifier-text pairs.\n",
    "    - The mapping between query and answer texts should be described in tab-separated values (TSV) formats.\n",
    "* Update the datastore with the additional documents\n",
    "    - Before we update the datastore attached to the search app, the additional documents and data for tuning should be uploaded to the bucket in Cloud Storage.\n",
    "    - After uploading the new documents and data onto the bucket in Cloud Storage, the datastore is refreshed just by creating the datastore with the same configuration used in the previous creation. In the refresh process, we can see that only the files just added are used to generate new search indexes at the console interface.\n",
    "* Rebuild the search app with the updated datastore\n",
    "    - After the refresh of the datastore is completed, the search app must be rebuilt to be connected to the updated datastore.\n",
    "\n",
    "In order to obtain the correct results with the additional documents and data, users must rebuild the search app after they rebuilt the datastore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d998a5140b2"
   },
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7de8816128de"
   },
   "source": [
    "### Install Vertex AI SDK and other required packages\n",
    "\n",
    "We will install some dependencies to run the cells in this notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "35b342466ed4"
   },
   "source": [
    "%pip install --upgrade --user --quiet google-cloud-aiplatform google-cloud-discoveryengine langchain_google_community langchain langchain-google-vertexai langchain-google-community[vertexaisearch] shortuuid"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f10b11bebfd1"
   },
   "source": [
    "## Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
    "\n",
    "The restart might take a minute or longer. After it has restarted, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d76628df8180"
   },
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c12448f2e71"
   },
   "source": [
    "## Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d8d593172549"
   },
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b3a2e9b94d5"
   },
   "source": [
    "## Set Google Cloud project information and initialize Vertex AI SDK for Python\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1800f6c7238e",
    "ExecuteTime": {
     "end_time": "2025-04-16T07:40:53.018955Z",
     "start_time": "2025-04-16T07:40:51.203038Z"
    }
   },
   "source": [
    "# Imports common packages\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import shortuuid\n",
    "import vertexai\n",
    "import json\n",
    "import re\n",
    "import platform\n",
    "\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.api_core.operation import Operation\n",
    "from google.cloud import discoveryengine"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:41:03.200220Z",
     "start_time": "2025-04-16T07:40:54.961551Z"
    }
   },
   "cell_type": "code",
   "source": "!gcloud auth login",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\r\n",
      "\r\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=oGuw7onEHJDFU4awa0SaSKahidJ4Ti&access_type=offline&code_challenge=hbMKFpFsyktl1HlYl4jvJdQEZXr5Zwr7SCFUGBP_mDQ&code_challenge_method=S256\r\n",
      "\r\n",
      "\r\n",
      "You are now logged in as [jincheolkim@jincheolkim.altostrat.com].\r\n",
      "Your current project is [genai-customersupport].  You can change this setting by running:\r\n",
      "  $ gcloud config set project PROJECT_ID\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:41:30.264459Z",
     "start_time": "2025-04-16T07:41:30.261993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use the environment variable if the user doesn't provide Project ID.\n",
    "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "PROJECT_ID = \"genai-customersupport\"\n",
    "LOCATION = \"global\"\n",
    "STORAGE_LOCATION = \"us\"\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "643f6d02011b"
   },
   "source": [
    "## Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts such as datasets."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f5c2d63395c1",
    "ExecuteTime": {
     "end_time": "2025-04-16T07:41:39.523846Z",
     "start_time": "2025-04-16T07:41:39.521099Z"
    }
   },
   "source": [
    "PUBLIC_DATA_SOURCE_URI = f\"gs://github-repo/generative-ai/search/tuning\"\n",
    "BASE_DATA_SOURCE_URI = f\"gs://github-repo/generative-ai/search/tuning/awesome_rlhf\"\n",
    "BUCKET_URI = f\"gs://sample-search-tuning-{PROJECT_ID}\"  # @param {type:\"string\"}\n",
    "TUNING_DATA_PATH_SOURCE = \"gs://github-repo/generative-ai/search/tuning/tuning_data\"\n",
    "TUNING_DATA_PATH_LOCAL = f\"./tuning_data\"\n",
    "TUNING_DATA_PATH_REMOTE = f\"{BUCKET_URI}/tuning_data\"\n",
    "SEARCH_DATASTORE_PATH_REMOTE = f\"{BUCKET_URI}/rlhf-datastore\"\n",
    "SEARCH_DATASTORE_ID = f\"search-datastore-{PROJECT_ID}-{shortuuid.uuid().lower()}\"\n",
    "SEARCH_DATASTORE_NAME = \"RLHF-ARTICLE-DATASTORE\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85597b5e35a8"
   },
   "source": [
    "\"**If your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "abaea548b38b",
    "ExecuteTime": {
     "end_time": "2025-04-16T07:41:49.823500Z",
     "start_time": "2025-04-16T07:41:41.253973Z"
    }
   },
   "source": [
    "! gcloud storage buckets create --location={STORAGE_LOCATION} --project={PROJECT_ID} --enable-hierarchical-namespace --uniform-bucket-level-access -b {BUCKET_URI}\n",
    "! mkdir $TUNING_DATA_PATH_LOCAL\n",
    "! gcloud storage cp $TUNING_DATA_PATH_SOURCE/* $TUNING_DATA_PATH_LOCAL"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://sample-search-tuning-genai-customersupport/...\r\n",
      "mkdir: ./tuning_data: File exists\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/tuning_data/FAQ-Kubernetes-Client.md to file://./tuning_data/FAQ-Kubernetes-Client.md\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/tuning_data/FAQ-Kubernetes-Client.pdf to file://./tuning_data/FAQ-Kubernetes-Client.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/tuning_data/FAQ.md to file://./tuning_data/FAQ.md\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/tuning_data/FAQ.pdf to file://./tuning_data/FAQ.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/tuning_data/README.md to file://./tuning_data/README.md\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/tuning_data/README.pdf to file://./tuning_data/README.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/tuning_data/corpus_file.jsonl to file://./tuning_data/corpus_file.jsonl\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/tuning_data/query_file.jsonl to file://./tuning_data/query_file.jsonl\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/tuning_data/test_data.tsv to file://./tuning_data/test_data.tsv\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/tuning_data/training_data.tsv to file://./tuning_data/training_data.tsv\r\n",
      "  Completed files 10/10 | 773.4kiB/773.4kiB                                    \r\n",
      "\r\n",
      "Average throughput: 1.5MiB/s\r\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5b4068c0c26"
   },
   "source": [
    "## Prepare the data\n",
    "\n",
    "We will use the following datasets for this notebook. \n",
    "\n",
    "(1) FAQ data from the open source projects Kubernetes and Kubernetes Client. This data is a short list of questions and answers which can be useful to test the working of this notebook in a short period of time.\n",
    "\n",
    "(2) BEIR ([Benchmarking IR datasets](https://github.com/beir-cellar/beir)): BEIR is a heterogeneous benchmark containing diverse IR tasks. It also provides a common and easy framework for evaluation of your NLP-based retrieval models within the benchmark. This public dataset is hosted in Google BigQuery and is included in BigQuery's 1TB/mo of free tier processing. This means that each user receives 1TB of free BigQuery processing every month, which can be used to run queries on this public dataset.\n",
    "    - For an overview, checkout our new wiki page: https://github.com/beir-cellar/beir/wiki.\n",
    "    - For models and datasets, checkout out Hugging Face (HF) page: https://huggingface.co/BeIR.\n",
    "      \n",
    "(3) SciFact ([SciFact](https://huggingface.co/datasets/allenai/scifact)): SciFact, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts, and annotated with labels and rationales.\n",
    "                                                                                     \n",
    "For BEIR and SciFact, the datasets are already prepared in JSONL and TSV formats. You can use them for testing the search tuning feature without any data preprocessing chore. However, the amount of the data of the BEIR and SciFact is large which make the tuning job run too long. Given that, we will try to generate a small amount of the data first to check if the search tuning feature is working correctly with the FAQ data from the Kubernetes project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7d8d04e32e5"
   },
   "source": [
    "This ```generate_source_dataset``` function is a function to read the raw FAQ data from the FAQ and the README documents of the Kubernetes project and to generate the ```corpus_file.jsonl``` and ```query_file.jsonl``` for the tuning job."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6958fb25e38f",
    "ExecuteTime": {
     "end_time": "2025-04-16T07:41:54.227365Z",
     "start_time": "2025-04-16T07:41:54.220236Z"
    }
   },
   "source": [
    "def generate_source_dataset(\n",
    "    source_file, corpus_filepath, query_filepath, cleanup_at_start=True\n",
    "):\n",
    "    '''\n",
    "        Helper function to generate JSONL-format datasets for search tuning.\n",
    "    \n",
    "        Args:\n",
    "            source_file (string): Path to the source files from which the JSONL\n",
    "                                  files will be generated\n",
    "            corpus_filepath (string): Path to the corpus file to which the JSONL\n",
    "                                      formated corpus dataset file will be stored.\n",
    "            query_filepath (string):  Path to the query file to which the JSONL\n",
    "                                      formated query dataset file will be stored.\n",
    "            cleanup_at_start (bool, default=True): Clears the corpus files and\n",
    "                                      the query files generated in the previous time\n",
    "                                      before generating new datasets when the value\n",
    "                                      is True\n",
    "            \n",
    "        Raises:\n",
    "\n",
    "        Returns:\n",
    "            No return values. Two JSONL files. (Corpus File, Query File)\n",
    "    '''\n",
    "    \n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    # If cleanup_at_start is True, this section deletes the corpus files and\n",
    "    # the query files before generating new corpus and query files in JSONL\n",
    "    if cleanup_at_start:\n",
    "        if os.path.isfile(corpus_filepath):\n",
    "            print(f\"Removing previous file: %s\")\n",
    "            os.remove(corpus_filepath)\n",
    "        if os.path.isfile(query_filepath):\n",
    "            print(f\"Removing previous file: %s\")\n",
    "            os.remove(query_filepath)\n",
    "\n",
    "    # This section generates a corpus file dataset in JSONL format\n",
    "    # from the source files.\n",
    "    logging.info(f\"{generate_source_dataset.__name__}: {1}\")\n",
    "    with open(source_file) as f:\n",
    "        line_str = f.readline()\n",
    "        answer = \"\"\n",
    "        answer_flag = False\n",
    "        while line_str:\n",
    "            if re.match(r\"^(#{3})\\s+(.+)$\", line_str):\n",
    "                question = re.split(r\"^(#{3})\\s+(.+)$\", line_str)\n",
    "                question_str = \"\"\n",
    "                len_question = len(question) - 1\n",
    "                reidx = 0\n",
    "                while not (question[len_question - reidx] == \"###\"):\n",
    "                    question_str += question[len_question - reidx]\n",
    "                    reidx += 1\n",
    "                questions.append(question_str)\n",
    "                # print(\"Question: %s\" % question_str)\n",
    "                answer_flag = True\n",
    "                answers.append(str.strip(answer, \"\"))\n",
    "                # print(\"Answer: %s\" % answer)\n",
    "                answer = \"\"\n",
    "            elif answer_flag == True:\n",
    "                answer += line_str\n",
    "            line_str = f.readline()\n",
    "\n",
    "    logging.info(f\"{generate_source_dataset.__name__}: {2}\")\n",
    "    corpus_idx_start = 0\n",
    "    try:\n",
    "        with open(corpus_filepath) as cf:\n",
    "            corpus_idx_start = len(list(enumerate(cf)))\n",
    "    except:\n",
    "        corpus_idx_start = 0\n",
    "\n",
    "    with open(corpus_filepath, \"a\") as cf:\n",
    "        jsonfile = \"\"\n",
    "        idx = corpus_idx_start\n",
    "        print(f\"start idx:%d\" % idx)\n",
    "        for answer in answers:\n",
    "            idx += 1\n",
    "            answer = answer.replace(\"\\\\[\", \"\\\\\\\\[\")\n",
    "            answer = answer.replace(\"\\\\]\", \"\\\\\\\\]\")\n",
    "            answer = answer.replace('\"', '\\\\\"')\n",
    "            json_line = '{{\"_id\": \"ans{:04d}\", \"text\": \"{}\" }}\\n'.format(\n",
    "                idx, str.strip(answer).replace(\"\\n\", \" \")\n",
    "            )\n",
    "            jsonfile += json_line\n",
    "        cf.writelines(jsonfile)\n",
    "\n",
    "    # This section generates a query file dataset in JSONL format\n",
    "    # from the source files.\n",
    "    logging.info(f\"{generate_source_dataset.__name__}: {3}\")\n",
    "    query_idx_start = 0\n",
    "    try:\n",
    "        with open(query_filepath) as qf:\n",
    "            query_idx_start = len(list(enumerate(qf)))\n",
    "    except:\n",
    "        query_idx_start = 0\n",
    "\n",
    "    with open(query_filepath, \"a\") as qf:\n",
    "        jsonfile = \"\"\n",
    "        idx = query_idx_start\n",
    "        print(f\"start idx:%d\" % idx)\n",
    "        for question in questions:\n",
    "            idx += 1\n",
    "            question = question.replace(\"\\\\[\", \"\\\\\\\\[\")\n",
    "            question = question.replace(\"\\\\]\", \"\\\\\\\\]\")\n",
    "            question = question.replace('\"', '\\\\\"')\n",
    "            json_line = '{{ \"_id\": \"que{:04d}\", \"text\": \"{}\" }}\\n'.format(\n",
    "                idx, str.strip(question).replace(\"\\n\", \" \")\n",
    "            )\n",
    "            jsonfile += json_line\n",
    "        qf.writelines(jsonfile)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "180fc88a543e"
   },
   "source": [
    "This ```generate_training_test_dataset``` generates the query-answer mapping in a tab-separated value format to help the tuning job to map the queries and the texts for the answers to the queries from the FAQ."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c241fd547498",
    "ExecuteTime": {
     "end_time": "2025-04-16T07:41:55.829426Z",
     "start_time": "2025-04-16T07:41:55.822142Z"
    }
   },
   "source": [
    "def generate_training_test_dataset(\n",
    "    corpus_filepath,\n",
    "    query_filepath,\n",
    "    training_filepath,\n",
    "    test_filepath,\n",
    "    cleanup_at_start=True,\n",
    "):\n",
    "    '''\n",
    "        Helper function to generate TSV(tab separated values)-format datasets\n",
    "       to map the corpus file and the query file for search tuning.\n",
    "    \n",
    "        Args:\n",
    "            corpus_filepath (string): Path to the corpus file to which the JSONL\n",
    "                                      formated corpus dataset file will be stored.\n",
    "            query_filepath (string):  Path to the query file to which the JSONL\n",
    "                                      formated query dataset file will be stored.\n",
    "            training_filepath (string): Path to the mapping file between the entries\n",
    "                                      in the corpus file and the query file to define\n",
    "                                      a training dataset in TSV-format\n",
    "            test_filepath (string): Path to the mapping file between the entries\n",
    "                                      in the corpus file and the query file to define\n",
    "                                      a test dataset in TSV-format\n",
    "            cleanup_at_start (bool, default=True): Clears the training dataset files and\n",
    "                                      the test dataset files generated in the previous time\n",
    "                                      before generating new datasets when the value is True\n",
    "\n",
    "        Raises:\n",
    "\n",
    "        Returns:\n",
    "            No return values. Two TSV files. (Training Dataset File, Test Dataset File)\n",
    "\n",
    "    '''\n",
    "\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    # If cleanup_at_start is True, this section deletes the training dataset files\n",
    "    # and the test dataset files before generating new TSV dataset files \n",
    "    if cleanup_at_start:\n",
    "        if os.path.isfile(training_filepath):\n",
    "            print(f\"Removing previous file: %s\")\n",
    "            os.remove(training_filepath)\n",
    "        if os.path.isfile(test_filepath):\n",
    "            print(f\"Removing previous file: %s\")\n",
    "            os.remove(test_filepath)\n",
    "\n",
    "    # Opens the corpus dataset file to generate the mapping between the corpus entries\n",
    "    # and the query entries\n",
    "    with open(corpus_filepath) as corpus_file:\n",
    "        line_str = corpus_file.readline()\n",
    "        while line_str:\n",
    "            jsonl = json.loads(line_str, strict=False)\n",
    "            questions.append(jsonl[\"text\"])\n",
    "            line_str = corpus_file.readline()\n",
    "\n",
    "    logging.info(f\"{generate_training_test_dataset.__name__}: {1}\")\n",
    "\n",
    "    # Opens the query dataset file to generate the mapping between the corpus entries\n",
    "    # and the query entries\n",
    "    with open(query_filepath) as query_file:\n",
    "        line_str = query_file.readline()\n",
    "        while line_str:\n",
    "            jsonl = json.loads(line_str, strict=False)\n",
    "            answers.append(jsonl[\"text\"])\n",
    "            line_str = query_file.readline()\n",
    "\n",
    "    logging.info(f\"{generate_training_test_dataset.__name__}: {2}\")\n",
    "\n",
    "    # Opens the training dataset file to generate the mapping between the corpus entries\n",
    "    # and the query entries\n",
    "    with open(training_filepath, \"a\") as trf:\n",
    "        jsonfile = \"\"\n",
    "        json_line = \"query-id\\tcorpus-id\\tscore\\n\"\n",
    "        idx = 1\n",
    "        jsonfile += json_line\n",
    "        len_questions = len(questions)\n",
    "        for question in questions:\n",
    "            json_line = f\"que{idx:04d}\\tans{idx:04d}\\t1\\n\"\n",
    "            jsonfile += json_line\n",
    "            idx = idx + 1\n",
    "            if idx > 0.85 * len_questions:\n",
    "                break\n",
    "        trf.write(jsonfile)\n",
    "\n",
    "    logging.info(f\"{generate_training_test_dataset.__name__}: {3}\")\n",
    "    \n",
    "    # Opens the test dataset file to generate the mapping between the corpus entries\n",
    "    # and the query entries\n",
    "    with open(test_filepath, \"a\") as tef:\n",
    "        jsonfile = \"\"\n",
    "        json_line = \"query-id\\tcorpus-id\\tscore\\n\"\n",
    "        idx = 1\n",
    "        len_questions = len(questions)\n",
    "        jsonfile += json_line\n",
    "        for question in questions:\n",
    "            if idx <= 0.85 * len_questions:\n",
    "                idx = idx + 1\n",
    "            elif idx > 0.85 * len_questions and idx <= len_questions:\n",
    "                json_line = f\"que{idx:04d}\\tans{idx:04d}\\t1\\n\"\n",
    "                jsonfile += json_line\n",
    "                idx = idx + 1\n",
    "        tef.write(jsonfile)\n",
    "\n",
    "    logging.info(f\"{generate_training_test_dataset.__name__}: {4}\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "038afd6614f5",
    "ExecuteTime": {
     "end_time": "2025-04-16T07:41:56.590775Z",
     "start_time": "2025-04-16T07:41:56.572955Z"
    }
   },
   "source": [
    "# Collects the generated JSONL and TSV files with PDF documents\n",
    "# to update the search index after the search tuning\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    datasets = [\n",
    "        \"./tuning_data/FAQ.md\",\n",
    "        \"./tuning_data/FAQ-Kubernetes-Client.md\",\n",
    "        \"./tuning_data/README.md\",\n",
    "    ]\n",
    "    if os.path.isfile(\"./tuning_data/corpus_file.jsonl\"):\n",
    "        os.remove(\"./tuning_data/corpus_file.jsonl\")\n",
    "    if os.path.isfile(\"./tuning_data/query_file.jsonl\"):\n",
    "        os.remove(\"./tuning_data/query_file.jsonl\")\n",
    "\n",
    "    for file in datasets:\n",
    "        print(file)\n",
    "        generate_source_dataset(\n",
    "            file,\n",
    "            \"./tuning_data/corpus_file.jsonl\",\n",
    "            \"./tuning_data/query_file.jsonl\",\n",
    "            cleanup_at_start=False,\n",
    "        )\n",
    "    generate_training_test_dataset(\n",
    "        \"./tuning_data/corpus_file.jsonl\",\n",
    "        \"./tuning_data/query_file.jsonl\",\n",
    "        \"./tuning_data/training_data.tsv\",\n",
    "        \"./tuning_data/test_data.tsv\",\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tuning_data/FAQ.md\n",
      "start idx:0\n",
      "start idx:0\n",
      "./tuning_data/FAQ-Kubernetes-Client.md\n",
      "start idx:56\n",
      "start idx:56\n",
      "./tuning_data/README.md\n",
      "start idx:67\n",
      "start idx:67\n",
      "Removing previous file: %s\n",
      "Removing previous file: %s\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2be63d1eccb3"
   },
   "source": [
    "We create pdf files for the FAQ documents which are importable to the datastore of Vertex AI Search."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8609d45b559b",
    "ExecuteTime": {
     "end_time": "2025-04-16T07:42:13.535503Z",
     "start_time": "2025-04-16T07:41:58.762251Z"
    }
   },
   "source": [
    "# Check if the system is macOS\n",
    "if platform.system() == \"Darwin\":\n",
    "    # Install using Homebrew\n",
    "    !brew install xelatex             # xelatex is used for pdf document creation in MacOS.\n",
    "    !pandoc --pdf-engine=xelatex ./tuning_data/FAQ-Kubernetes-Client.md -o ./tuning_data/FAQ-Kubernetes-Client.pdf\n",
    "    !pandoc --pdf-engine=xelatex ./tuning_data/FAQ.md -o ./tuning_data/FAQ.pdf\n",
    "    !pandoc --pdf-engine=xelatex ./tuning_data/README.md -o ./tuning_data/README.pdf\n",
    "elif platform.system() == \"Linux\":\n",
    "    # Install using apt-get for Ubuntu Linux\n",
    "    !sudo apt-get install pdflatex    # pdflatex is used for pdf document creation in MacOS.\n",
    "    !pandoc --pdf-engine=pdflatex ./tuning_data/FAQ-Kubernetes-Client.md -o ./tuning_data/FAQ-Kubernetes-Client.pdf\n",
    "    !pandoc --pdf-engine=pdflatex ./tuning_data/FAQ.md -o ./tuning_data/FAQ.pdf\n",
    "    !pandoc --pdf-engine=pdflatex ./tuning_data/README.md -o ./tuning_data/README.pdf"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m==>\u001B[0m \u001B[1mDownloading https://formulae.brew.sh/api/formula.jws.json\u001B[0m\r\n",
      "\u001B[34m==>\u001B[0m \u001B[1mDownloading https://formulae.brew.sh/api/cask.jws.json\u001B[0m\r\n",
      "\u001B[33mWarning:\u001B[0m No available formula with the name \"xelatex\".\r\n",
      "\u001B[34m==>\u001B[0m \u001B[1mSearching for similarly named formulae and casks...\u001B[0m\r\n",
      "\u001B[31mError:\u001B[0m No formulae or casks found for xelatex.\r\n",
      "[WARNING] Missing character: There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ├ (U+251C) (U+251C) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no │ (U+2502) (U+2502) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no │ (U+2502) (U+2502) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ├ (U+251C) (U+251C) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no │ (U+2502) (U+2502) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ├ (U+251C) (U+251C) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] Missing character: There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!\r\n",
      "[WARNING] [makePDF] LaTeX Warning: Hyper reference\r\n",
      "  `how-does-cluster-autoscaler-treat-nodes-with-taints' on\r\n",
      "  page 1 undefined on input line 172.\r\n",
      "[WARNING] [makePDF] LaTeX Warning: Hyper reference\r\n",
      "  `im-running-cluster-with-nodes-in-multiple-zones-for-ha-purposes-is-that-supported-by-cluster-autoscaler'\r\n",
      "  on page 1 undefined on input line 182.\r\n",
      "[WARNING] [makePDF] LaTeX Warning: Hyper reference\r\n",
      "  `i-have-a-couple-of-nodes-with-low-utilization-but-they-are-not-scaled-down-why'\r\n",
      "  on page 2 undefined on input line 272.\r\n",
      "[WARNING] [makePDF] LaTeX Warning: Hyper reference\r\n",
      "  `ca-doesnt-work-but-it-used-to-work-yesterday-why' on page 2\r\n",
      "  undefined on input line 281.\r\n",
      "[WARNING] [makePDF] LaTeX Warning: Hyper reference\r\n",
      "  `how-can-i-check-what-is-going-on-in-ca-' on page 2\r\n",
      "  undefined on input line 284.\r\n",
      "[WARNING] [makePDF] LaTeX Warning: Hyper reference\r\n",
      "  `my-cluster-is-below-minimum--above-maximum-number-of-nodes-but-ca-did-not-fix-that-why'\r\n",
      "  on page 2 undefined on input line 291.\r\n",
      "[WARNING] [makePDF] LaTeX Warning: Hyper reference\r\n",
      "  `how-can-i-update-ca-dependencies-particularly-k8siokubernetes'\r\n",
      "  on page 2 undefined on input line 312.\r\n",
      "[WARNING] [makePDF] LaTeX Warning: Hyper reference\r\n",
      "  `i-have-a-couple-of-nodes-with-low-utilization-but-they-are-not-scaled-down-why'\r\n",
      "  on page 9 undefined on input line 815.\r\n",
      "[WARNING] [makePDF] LaTeX Warning: Hyper reference\r\n",
      "  `i-have-a-couple-of-nodes-with-low-utilization-but-they-are-not-scaled-down-why'\r\n",
      "  on page 19 undefined on input line 1461.\r\n",
      "[WARNING] [makePDF] LaTeX Warning: Hyper reference\r\n",
      "  `i-have-a-couple-of-nodes-with-low-utilization-but-they-are-not-scaled-down-why'\r\n",
      "  on page 46 undefined on input line 2265.\r\n",
      "[WARNING] [makePDF] LaTeX Warning: There were undefined references.\r\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecaab399efba"
   },
   "source": [
    "After generating the test tuning datasets, we will upload the datasets to the bucket in Cloud Storage which will be used as a data store for the search tuning."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fc0b7bf1960f",
    "ExecuteTime": {
     "end_time": "2025-04-16T07:42:25.978171Z",
     "start_time": "2025-04-16T07:42:17.375168Z"
    }
   },
   "source": [
    "# Uploading the preprocessed data with the PDF files for reindexing to the search app data store\n",
    "!echo \"Preprocessed tuning data: {TUNING_DATA_PATH_LOCAL}\"\n",
    "!echo \"Destination path: {TUNING_DATA_PATH_REMOTE}\"\n",
    "!gcloud storage folders create \"{TUNING_DATA_PATH_REMOTE}\"\n",
    "!gcloud storage cp $TUNING_DATA_PATH_LOCAL/* $TUNING_DATA_PATH_REMOTE"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed tuning data: ./tuning_data\r\n",
      "Destination path: gs://sample-search-tuning-genai-customersupport/tuning_data\r\n",
      "Creating gs://sample-search-tuning-genai-customersupport/tuning_data...\r\n",
      "Copying file://./tuning_data/corpus_file.jsonl to gs://sample-search-tuning-genai-customersupport/tuning_data/corpus_file.jsonl\r\n",
      "Copying file://./tuning_data/FAQ-Kubernetes-Client.md to gs://sample-search-tuning-genai-customersupport/tuning_data/FAQ-Kubernetes-Client.md\r\n",
      "Copying file://./tuning_data/FAQ-Kubernetes-Client.pdf to gs://sample-search-tuning-genai-customersupport/tuning_data/FAQ-Kubernetes-Client.pdf\r\n",
      "Copying file://./tuning_data/FAQ.md to gs://sample-search-tuning-genai-customersupport/tuning_data/FAQ.md\r\n",
      "Copying file://./tuning_data/FAQ.pdf to gs://sample-search-tuning-genai-customersupport/tuning_data/FAQ.pdf\r\n",
      "Copying file://./tuning_data/query_file.jsonl to gs://sample-search-tuning-genai-customersupport/tuning_data/query_file.jsonl\r\n",
      "Copying file://./tuning_data/README.md to gs://sample-search-tuning-genai-customersupport/tuning_data/README.md\r\n",
      "Copying file://./tuning_data/README.pdf to gs://sample-search-tuning-genai-customersupport/tuning_data/README.pdf\r\n",
      "Copying file://./tuning_data/test_data.tsv to gs://sample-search-tuning-genai-customersupport/tuning_data/test_data.tsv\r\n",
      "Copying file://./tuning_data/training_data.tsv to gs://sample-search-tuning-genai-customersupport/tuning_data/training_data.tsv\r\n",
      "  Completed files 10/10 | 552.2kiB/552.2kiB                                    \r\n",
      "\r\n",
      "Average throughput: 1.0MiB/s\r\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30c11d2bc24c"
   },
   "source": [
    "## Uploading data for a search app datastore (papers on RLHF)\n",
    "\n",
    "To create a Vertex AI search app, we will upload some pdf files on Reinforcement Learning on Human Feedback from [Awesome RLHF](https://github.com/opendilab/awesome-RLHF.git) github repository to a bucket in Cloud Storage which will be used as a search datastore. The pdf files are available at [Awesome RLHF - PDF Files](https://gitlab.com/jincheolkim/awesome-rlhf)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e98fc0c02b96",
    "ExecuteTime": {
     "end_time": "2025-04-16T07:42:40.759095Z",
     "start_time": "2025-04-16T07:42:28.111441Z"
    }
   },
   "source": [
    "!echo {SEARCH_DATASTORE_PATH_REMOTE}\n",
    "!gcloud storage folders create \"{SEARCH_DATASTORE_PATH_REMOTE}\"\n",
    "!gcloud storage cp --recursive $BASE_DATA_SOURCE_URI/* $SEARCH_DATASTORE_PATH_REMOTE"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore\r\n",
      "Creating gs://sample-search-tuning-genai-customersupport/rlhf-datastore...\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/ to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/awesome_rlhf/\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/Few-Shot Preference Learning for Human-in-the-Loop Reinforcement Learning.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/Few-Shot Preference Learning for Human-in-the-Loop Reinforcement Learning.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/README.md to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/README.md\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/Scaling GAIA-1_ 9-billion parameter generative world model for autonomous driving - Wayve.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/Scaling GAIA-1_ 9-billion parameter generative world model for autonomous driving - Wayve.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[1701.06049] Interactive Learning from Policy-Dependent Human Feedback.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[1701.06049] Interactive Learning from Policy-Dependent Human Feedback.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[1706.03741] Deep reinforcement learning from human preferences.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[1706.03741] Deep reinforcement learning from human preferences.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[1709.10163] Deep TAMER - Interactive Agent Shaping in High-Dimensional State Spaces.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[1709.10163] Deep TAMER - Interactive Agent Shaping in High-Dimensional State Spaces.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[1811.06521] Reward learning from human preferences and demonstrations in Atari.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[1811.06521] Reward learning from human preferences and demonstrations in Atari.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[1811.07871] Scalable agent alignment via reward modeling - a research direction.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[1811.07871] Scalable agent alignment via reward modeling - a research direction.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[1909.08593] Fine-Tuning Language Models from Human Preferences.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[1909.08593] Fine-Tuning Language Models from Human Preferences.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2009.01325] Learning to summarize from human feedback.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2009.01325] Learning to summarize from human feedback.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2106.08942] Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2106.08942] Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2109.10862] Recursively Summarizing Books with Human Feedback.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2109.10862] Recursively Summarizing Books with Human Feedback.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2112.09332] WebGPT - Browser-assisted question-answering with human feedback.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2112.09332] WebGPT - Browser-assisted question-answering with human feedback.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2203.02155] Training language models to follow instructions with human feedback.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2203.02155] Training language models to follow instructions with human feedback.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2203.11147] Teaching language models to support answers with verified quotes.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2203.11147] Teaching language models to support answers with verified quotes.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2204.05862] Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2204.05862] Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2205.13636] Quark - Controllable Text Generation with Reinforced Unlearning.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2205.13636] Quark - Controllable Text Generation with Reinforced Unlearning.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2205.15367] Non-Markovian Reward Modelling from Trajectory Labels via Interpretable Multiple Instance Learning.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2205.15367] Non-Markovian Reward Modelling from Trajectory Labels via Interpretable Multiple Instance Learning.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2208.02294] Dynamic Planning in Open-Ended Dialogue using Reinforcement Learning.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2208.02294] Dynamic Planning in Open-Ended Dialogue using Reinforcement Learning.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2209.07858] Red Teaming Language Models to Reduce Harms - Methods, Scaling Behaviors, and Lessons Learned.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2209.07858] Red Teaming Language Models to Reduce Harms - Methods, Scaling Behaviors, and Lessons Learned.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2209.14375] Improving alignment of dialogue agents via targeted human judgements.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2209.14375] Improving alignment of dialogue agents via targeted human judgements.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2210.01241] Is Reinforcement Learning (Not) for Natural Language Processing.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2210.01241] Is Reinforcement Learning (Not) for Natural Language Processing.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2210.10760] Scaling Laws for Reward Model Overoptimization.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2210.10760] Scaling Laws for Reward Model Overoptimization.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2212.08073] Constitutional AI - Harmlessness from AI Feedback.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2212.08073] Constitutional AI - Harmlessness from AI Feedback.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2212.09251] Discovering Language Model Behaviors with Model-Written Evaluations.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2212.09251] Discovering Language Model Behaviors with Model-Written Evaluations.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2301.11270] Principled Reinforcement Learning with Human Feedback from Pairwise or K-wise Comparisons.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2301.11270] Principled Reinforcement Learning with Human Feedback from Pairwise or K-wise Comparisons.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2302.05206] The Wisdom of Hindsight Makes Language Models Better Instruction Followers.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2302.05206] The Wisdom of Hindsight Makes Language Models Better Instruction Followers.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2302.07459] The Capacity for Moral Self-Correction in Large Language Models.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2302.07459] The Capacity for Moral Self-Correction in Large Language Models.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2302.08215] Aligning Language Models with Preferences through f-divergence Minimization.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2302.08215] Aligning Language Models with Preferences through f-divergence Minimization.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2302.08242] Tuning computer vision models with task rewards.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2302.08242] Tuning computer vision models with task rewards.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2302.08582] Pretraining Language Models with Human Preferences.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2302.08582] Pretraining Language Models with Human Preferences.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2302.12192] Aligning Text-to-Image Models using Human Feedback.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2302.12192] Aligning Text-to-Image Models using Human Feedback.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2303.04671] Visual ChatGPT - Talking, Drawing and Editing with Visual Foundation Models.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2303.04671] Visual ChatGPT - Talking, Drawing and Editing with Visual Foundation Models.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2303.14420] Human Preference Score - Better Aligning Text-to-Image Models with Human Preference.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2303.14420] Human Preference Score - Better Aligning Text-to-Image Models with Human Preference.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2304.05302v1] RRHF - Rank Responses to Align Language Models with Human Feedback without tears.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2304.05302v1] RRHF - Rank Responses to Align Language Models with Human Feedback without tears.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2304.05977v2] ImageReward - Learning and Evaluating Human Preferences for Text-to-Image Generation.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2304.05977v2] ImageReward - Learning and Evaluating Human Preferences for Text-to-Image Generation.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2304.06767] RAFT - Reward rAnked FineTuning for Generative Foundation Model Alignment.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2304.06767] RAFT - Reward rAnked FineTuning for Generative Foundation Model Alignment.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2304.07297] Language Instructed Reinforcement Learning for Human-AI Coordination.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2304.07297] Language Instructed Reinforcement Learning for Human-AI Coordination.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2305.00955] Bridging the Gap - A Survey on Integrating (Human) Feedback for Natural Language Generation.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2305.00955] Bridging the Gap - A Survey on Integrating (Human) Feedback for Natural Language Generation.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2306.17492] Preference Ranking Optimization for Human Alignment.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2306.17492] Preference Ranking Optimization for Human Alignment.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2308.12050] Aligning Language Models with Offline Reinforcement Learning from Human.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2308.12050] Aligning Language Models with Offline Reinforcement Learning from Human.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[2309.17080] GAIA-1 - A Generative World Model for Autonomous Driving.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2309.17080] GAIA-1 - A Generative World Model for Autonomous Driving.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/[gpt-4] GPT-4 Technical Report.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[gpt-4] GPT-4 Technical Report.pdf\r\n",
      "Copying gs://github-repo/generative-ai/search/tuning/awesome_rlhf/_1701.06049__Interactive_Learning_from_Policy-Dependent_Human_Feedback.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/_1701.06049__Interactive_Learning_from_Policy-Dependent_Human_Feedback.pdf\r\n",
      "  Completed files 45/45 | 208.6MiB/208.6MiB                                    \r\n",
      "\r\n",
      "Average throughput: 304.8MiB/s\r\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Helper functions to facilitate the following steps\n",
    "\n",
    "The following functions are helper functions to help you clear the steps to perform the search tuning without distraction on other details.\n",
    "\n",
    "* ```create_data_store```: function creates a datastore for an agent app with the identifier of a datastore with the ```data_store_id``` and the ```data_store_name```\n",
    "* ```create_search_engine```: function creates a search agent app\n",
    "* ```search```: function to perform a query with the query given through the argument\n",
    "* ```train_custom_model```: function to tune the backend LLM for the search agent app\n",
    "* ```delete_engine```: function to delete the search agent app\n",
    "* ```purge_documents```: function to delete the index and the documents indexed for the search agent app\n",
    "* ```delete_data_store```: function to delete the data store\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:42:44.439581Z",
     "start_time": "2025-04-16T07:42:44.437158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  For more information, refer to:\n",
    "# https://cloud.google.com/generative-ai-app-builder/docs/locations#specify_a_multi-region_for_your_data_store\n",
    "search_client_options = (\n",
    "    ClientOptions(api_endpoint=f\"{LOCATION}-discoveryengine.googleapis.com\")\n",
    "    if LOCATION != \"global\"\n",
    "    else None\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:42:45.907535Z",
     "start_time": "2025-04-16T07:42:45.902675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_data_store(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    data_store_name: str,\n",
    "    client_options: ClientOptions = search_client_options\n",
    ") -> str:\n",
    "    # Create a client\n",
    "    client = discoveryengine.DataStoreServiceClient(client_options=client_options)    \n",
    "    \n",
    "    # The full resource name of the collection\n",
    "    # e.g. projects/{project}/locations/{location}/collections/default_collection\n",
    "    parent = client.collection_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        collection=\"default_collection\",\n",
    "    )\n",
    "\n",
    "    data_store = discoveryengine.DataStore(\n",
    "        display_name=data_store_name,\n",
    "        # Options: GENERIC, MEDIA, HEALTHCARE_FHIR\n",
    "        industry_vertical=discoveryengine.IndustryVertical.GENERIC,\n",
    "        # Options: SOLUTION_TYPE_RECOMMENDATION, SOLUTION_TYPE_SEARCH, SOLUTION_TYPE_CHAT, SOLUTION_TYPE_GENERATIVE_CHAT\n",
    "        solution_types=[discoveryengine.SolutionType.SOLUTION_TYPE_SEARCH],\n",
    "        # Options: NO_CONTENT, CONTENT_REQUIRED, PUBLIC_WEBSITE\n",
    "        content_config=discoveryengine.DataStore.ContentConfig.CONTENT_REQUIRED,\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.CreateDataStoreRequest(\n",
    "        parent=parent,\n",
    "        data_store_id=data_store_id,\n",
    "        data_store=data_store,\n",
    "        # Optional: For Advanced Site Search Only\n",
    "        # create_advanced_site_search=True,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.create_data_store(request=request)\n",
    "\n",
    "    print(f\"Waiting for operation to complete: {operation.operation.name}\")\n",
    "    response = operation.result()\n",
    "\n",
    "    # After the operation is complete,\n",
    "    # get information from operation metadata\n",
    "    metadata = discoveryengine.CreateDataStoreMetadata(operation.metadata)\n",
    "\n",
    "    # Handle the response\n",
    "    print(response)\n",
    "    print(metadata)\n",
    "\n",
    "    return operation.operation.name"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:42:47.159496Z",
     "start_time": "2025-04-16T07:42:47.154902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def import_documents(\n",
    "    project_id: str, location: str, data_store_id: str,\n",
    "    client_options: ClientOptions = search_client_options\n",
    ") -> discoveryengine.PurgeDocumentsMetadata:\n",
    "\n",
    "    # Create clients for importing documents\n",
    "    client = discoveryengine.DocumentServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the search engine branch.\n",
    "    # e.g. projects/{project}/locations/{location}/dataStores/{data_store_id}/branches/{branch}\n",
    "    parent = client.branch_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        data_store=data_store_id,\n",
    "        branch=\"default_branch\",\n",
    "    )\n",
    "\n",
    "    # With the new datastore, we will import and make an index over the documents in the datastore.\n",
    "    # The ```ImportDocumentsRequests``` generates a REST API request message in the JSON format\n",
    "    # and the ```import_documents``` method of the DocumentServiceClient class lets you import\n",
    "    # the documents and make an index over the document set with the information\n",
    "    # in the ```ImportDocumentRequest``` request.\n",
    "    document_import_request = discoveryengine.ImportDocumentsRequest(\n",
    "        parent=parent,\n",
    "        gcs_source=discoveryengine.GcsSource(\n",
    "            # Multiple URIs are supported\n",
    "            input_uris=[f\"{SEARCH_DATASTORE_PATH_REMOTE}/*\"],\n",
    "            # Options:\n",
    "            # - `content` - Unstructured documents (PDF, HTML, DOC, TXT, PPTX)\n",
    "            # - `custom` - Unstructured documents with custom JSONL metadata\n",
    "            # - `document` - Structured documents in the discoveryengine.Document format.\n",
    "            # - `csv` - Unstructured documents with CSV metadata\n",
    "            data_schema=\"content\",\n",
    "        ),\n",
    "        # Options: `FULL`, `INCREMENTAL`\n",
    "        reconciliation_mode=discoveryengine.ImportDocumentsRequest.ReconciliationMode.INCREMENTAL,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.import_documents(request=document_import_request)\n",
    "\n",
    "    print(f\"Waiting for operation to complete: {operation.operation.name}\")\n",
    "\n",
    "    # After the operation is complete,\n",
    "    # get information from operation metadata\n",
    "    response = operation.result()\n",
    "    metadata = discoveryengine.ImportDocumentsMetadata(operation.metadata)\n",
    "\n",
    "    # Handle the response\n",
    "    print(response)\n",
    "    print(metadata)\n",
    "\n",
    "    return metadata"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:42:48.030359Z",
     "start_time": "2025-04-16T07:42:48.026412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_search_engine(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    engine_name: str,\n",
    "    engine_id: str,\n",
    "    data_store_ids: list[str],\n",
    "    client_options: ClientOptions = search_client_options\n",
    ") -> str:\n",
    "    # Create a client\n",
    "    client = discoveryengine.EngineServiceClient(client_options=client_options)\n",
    "    \n",
    "    # The full resource name of the collection\n",
    "    # e.g. projects/{project}/locations/{location}/collections/default_collection\n",
    "    parent = client.collection_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        collection=\"default_collection\",\n",
    "    )\n",
    "\n",
    "    engine = discoveryengine.Engine(\n",
    "        display_name=engine_name,\n",
    "        # Options: GENERIC, MEDIA, HEALTHCARE_FHIR\n",
    "        industry_vertical=discoveryengine.IndustryVertical.GENERIC,\n",
    "        # Options: SOLUTION_TYPE_RECOMMENDATION, SOLUTION_TYPE_SEARCH, SOLUTION_TYPE_CHAT, SOLUTION_TYPE_GENERATIVE_CHAT\n",
    "        solution_type=discoveryengine.SolutionType.SOLUTION_TYPE_SEARCH,\n",
    "        # For search apps only\n",
    "        search_engine_config=discoveryengine.Engine.SearchEngineConfig(\n",
    "            # Options: SEARCH_TIER_STANDARD, SEARCH_TIER_ENTERPRISE\n",
    "            search_tier=discoveryengine.SearchTier.SEARCH_TIER_ENTERPRISE,\n",
    "            # Options: SEARCH_ADD_ON_LLM, SEARCH_ADD_ON_UNSPECIFIED\n",
    "            search_add_ons=[discoveryengine.SearchAddOn.SEARCH_ADD_ON_LLM],\n",
    "        ),\n",
    "        # For generic recommendation apps only\n",
    "        # similar_documents_config=discoveryengine.Engine.SimilarDocumentsEngineConfig,\n",
    "        data_store_ids=data_store_ids,\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.CreateEngineRequest(\n",
    "        parent=parent,\n",
    "        engine=engine,\n",
    "        engine_id=engine_id,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.create_engine(request=request)\n",
    "\n",
    "    print(f\"Waiting for operation to complete: {operation.operation.name}\")\n",
    "    response = operation.result()\n",
    "\n",
    "    # After the operation is complete,\n",
    "    # get information from operation metadata\n",
    "    metadata = discoveryengine.CreateEngineMetadata(operation.metadata)\n",
    "\n",
    "    # Handle the response\n",
    "    print(response)\n",
    "    print(metadata)\n",
    "\n",
    "    return operation.operation.name"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:42:48.735977Z",
     "start_time": "2025-04-16T07:42:48.731649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    engine_id: str,\n",
    "    search_query: str,\n",
    "    client_options: ClientOptions = search_client_options\n",
    ") -> list[discoveryengine.SearchResponse]:\n",
    "\n",
    "    # Create a client\n",
    "    client = discoveryengine.SearchServiceClient(client_options=client_options)\n",
    "    \n",
    "    # The full resource name of the search app serving config\n",
    "    serving_config = f\"projects/{project_id}/locations/{location}/collections/default_collection/engines/{engine_id}/servingConfigs/default_config\"\n",
    "\n",
    "    # Optional - only supported for unstructured data: Configuration options for search.\n",
    "    # Refer to the `ContentSearchSpec` reference for all supported fields:\n",
    "    # https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1.types.SearchRequest.ContentSearchSpec\n",
    "    content_search_spec = discoveryengine.SearchRequest.ContentSearchSpec(\n",
    "        # For information about snippets, refer to:\n",
    "        # https://cloud.google.com/generative-ai-app-builder/docs/snippets\n",
    "        snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(\n",
    "            return_snippet=True\n",
    "        ),\n",
    "        # For information about search summaries, refer to:\n",
    "        # https://cloud.google.com/generative-ai-app-builder/docs/get-search-summaries\n",
    "        summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(\n",
    "            summary_result_count=5,\n",
    "            include_citations=True,\n",
    "            ignore_adversarial_query=True,\n",
    "            ignore_non_summary_seeking_query=True,\n",
    "            model_prompt_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelPromptSpec(\n",
    "                preamble=\"YOUR_CUSTOM_PROMPT\"\n",
    "            ),\n",
    "            model_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelSpec(\n",
    "                version=\"stable\",\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Refer to the `SearchRequest` reference for all supported fields:\n",
    "    # https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1.types.SearchRequest\n",
    "    request = discoveryengine.SearchRequest(\n",
    "        serving_config=serving_config,\n",
    "        query=search_query,\n",
    "        page_size=10,\n",
    "        content_search_spec=content_search_spec,\n",
    "        query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(\n",
    "            condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,\n",
    "        ),\n",
    "        spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(\n",
    "            mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    response = client.search(request)\n",
    "    print(response)\n",
    "\n",
    "    return response"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:42:49.389019Z",
     "start_time": "2025-04-16T07:42:49.385514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_custom_model(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    corpus_data_path: str,\n",
    "    query_data_path: str,\n",
    "    train_data_path: str,\n",
    "    test_data_path: str,\n",
    "    client_options: ClientOptions = search_client_options\n",
    ") -> Operation:\n",
    "    # Create a client\n",
    "    client = discoveryengine.SearchTuningServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the data store\n",
    "    data_store = f\"projects/{project_id}/locations/{location}/collections/default_collection/dataStores/{data_store_id}\"\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.train_custom_model(\n",
    "        request=discoveryengine.TrainCustomModelRequest(\n",
    "            gcs_training_input=discoveryengine.TrainCustomModelRequest.GcsTrainingInput(\n",
    "                corpus_data_path=corpus_data_path,\n",
    "                query_data_path=query_data_path,\n",
    "                train_data_path=train_data_path,\n",
    "                test_data_path=test_data_path,\n",
    "            ),\n",
    "            data_store=data_store,\n",
    "            model_type=\"search-tuning\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Optional: Wait for training to complete\n",
    "    print(f\"Waiting for operation to complete: {operation.operation.name}\")\n",
    "    response = operation.result()\n",
    "\n",
    "    # After the operation is complete,\n",
    "    # get information from operation metadata\n",
    "    metadata = discoveryengine.TrainCustomModelMetadata(operation.metadata)\n",
    "\n",
    "    # Handle the response\n",
    "    print(response)\n",
    "    print(metadata)\n",
    "    print(operation)\n",
    "\n",
    "    return operation"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:42:50.070118Z",
     "start_time": "2025-04-16T07:42:50.067635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def delete_engine(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    engine_id: str,\n",
    "    client_options: ClientOptions = search_client_options\n",
    ") -> str:\n",
    "    # Create a client\n",
    "    client = discoveryengine.EngineServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the engine\n",
    "    # e.g. projects/{project}/locations/{location}/collections/default_collection/engines/{engine_id}\n",
    "    name = client.engine_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        collection=\"default_collection\",\n",
    "        engine=engine_id,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.delete_engine(name=name)\n",
    "\n",
    "    print(f\"Operation: {operation.operation.name}\")\n",
    "\n",
    "    return operation.operation.name"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:42:51.144110Z",
     "start_time": "2025-04-16T07:42:51.140921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def purge_documents(\n",
    "    project_id: str, location: str, data_store_id: str,\n",
    "    client_options: ClientOptions = search_client_options\n",
    ") -> discoveryengine.PurgeDocumentsMetadata:\n",
    "    \n",
    "    # Create a client\n",
    "    client = discoveryengine.DocumentServiceClient(client_options=client_options)\n",
    "    \n",
    "    operation = client.purge_documents(\n",
    "        request=discoveryengine.PurgeDocumentsRequest(\n",
    "            # The full resource name of the search engine branch.\n",
    "            # e.g. projects/{project}/locations/{location}/dataStores/{data_store_id}/branches/{branch}\n",
    "            parent=client.branch_path(\n",
    "                project=project_id,\n",
    "                location=location,\n",
    "                data_store=data_store_id,\n",
    "                branch=\"default_branch\",\n",
    "            ),\n",
    "            filter=\"*\",\n",
    "            # If force is set to `False`, return the expected purge count without deleting any documents.\n",
    "            force=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(f\"Waiting for operation to complete: {operation.operation.name}\")\n",
    "    response = operation.result()\n",
    "\n",
    "    # After the operation is complete,\n",
    "    # get information from operation metadata\n",
    "    metadata = discoveryengine.PurgeDocumentsMetadata(operation.metadata)\n",
    "\n",
    "    # Handle the response\n",
    "    print(response)\n",
    "    print(metadata)\n",
    "\n",
    "    return metadata"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:42:52.065653Z",
     "start_time": "2025-04-16T07:42:52.062432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def delete_data_store(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    client_options: ClientOptions = search_client_options\n",
    ") -> str:\n",
    "    # Create a client\n",
    "    client = discoveryengine.DataStoreServiceClient(client_options=client_options)\n",
    "\n",
    "    request = discoveryengine.DeleteDataStoreRequest(\n",
    "        # The full resource name of the data store\n",
    "        name=client.data_store_path(project_id, location, data_store_id)\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.delete_data_store(request=request)\n",
    "\n",
    "    print(f\"Operation: {operation.operation.name}\")\n",
    "\n",
    "    return operation.operation.name"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df2d7e8fc6e6"
   },
   "source": [
    "## Creating a data store for a search app with the cloud storage bucket with PDF documents\n",
    "\n",
    "We create a datastore with the datastore bucket in Cloud Storage with the PDF files on RLHF and import them to generate indices for search."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "588af607bc6d",
    "ExecuteTime": {
     "end_time": "2025-04-16T07:42:57.967255Z",
     "start_time": "2025-04-16T07:42:54.359658Z"
    }
   },
   "source": [
    "!echo \"Datastore ID: {SEARCH_DATASTORE_ID}\"\n",
    "!echo \"Datastore Name: {SEARCH_DATASTORE_NAME}\"\n",
    "create_datastore_op_name = create_data_store(\n",
    "    PROJECT_ID, LOCATION, SEARCH_DATASTORE_ID, SEARCH_DATASTORE_NAME\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datastore ID: search-datastore-genai-customersupport-cqbfgumcsmwnyz9gbccwuq\r\n",
      "Datastore Name: RLHF-ARTICLE-DATASTORE\r\n",
      "Waiting for operation to complete: projects/1011110730258/locations/global/collections/default_collection/operations/create-data-store-6682775123270097821\n",
      "name: \"projects/1011110730258/locations/global/collections/default_collection/dataStores/search-datastore-genai-customersupport-cqbfgumcsmwnyz9gbccwuq\"\n",
      "display_name: \"RLHF-ARTICLE-DATASTORE\"\n",
      "industry_vertical: GENERIC\n",
      "solution_types: SOLUTION_TYPE_SEARCH\n",
      "content_config: CONTENT_REQUIRED\n",
      "default_schema_id: \"default_schema\"\n",
      "document_processing_config {\n",
      "  name: \"projects/1011110730258/locations/global/collections/default_collection/dataStores/search-datastore-genai-customersupport-cqbfgumcsmwnyz9gbccwuq/documentProcessingConfig\"\n",
      "  default_parsing_config {\n",
      "    digital_parsing_config {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "765dcf64879d",
    "ExecuteTime": {
     "end_time": "2025-04-16T07:58:09.399116Z",
     "start_time": "2025-04-16T07:43:01.865143Z"
    }
   },
   "source": "metadata = import_documents(PROJECT_ID, LOCATION, SEARCH_DATASTORE_ID)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete: projects/1011110730258/locations/global/collections/default_collection/dataStores/search-datastore-genai-customersupport-cqbfgumcsmwnyz9gbccwuq/branches/0/operations/import-documents-8746447334494493774\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "Operation did not complete within the designated timeout of 900 seconds.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31m_OperationNotComplete\u001B[0m                     Traceback (most recent call last)",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001B[0m, in \u001B[0;36mretry_target\u001B[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 144\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mtarget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misawaitable(result):\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/future/polling.py:120\u001B[0m, in \u001B[0;36mPollingFuture._done_or_raise\u001B[0;34m(self, retry)\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdone(retry\u001B[38;5;241m=\u001B[39mretry):\n\u001B[0;32m--> 120\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m _OperationNotComplete()\n",
      "\u001B[0;31m_OperationNotComplete\u001B[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRetryError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/future/polling.py:137\u001B[0m, in \u001B[0;36mPollingFuture._blocking_poll\u001B[0;34m(self, timeout, retry, polling)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 137\u001B[0m     \u001B[43mpolling\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_done_or_raise\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mRetryError:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001B[0m, in \u001B[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    290\u001B[0m sleep_generator \u001B[38;5;241m=\u001B[39m exponential_sleep_generator(\n\u001B[1;32m    291\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initial, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maximum, multiplier\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_multiplier\n\u001B[1;32m    292\u001B[0m )\n\u001B[0;32m--> 293\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mretry_target\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m    \u001B[49m\u001B[43msleep_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[43m    \u001B[49m\u001B[43mon_error\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001B[0m, in \u001B[0;36mretry_target\u001B[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;66;03m# defer to shared logic for handling errors\u001B[39;00m\n\u001B[0;32m--> 153\u001B[0m     \u001B[43m_retry_error_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdeadline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43msleep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpredicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexception_factory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;66;03m# if exception not raised, sleep before next attempt\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:221\u001B[0m, in \u001B[0;36m_retry_error_helper\u001B[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001B[0m\n\u001B[1;32m    216\u001B[0m     final_exc, source_exc \u001B[38;5;241m=\u001B[39m exc_factory_fn(\n\u001B[1;32m    217\u001B[0m         error_list,\n\u001B[1;32m    218\u001B[0m         RetryFailureReason\u001B[38;5;241m.\u001B[39mTIMEOUT,\n\u001B[1;32m    219\u001B[0m         original_timeout,\n\u001B[1;32m    220\u001B[0m     )\n\u001B[0;32m--> 221\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m final_exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msource_exc\u001B[39;00m\n\u001B[1;32m    222\u001B[0m _LOGGER\u001B[38;5;241m.\u001B[39mdebug(\n\u001B[1;32m    223\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRetrying due to \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, sleeping \u001B[39m\u001B[38;5;132;01m{:.1f}\u001B[39;00m\u001B[38;5;124ms ...\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(error_list[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], next_sleep)\n\u001B[1;32m    224\u001B[0m )\n",
      "\u001B[0;31mRetryError\u001B[0m: Timeout of 900.0s exceeded, last exception: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTimeoutError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m metadata \u001B[38;5;241m=\u001B[39m \u001B[43mimport_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPROJECT_ID\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLOCATION\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mSEARCH_DATASTORE_ID\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[14], line 46\u001B[0m, in \u001B[0;36mimport_documents\u001B[0;34m(project_id, location, data_store_id, client_options)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWaiting for operation to complete: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moperation\u001B[38;5;241m.\u001B[39moperation\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# After the operation is complete,\u001B[39;00m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# get information from operation metadata\u001B[39;00m\n\u001B[0;32m---> 46\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43moperation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m metadata \u001B[38;5;241m=\u001B[39m discoveryengine\u001B[38;5;241m.\u001B[39mImportDocumentsMetadata(operation\u001B[38;5;241m.\u001B[39mmetadata)\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# Handle the response\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/future/polling.py:256\u001B[0m, in \u001B[0;36mPollingFuture.result\u001B[0;34m(self, timeout, retry, polling)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mresult\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_DEFAULT_VALUE, retry\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, polling\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    145\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get the result of the operation.\u001B[39;00m\n\u001B[1;32m    146\u001B[0m \n\u001B[1;32m    147\u001B[0m \u001B[38;5;124;03m    This method will poll for operation status periodically, blocking if\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;124;03m            the timeout is reached before the operation completes.\u001B[39;00m\n\u001B[1;32m    254\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 256\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_blocking_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpolling\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpolling\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    258\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;66;03m# pylint: disable=raising-bad-type\u001B[39;00m\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001B[39;00m\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/future/polling.py:139\u001B[0m, in \u001B[0;36mPollingFuture._blocking_poll\u001B[0;34m(self, timeout, retry, polling)\u001B[0m\n\u001B[1;32m    137\u001B[0m     polling(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_done_or_raise)(retry\u001B[38;5;241m=\u001B[39mretry)\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mRetryError:\n\u001B[0;32m--> 139\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m concurrent\u001B[38;5;241m.\u001B[39mfutures\u001B[38;5;241m.\u001B[39mTimeoutError(\n\u001B[1;32m    140\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOperation did not complete within the designated timeout of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    141\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpolling\u001B[38;5;241m.\u001B[39mtimeout\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    142\u001B[0m     )\n",
      "\u001B[0;31mTimeoutError\u001B[0m: Operation did not complete within the designated timeout of 900 seconds."
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acdb037fce28"
   },
   "source": [
    "## Creating a search app using the Vertex AI Search SDK\n",
    "\n",
    "As we just created a datastore and made an index over the documents in it in the above, we will create a search app with the datastore. \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f549f8d5091f",
    "ExecuteTime": {
     "end_time": "2025-04-16T08:22:21.900443Z",
     "start_time": "2025-04-16T08:22:21.891146Z"
    }
   },
   "source": [
    "SEARCH_DATASTORE_REF_ID = f\"projects/{PROJECT_ID}/locations/{LOCATION}/collections/default_collection/dataStores/{SEARCH_DATASTORE_ID}\"\n",
    "SEARCH_APP_ID = f\"search-app-{PROJECT_ID}-{shortuuid.uuid().lower()}\"\n",
    "SEARCH_APP_NAME = \"RLHF_SEARCH_APP\""
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "10a707979daf",
    "ExecuteTime": {
     "end_time": "2025-04-16T08:22:29.579585Z",
     "start_time": "2025-04-16T08:22:22.807114Z"
    }
   },
   "source": [
    "create_search_app_op_name = create_search_engine(\n",
    "    PROJECT_ID, LOCATION, SEARCH_APP_NAME, SEARCH_APP_ID, [SEARCH_DATASTORE_ID]\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete: projects/1011110730258/locations/global/collections/default_collection/operations/create-engine-11151642560420651003\n",
      "name: \"projects/1011110730258/locations/global/collections/default_collection/engines/search-app-genai-customersupport-jemsevxhvmgyjobjmwndgb\"\n",
      "display_name: \"RLHF_SEARCH_APP\"\n",
      "data_store_ids: \"search-datastore-genai-customersupport-cqbfgumcsmwnyz9gbccwuq\"\n",
      "solution_type: SOLUTION_TYPE_SEARCH\n",
      "search_engine_config {\n",
      "  search_tier: SEARCH_TIER_ENTERPRISE\n",
      "  search_add_ons: SEARCH_ADD_ON_LLM\n",
      "}\n",
      "industry_vertical: GENERIC\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3862d318d1ad"
   },
   "source": [
    "### Test the search app with a test prompt\n",
    "\n",
    "We will test the search app we just created with information about a paper regarding a world model for autonomous driving which is described in a paper among the documents in the datastore."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "68365934e4b2",
    "ExecuteTime": {
     "end_time": "2025-04-16T08:22:31.967549Z",
     "start_time": "2025-04-16T08:22:31.962329Z"
    }
   },
   "source": [
    "QUERY_PROMPT = \"\"\"\n",
    "    What is the name of the world model for autonomous driving developed recently?\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bad64c16adca"
   },
   "source": [
    "We can see that the search app returns a list of relevant documents with references to the related documents in the datastore. Please keep the \n",
    "result in your mind to compare it with the results after the search tuning is performed."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fc7cd4f71bbc",
    "ExecuteTime": {
     "end_time": "2025-04-16T08:25:07.078497Z",
     "start_time": "2025-04-16T08:25:03.480821Z"
    }
   },
   "source": [
    "search_response = search(PROJECT_ID, LOCATION, SEARCH_APP_ID, QUERY_PROMPT)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchPager<results {\n",
      "  id: \"c44f3663d583ba7a25355b91bbe1fa9a\"\n",
      "  document {\n",
      "    name: \"projects/1011110730258/locations/global/collections/default_collection/dataStores/search-datastore-genai-customersupport-cqbfgumcsmwnyz9gbccwuq/branches/0/documents/c44f3663d583ba7a25355b91bbe1fa9a\"\n",
      "    id: \"c44f3663d583ba7a25355b91bbe1fa9a\"\n",
      "    derived_struct_data {\n",
      "      fields {\n",
      "        key: \"title\"\n",
      "        value {\n",
      "          string_value: \"[2309.17080] GAIA-1 - A Generative World Model for Autonomous Driving\"\n",
      "        }\n",
      "      }\n",
      "      fields {\n",
      "        key: \"snippets\"\n",
      "        value {\n",
      "          list_value {\n",
      "            values {\n",
      "              struct_value {\n",
      "                fields {\n",
      "                  key: \"snippet\"\n",
      "                  value {\n",
      "                    string_value: \"GAIA-1: A Generative <b>World Model for Autonomous Driving</b> Anthony Hu* Lloyd Russell* Hudson Yeo* Zak Murez George Fedoseev Alex Kendall Jamie Shotton Gianluca&nbsp;...\"\n",
      "                  }\n",
      "                }\n",
      "                fields {\n",
      "                  key: \"snippet_status\"\n",
      "                  value {\n",
      "                    string_value: \"SUCCESS\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      fields {\n",
      "        key: \"link\"\n",
      "        value {\n",
      "          string_value: \"gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2309.17080] GAIA-1 - A Generative World Model for Autonomous Driving.pdf\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "results {\n",
      "  id: \"535d438974917866f199cfe6b3aa825b\"\n",
      "  document {\n",
      "    name: \"projects/1011110730258/locations/global/collections/default_collection/dataStores/search-datastore-genai-customersupport-cqbfgumcsmwnyz9gbccwuq/branches/0/documents/535d438974917866f199cfe6b3aa825b\"\n",
      "    id: \"535d438974917866f199cfe6b3aa825b\"\n",
      "    derived_struct_data {\n",
      "      fields {\n",
      "        key: \"title\"\n",
      "        value {\n",
      "          string_value: \"Scaling GAIA-1_ 9-billion parameter generative world model for autonomous driving - Wayve\"\n",
      "        }\n",
      "      }\n",
      "      fields {\n",
      "        key: \"snippets\"\n",
      "        value {\n",
      "          list_value {\n",
      "            values {\n",
      "              struct_value {\n",
      "                fields {\n",
      "                  key: \"snippet\"\n",
      "                  value {\n",
      "                    string_value: \"... <b>recent</b> advances in artificial intelligence will open new possibilities for <b>autonomous driving</b> and other applications of embodied AI. Read more r  r  r &nbsp;...\"\n",
      "                  }\n",
      "                }\n",
      "                fields {\n",
      "                  key: \"snippet_status\"\n",
      "                  value {\n",
      "                    string_value: \"SUCCESS\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      fields {\n",
      "        key: \"link\"\n",
      "        value {\n",
      "          string_value: \"gs://sample-search-tuning-genai-customersupport/rlhf-datastore/Scaling GAIA-1_ 9-billion parameter generative world model for autonomous driving - Wayve.pdf\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "results {\n",
      "  id: \"44e69b8db1bf959e27df9cc34d02ca01\"\n",
      "  document {\n",
      "    name: \"projects/1011110730258/locations/global/collections/default_collection/dataStores/search-datastore-genai-customersupport-cqbfgumcsmwnyz9gbccwuq/branches/0/documents/44e69b8db1bf959e27df9cc34d02ca01\"\n",
      "    id: \"44e69b8db1bf959e27df9cc34d02ca01\"\n",
      "    derived_struct_data {\n",
      "      fields {\n",
      "        key: \"title\"\n",
      "        value {\n",
      "          string_value: \"Few-Shot Preference Learning for Human-in-the-Loop Reinforcement Learning\"\n",
      "        }\n",
      "      }\n",
      "      fields {\n",
      "        key: \"snippets\"\n",
      "        value {\n",
      "          list_value {\n",
      "            values {\n",
      "              struct_value {\n",
      "                fields {\n",
      "                  key: \"snippet\"\n",
      "                  value {\n",
      "                    string_value: \"... <b>world</b>: A benchmark and evaluation for multi-task and meta reinforcement learning. ... <b>Autonomous</b> robots, 46(1):115–147, 2022. [30] C. Basu, Q. Yang, D. Hungerman,&nbsp;...\"\n",
      "                  }\n",
      "                }\n",
      "                fields {\n",
      "                  key: \"snippet_status\"\n",
      "                  value {\n",
      "                    string_value: \"SUCCESS\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      fields {\n",
      "        key: \"link\"\n",
      "        value {\n",
      "          string_value: \"gs://sample-search-tuning-genai-customersupport/rlhf-datastore/Few-Shot Preference Learning for Human-in-the-Loop Reinforcement Learning.pdf\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "total_size: 3\n",
      "attribution_token: \"-AL0dwEKDAjh0v2_BhC16vTTARIkNjdmZjY2MTAtMDAwMC0yYTJmLThiMTUtNTgyNDI5YWQ4ZTA0IgdHRU5FUklDKnzC8J4V_pT3MLa3jC2Q97Iw7MHjMPHN_TC4jukwtY7pMMXL8xfYmIYx9dntMNLIiDHYqbcwm9jTMNS_4jDbmIYx1LKdFY6-nRWY1rct78HjMIGV9zDPv-Iw9M39MKOAlyKe2NMw8tntMJWSxTCOkckwz8iIMdWptzCb1rctMAFKEjB4MDNhYWQxYmNiMTZhMmUyOVKkAXByb2plY3RzLzEwMTExMTA3MzAyNTgvbG9jYXRpb25zL2dsb2JhbC9jb2xsZWN0aW9ucy9kZWZhdWx0X2NvbGxlY3Rpb24vZW5naW5lcy9zZWFyY2gtYXBwLWdlbmFpLWN1c3RvbWVyc3VwcG9ydC1qZW1zZXZ4aHZtZ3lqb2JqbXduZGdiL3NlcnZpbmdDb25maWdzL2RlZmF1bHRfY29uZmln\"\n",
      "guided_search_result {\n",
      "}\n",
      "summary {\n",
      "  summary_text: \"The world model for autonomous driving developed recently is called GAIA-1 [1, 2]. GAIA-1 is a generative AI model that leverages video, text, and action inputs to generate realistic driving videos and offers fine-grained control over ego-vehicle behavior and scene features [1, 2]. It can distinguish between objects like cars, trucks, buses, pedestrians, cyclists, road layouts, buildings, and traffic lights [2].\\n\"\n",
      "  summary_with_metadata {\n",
      "    summary: \"The world model for autonomous driving developed recently is called GAIA-1. GAIA-1 is a generative AI model that leverages video, text, and action inputs to generate realistic driving videos and offers fine-grained control over ego-vehicle behavior and scene features. It can distinguish between objects like cars, trucks, buses, pedestrians, cyclists, road layouts, buildings, and traffic lights.\\n\"\n",
      "    citation_metadata {\n",
      "      citations {\n",
      "        end_index: 75\n",
      "        sources {\n",
      "        }\n",
      "        sources {\n",
      "          reference_index: 1\n",
      "        }\n",
      "      }\n",
      "      citations {\n",
      "        start_index: 76\n",
      "        end_index: 268\n",
      "        sources {\n",
      "        }\n",
      "        sources {\n",
      "          reference_index: 1\n",
      "        }\n",
      "      }\n",
      "      citations {\n",
      "        start_index: 269\n",
      "        end_index: 397\n",
      "        sources {\n",
      "          reference_index: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    references {\n",
      "      title: \"[2309.17080] GAIA-1 - A Generative World Model for Autonomous Driving\"\n",
      "      document: \"projects/1011110730258/locations/global/collections/default_collection/dataStores/search-datastore-genai-customersupport-cqbfgumcsmwnyz9gbccwuq/branches/0/documents/c44f3663d583ba7a25355b91bbe1fa9a\"\n",
      "    }\n",
      "    references {\n",
      "      title: \"Scaling GAIA-1_ 9-billion parameter generative world model for autonomous driving - Wayve\"\n",
      "      document: \"projects/1011110730258/locations/global/collections/default_collection/dataStores/search-datastore-genai-customersupport-cqbfgumcsmwnyz9gbccwuq/branches/0/documents/535d438974917866f199cfe6b3aa825b\"\n",
      "    }\n",
      "    references {\n",
      "      title: \"Few-Shot Preference Learning for Human-in-the-Loop Reinforcement Learning\"\n",
      "      document: \"projects/1011110730258/locations/global/collections/default_collection/dataStores/search-datastore-genai-customersupport-cqbfgumcsmwnyz9gbccwuq/branches/0/documents/44e69b8db1bf959e27df9cc34d02ca01\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "query_expansion_info {\n",
      "}\n",
      ">\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c307dc82f9f"
   },
   "source": [
    "## Configuring and submitting a search tuning job\n",
    "\n",
    "With the search app ready, we will perform a search tuning with a test tuning data on Kubernetes.\n",
    "\n",
    "First, we will upload the documents of FAQs about Kubernetes and Kubernetes Client API. The original documents were in the Markdown format but we transform them to PDF format files as the Vertex AI Search cannot accept Markdown files but only HTML, PDF and PDF with embedded text, TXT, JSON, XHTML, and XML format. PPTX, DOCX and XLSX formats are available in Preview. The PDF files are uploaded to the buckets for the datastore of the search app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bd5eb9e64ee"
   },
   "source": [
    "#### Uploading the additional PDF files for tuning to the bucket of the datastore"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0741318fcd32",
    "ExecuteTime": {
     "end_time": "2025-04-16T08:25:28.874468Z",
     "start_time": "2025-04-16T08:25:11.085350Z"
    }
   },
   "source": [
    "!gcloud storage cp {TUNING_DATA_PATH_LOCAL}/*.jsonl \"{TUNING_DATA_PATH_REMOTE}\"\n",
    "!gcloud storage cp {TUNING_DATA_PATH_LOCAL}/*.tsv \"{TUNING_DATA_PATH_REMOTE}\"\n",
    "!gcloud storage ls \"{TUNING_DATA_PATH_REMOTE}\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./tuning_data/corpus_file.jsonl to gs://sample-search-tuning-genai-customersupport/tuning_data/corpus_file.jsonl\r\n",
      "Copying file://./tuning_data/query_file.jsonl to gs://sample-search-tuning-genai-customersupport/tuning_data/query_file.jsonl\r\n",
      "  Completed files 2/2 | 134.3kiB/134.3kiB                                      \r\n",
      "\r\n",
      "Average throughput: 384.7kiB/s\r\n",
      "Copying file://./tuning_data/test_data.tsv to gs://sample-search-tuning-genai-customersupport/tuning_data/test_data.tsv\r\n",
      "Copying file://./tuning_data/training_data.tsv to gs://sample-search-tuning-genai-customersupport/tuning_data/training_data.tsv\r\n",
      "  Completed files 2/2 | 2.2kiB/2.2kiB                                          \r\n",
      "\r\n",
      "Average throughput: 723.2kiB/s\r\n",
      "gs://sample-search-tuning-genai-customersupport/tuning_data/FAQ-Kubernetes-Client.md\r\n",
      "gs://sample-search-tuning-genai-customersupport/tuning_data/FAQ-Kubernetes-Client.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/tuning_data/FAQ.md\r\n",
      "gs://sample-search-tuning-genai-customersupport/tuning_data/FAQ.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/tuning_data/README.md\r\n",
      "gs://sample-search-tuning-genai-customersupport/tuning_data/README.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/tuning_data/corpus_file.jsonl\r\n",
      "gs://sample-search-tuning-genai-customersupport/tuning_data/query_file.jsonl\r\n",
      "gs://sample-search-tuning-genai-customersupport/tuning_data/test_data.tsv\r\n",
      "gs://sample-search-tuning-genai-customersupport/tuning_data/training_data.tsv\r\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53d377765df5"
   },
   "source": [
    "#### Uploading the datasets for the search tuning and perform the tuning\n",
    "\n",
    "These are the information on the tuning dataset files to be used to tune the backend LLM behind the search app. Please refer to the [Prepare data for ingesting](https://cloud.google.com/generative-ai-app-builder/docs/prepare-data#website) in the Google Cloud Documentation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b91ea4e8b7a5",
    "ExecuteTime": {
     "end_time": "2025-04-16T08:25:32.106155Z",
     "start_time": "2025-04-16T08:25:32.103388Z"
    }
   },
   "source": [
    "data_store_id = f\"{SEARCH_DATASTORE_ID}\"\n",
    "corpus_data_path = f\"{TUNING_DATA_PATH_REMOTE}/corpus_file.jsonl\"\n",
    "query_data_path = f\"{TUNING_DATA_PATH_REMOTE}/query_file.jsonl\"\n",
    "train_data_path = f\"{TUNING_DATA_PATH_REMOTE}/training_data.tsv\"\n",
    "test_data_path = f\"{TUNING_DATA_PATH_REMOTE}/test_data.tsv\""
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1a44073dbafc"
   },
   "source": [
    "This ```train_custom_model``` function is to submit a search tuning job with the datasets we just prepared."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "47206888e8e1",
    "ExecuteTime": {
     "end_time": "2025-04-16T08:40:39.100658Z",
     "start_time": "2025-04-16T08:25:34.243077Z"
    }
   },
   "source": [
    "tuning_op = train_custom_model(\n",
    "    PROJECT_ID,\n",
    "    LOCATION,\n",
    "    data_store_id,\n",
    "    corpus_data_path,\n",
    "    query_data_path,\n",
    "    train_data_path,\n",
    "    test_data_path,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete: projects/1011110730258/locations/global/collections/default_collection/dataStores/search-datastore-genai-customersupport-cqbfgumcsmwnyz9gbccwuq/operations/train-custom-model-11030764292033396174\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "Operation did not complete within the designated timeout of 900 seconds.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31m_OperationNotComplete\u001B[0m                     Traceback (most recent call last)",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001B[0m, in \u001B[0;36mretry_target\u001B[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 144\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mtarget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misawaitable(result):\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/future/polling.py:120\u001B[0m, in \u001B[0;36mPollingFuture._done_or_raise\u001B[0;34m(self, retry)\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdone(retry\u001B[38;5;241m=\u001B[39mretry):\n\u001B[0;32m--> 120\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m _OperationNotComplete()\n",
      "\u001B[0;31m_OperationNotComplete\u001B[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRetryError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/future/polling.py:137\u001B[0m, in \u001B[0;36mPollingFuture._blocking_poll\u001B[0;34m(self, timeout, retry, polling)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 137\u001B[0m     \u001B[43mpolling\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_done_or_raise\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mRetryError:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001B[0m, in \u001B[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    290\u001B[0m sleep_generator \u001B[38;5;241m=\u001B[39m exponential_sleep_generator(\n\u001B[1;32m    291\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initial, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maximum, multiplier\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_multiplier\n\u001B[1;32m    292\u001B[0m )\n\u001B[0;32m--> 293\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mretry_target\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m    \u001B[49m\u001B[43msleep_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[43m    \u001B[49m\u001B[43mon_error\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001B[0m, in \u001B[0;36mretry_target\u001B[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;66;03m# defer to shared logic for handling errors\u001B[39;00m\n\u001B[0;32m--> 153\u001B[0m     \u001B[43m_retry_error_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdeadline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43msleep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpredicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexception_factory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;66;03m# if exception not raised, sleep before next attempt\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:221\u001B[0m, in \u001B[0;36m_retry_error_helper\u001B[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001B[0m\n\u001B[1;32m    216\u001B[0m     final_exc, source_exc \u001B[38;5;241m=\u001B[39m exc_factory_fn(\n\u001B[1;32m    217\u001B[0m         error_list,\n\u001B[1;32m    218\u001B[0m         RetryFailureReason\u001B[38;5;241m.\u001B[39mTIMEOUT,\n\u001B[1;32m    219\u001B[0m         original_timeout,\n\u001B[1;32m    220\u001B[0m     )\n\u001B[0;32m--> 221\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m final_exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msource_exc\u001B[39;00m\n\u001B[1;32m    222\u001B[0m _LOGGER\u001B[38;5;241m.\u001B[39mdebug(\n\u001B[1;32m    223\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRetrying due to \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, sleeping \u001B[39m\u001B[38;5;132;01m{:.1f}\u001B[39;00m\u001B[38;5;124ms ...\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(error_list[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], next_sleep)\n\u001B[1;32m    224\u001B[0m )\n",
      "\u001B[0;31mRetryError\u001B[0m: Timeout of 900.0s exceeded, last exception: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTimeoutError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m tuning_op \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_custom_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mPROJECT_ID\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mLOCATION\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_store_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcorpus_data_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery_data_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_data_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_data_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[17], line 33\u001B[0m, in \u001B[0;36mtrain_custom_model\u001B[0;34m(project_id, location, data_store_id, corpus_data_path, query_data_path, train_data_path, test_data_path, client_options)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# Optional: Wait for training to complete\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWaiting for operation to complete: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moperation\u001B[38;5;241m.\u001B[39moperation\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 33\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43moperation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# After the operation is complete,\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# get information from operation metadata\u001B[39;00m\n\u001B[1;32m     37\u001B[0m metadata \u001B[38;5;241m=\u001B[39m discoveryengine\u001B[38;5;241m.\u001B[39mTrainCustomModelMetadata(operation\u001B[38;5;241m.\u001B[39mmetadata)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/future/polling.py:256\u001B[0m, in \u001B[0;36mPollingFuture.result\u001B[0;34m(self, timeout, retry, polling)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mresult\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_DEFAULT_VALUE, retry\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, polling\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    145\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get the result of the operation.\u001B[39;00m\n\u001B[1;32m    146\u001B[0m \n\u001B[1;32m    147\u001B[0m \u001B[38;5;124;03m    This method will poll for operation status periodically, blocking if\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;124;03m            the timeout is reached before the operation completes.\u001B[39;00m\n\u001B[1;32m    254\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 256\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_blocking_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpolling\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpolling\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    258\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;66;03m# pylint: disable=raising-bad-type\u001B[39;00m\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001B[39;00m\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/future/polling.py:139\u001B[0m, in \u001B[0;36mPollingFuture._blocking_poll\u001B[0;34m(self, timeout, retry, polling)\u001B[0m\n\u001B[1;32m    137\u001B[0m     polling(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_done_or_raise)(retry\u001B[38;5;241m=\u001B[39mretry)\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mRetryError:\n\u001B[0;32m--> 139\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m concurrent\u001B[38;5;241m.\u001B[39mfutures\u001B[38;5;241m.\u001B[39mTimeoutError(\n\u001B[1;32m    140\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOperation did not complete within the designated timeout of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    141\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpolling\u001B[38;5;241m.\u001B[39mtimeout\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    142\u001B[0m     )\n",
      "\u001B[0;31mTimeoutError\u001B[0m: Operation did not complete within the designated timeout of 900 seconds."
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0e334074066"
   },
   "source": [
    "We can see that three additional documents related to the tuning task was uploaded to the datastore bucket, ```FAQ-Kubernetes-Client.pdf, FAQ.pdf, README.pdf.``` With these new documents, we should perform the indexing again by calling the ```import_documents``` method of the client again."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3c3d193b5c3e",
    "ExecuteTime": {
     "end_time": "2025-04-16T09:08:19.823301Z",
     "start_time": "2025-04-16T09:08:09.705695Z"
    }
   },
   "source": [
    "!gcloud storage cp \"{TUNING_DATA_PATH_LOCAL}/*.pdf\" \"{SEARCH_DATASTORE_PATH_REMOTE}\"\n",
    "!gcloud storage ls \"{SEARCH_DATASTORE_PATH_REMOTE}\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./tuning_data/FAQ.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/FAQ.pdf\r\n",
      "Copying file://./tuning_data/FAQ-Kubernetes-Client.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/FAQ-Kubernetes-Client.pdf\r\n",
      "Copying file://./tuning_data/README.pdf to gs://sample-search-tuning-genai-customersupport/rlhf-datastore/README.pdf\r\n",
      "  Completed files 3/3 | 272.2kiB/272.2kiB                                      \r\n",
      "\r\n",
      "Average throughput: 2.0MiB/s\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/FAQ-Kubernetes-Client.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/FAQ.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/Few-Shot Preference Learning for Human-in-the-Loop Reinforcement Learning.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/README.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/Scaling GAIA-1_ 9-billion parameter generative world model for autonomous driving - Wayve.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[1701.06049] Interactive Learning from Policy-Dependent Human Feedback.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[1706.03741] Deep reinforcement learning from human preferences.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[1709.10163] Deep TAMER - Interactive Agent Shaping in High-Dimensional State Spaces.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[1811.06521] Reward learning from human preferences and demonstrations in Atari.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[1811.07871] Scalable agent alignment via reward modeling - a research direction.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[1909.08593] Fine-Tuning Language Models from Human Preferences.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2009.01325] Learning to summarize from human feedback.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2106.08942] Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2109.10862] Recursively Summarizing Books with Human Feedback.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2112.09332] WebGPT - Browser-assisted question-answering with human feedback.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2203.02155] Training language models to follow instructions with human feedback.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2203.11147] Teaching language models to support answers with verified quotes.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2204.05862] Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2205.13636] Quark - Controllable Text Generation with Reinforced Unlearning.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2205.15367] Non-Markovian Reward Modelling from Trajectory Labels via Interpretable Multiple Instance Learning.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2208.02294] Dynamic Planning in Open-Ended Dialogue using Reinforcement Learning.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2209.07858] Red Teaming Language Models to Reduce Harms - Methods, Scaling Behaviors, and Lessons Learned.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2209.14375] Improving alignment of dialogue agents via targeted human judgements.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2210.01241] Is Reinforcement Learning (Not) for Natural Language Processing.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2210.10760] Scaling Laws for Reward Model Overoptimization.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2212.08073] Constitutional AI - Harmlessness from AI Feedback.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2212.09251] Discovering Language Model Behaviors with Model-Written Evaluations.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2301.11270] Principled Reinforcement Learning with Human Feedback from Pairwise or K-wise Comparisons.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2302.05206] The Wisdom of Hindsight Makes Language Models Better Instruction Followers.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2302.07459] The Capacity for Moral Self-Correction in Large Language Models.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2302.08215] Aligning Language Models with Preferences through f-divergence Minimization.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2302.08242] Tuning computer vision models with task rewards.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2302.08582] Pretraining Language Models with Human Preferences.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2302.12192] Aligning Text-to-Image Models using Human Feedback.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2303.04671] Visual ChatGPT - Talking, Drawing and Editing with Visual Foundation Models.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2303.14420] Human Preference Score - Better Aligning Text-to-Image Models with Human Preference.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2304.05302v1] RRHF - Rank Responses to Align Language Models with Human Feedback without tears.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2304.05977v2] ImageReward - Learning and Evaluating Human Preferences for Text-to-Image Generation.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2304.06767] RAFT - Reward rAnked FineTuning for Generative Foundation Model Alignment.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2304.07297] Language Instructed Reinforcement Learning for Human-AI Coordination.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2305.00955] Bridging the Gap - A Survey on Integrating (Human) Feedback for Natural Language Generation.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2306.17492] Preference Ranking Optimization for Human Alignment.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2308.12050] Aligning Language Models with Offline Reinforcement Learning from Human.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[2309.17080] GAIA-1 - A Generative World Model for Autonomous Driving.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/[gpt-4] GPT-4 Technical Report.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/_1701.06049__Interactive_Learning_from_Policy-Dependent_Human_Feedback.pdf\r\n",
      "gs://sample-search-tuning-genai-customersupport/rlhf-datastore/awesome_rlhf/\r\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "17191f107297",
    "ExecuteTime": {
     "end_time": "2025-04-16T09:15:27.225540Z",
     "start_time": "2025-04-16T09:09:35.210541Z"
    }
   },
   "source": "metadata = import_documents(PROJECT_ID, LOCATION, SEARCH_DATASTORE_ID)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete: projects/1011110730258/locations/global/collections/default_collection/dataStores/search-datastore-genai-customersupport-cqbfgumcsmwnyz9gbccwuq/branches/0/operations/import-documents-7744050282961137366\n",
      "error_config {\n",
      "  gcs_prefix: \"gs://1011110730258_us_import_content/errors7744050282961134671\"\n",
      "}\n",
      "\n",
      "create_time {\n",
      "  seconds: 1744794581\n",
      "  nanos: 363484000\n",
      "}\n",
      "update_time {\n",
      "  seconds: 1744794916\n",
      "  nanos: 685589000\n",
      "}\n",
      "success_count: 46\n",
      "total_count: 46\n",
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32c8827f86e6"
   },
   "source": [
    "#### Testing the tuned search app endpoint with a question on Kubernetes\n",
    "\n",
    "The tuning job will take about 30 to 60 minutes. After the tuning job completed, we test the search app with a query prompt regarding Kubernetes which is the information in the documents indexed additionally with the tuning."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "214b65078ce4"
   },
   "source": [
    "QUERY_PROMPT = \"\"\"\n",
    "    How do I determine the status of a deployment of Kubernetes?\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa567f3c38eb"
   },
   "source": [
    "We can see that the information on the deployment of Kubernetes which was described in the FAQ documents are correctly returned with the new documents indexed in the tuning."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cdbb758533ef"
   },
   "source": [
    "search_response = search(PROJECT_ID, LOCATION, SEARCH_APP_ID, QUERY_PROMPT)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f717e9cb30e7"
   },
   "source": [
    "## Clean up\n",
    "\n",
    "We should clean up the deployed resources and data not to create unnecessary costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b2bf33f37c7"
   },
   "source": [
    "#### Deleting the search app"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "82138114c3bb"
   },
   "source": [
    "delete_search_app_op_name = delete_engine(PROJECT_ID, LOCATION, SEARCH_APP_ID)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba60668eb8bc"
   },
   "source": [
    "#### Deleting the documents in the datastore"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a76b43ef3767"
   },
   "source": [
    "purge_document_metadata = purge_documents(PROJECT_ID, LOCATION, SEARCH_DATASTORE_ID)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80f199d6f782"
   },
   "source": [
    "#### Deleting the datastore"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ac2f897cf840"
   },
   "source": [
    "delete_datastore_op_name = delete_data_store(PROJECT_ID, LOCATION, SEARCH_DATASTORE_ID)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2d0d394cb942"
   },
   "source": [
    "!gcloud storage rm -r \"{BUCKET_URI}\""
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "name": "vertexai-search-tuning.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
