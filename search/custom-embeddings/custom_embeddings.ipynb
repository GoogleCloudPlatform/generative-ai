{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3Gi-zdCeEbE"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcfbGhs1eJF6"
   },
   "source": [
    "# Document Q&A With Retrieval Augmented Generation\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/search/custom-embeddings/custom_embeddings.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/search/custom-embeddings/custom_embeddings.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/search/custom-embeddings/custom_embeddings.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghQ2aBsbnMyn"
   },
   "source": [
    "---\n",
    "\n",
    "* Author: Holt Skinner\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "\n",
    "  - Get text embeddings using [`textembedding-gecko` in Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings)\n",
    "  - Convert embeddings into the [format expected by Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/prepare-data#unstructured)\n",
    "  - [Create a search app with custom embeddings](https://cloud.google.com/generative-ai-app-builder/docs/bring-embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsW5tPDRkT4m"
   },
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jx1FQVAokWVb"
   },
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJFw23w1kYVj"
   },
   "outputs": [],
   "source": [
    "%pip install -q --upgrade --user google-cloud-aiplatform google-cloud-discoveryengine google-cloud-storage google-cloud-bigquery[pandas] ipywidgets retrying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### ⚠️ Do not forget to click the \"RESTART RUNTIME\" button above.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jwsaMQYkZm8"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, you will need to authenticate your environment. To do this, run the new cell below. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikOmH4doxOFs"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-h0ba4rmkpKW"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLUml_s7iqBc"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import requests\n",
    "import vertexai\n",
    "\n",
    "from vertexai.language_models import TextEmbeddingModel, TextEmbeddingInput\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure notebook environment\n",
    "\n",
    "### Set the following constants to reflect your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define project information for Vertex AI\n",
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating embeddings with Vertex AI\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "We will be using [the Stack Overflow public dataset](https://console.cloud.google.com/marketplace/product/stack-exchange/stack-overflow) hosted on BigQuery table `bigquery-public-data.stackoverflow.posts_questions`.\n",
    "\n",
    "This is a very big dataset with 23 million rows that doesn't fit into the memory. We are going to limit it to 1000 rows for this tutorial.\n",
    "\n",
    "- Fetch the data from BigQuery\n",
    "- Get the HTML from the StackOverflow Question page\n",
    "   - Upload it to GCS as the Document Store/for displayed search results\n",
    "- Concat the Title and Body, and create embeddings from the text.\n",
    "- Save the rest of the fields as Metadata\n",
    "- Create a JSONL file and upload to Cloud Storage\n",
    "- Import JSONL file as Unstructured with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the BQ Table into a Pandas Dataframe\n",
    "from google.cloud import bigquery\n",
    "\n",
    "QUESTIONS_SIZE = 1000\n",
    "\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "  DISTINCT \n",
    "  q.id,\n",
    "  q.title,\n",
    "  q.body,\n",
    "  q.answer_count,\n",
    "  q.comment_count,\n",
    "  q.creation_date,\n",
    "  q.favorite_count,\n",
    "  q.last_activity_date,\n",
    "  q.score,\n",
    "  q.tags,\n",
    "  q.view_count\n",
    "FROM\n",
    "  `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "WHERE\n",
    "  q.score > 0\n",
    "ORDER BY\n",
    "  q.view_count DESC\n",
    "LIMIT\n",
    "  {QUESTIONS_SIZE};\n",
    "\"\"\"\n",
    "\n",
    "query_job = bq_client.query(query)\n",
    "rows = query_job.result()\n",
    "df = rows.to_dataframe()\n",
    "\n",
    "# Convert ID to String\n",
    "df[\"id\"] = df[\"id\"].apply(str)\n",
    "\n",
    "# examine the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the API to generate embeddings\n",
    "\n",
    "With the Stack Overflow dataset, we will use the `title` column (the question title) and generate embedding for it with Embeddings for Text API. The API is available under the [`vertexai`](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai) package of the SDK.\n",
    "\n",
    "You may see some warning messages from the TensorFlow library but you can ignore them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the package, import [`TextEmbeddingModel`](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.language_models.TextEmbeddingModel) and get a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text embeddings model\n",
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm  # to show a progress bar\n",
    "\n",
    "# Get embeddings for a list of texts\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "\n",
    "def get_embeddings_wrapper(texts, batch_size: int = BATCH_SIZE) -> List:\n",
    "    embs = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        time.sleep(1)  # to avoid the quota error\n",
    "\n",
    "        # Create embeddings optimized for document retrieval\n",
    "        # (supported in textembedding-gecko@002)\n",
    "        result = model.get_embeddings(\n",
    "            [\n",
    "                TextEmbeddingInput(text=text, task_type=\"RETRIEVAL_DOCUMENT\")\n",
    "                for text in texts[i : i + batch_size]\n",
    "            ]\n",
    "        )\n",
    "        embs.extend([e.values for e in result])\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get embeddings for the question titles/body and add them as the `\"embedding\"` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_body\"] = df[\"title\"] + \"\\n\" + df[\"body\"]\n",
    "\n",
    "df = df.assign(embedding=get_embeddings_wrapper(df.title_body))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKBmi2BMk_OU"
   },
   "source": [
    "## Scrape HTML from Question Pages\n",
    "\n",
    "- Grab HTML to upload to Cloud Storage\n",
    "- This will be used for the search results links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXHmC10IitET"
   },
   "outputs": [],
   "source": [
    "JSONL_MIME_TYPE = \"application/jsonl\"\n",
    "HTML_MIME_TYPE = \"text/html\"\n",
    "\n",
    "BUCKET_NAME = \"ucs-demo\"\n",
    "DIRECTORY = \"embeddings-stackoverflow\"\n",
    "BLOB_PREFIX = f\"{DIRECTORY}/html/\"\n",
    "\n",
    "GCS_URI_PREFIX = f\"gs://{BUCKET_NAME}/{BLOB_PREFIX}\"\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "\n",
    "def scrape_question(question_url: str) -> str:\n",
    "    response = requests.get(question_url)\n",
    "\n",
    "    if response.status_code != 200 or not response.content:\n",
    "        print(f\"URL: {question_url} Code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Scraping {question_url}\")\n",
    "\n",
    "    link_title = response.url.split(\"/\")[-1] + \".html\"\n",
    "    gcs_uri = f\"{GCS_URI_PREFIX}{link_title}\"\n",
    "\n",
    "    # Upload HTML to Google Cloud Storage\n",
    "    blob = bucket.blob(f\"{BLOB_PREFIX}{link_title}\")\n",
    "    blob.upload_from_string(response.content, content_type=HTML_MIME_TYPE)\n",
    "    time.sleep(1)\n",
    "    return gcs_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the published URL from the ID\n",
    "QUESTION_BASE_URL = \"https://stackoverflow.com/questions/\"\n",
    "df[\"question_url\"] = df[\"id\"].apply(lambda x: f\"{QUESTION_BASE_URL}{x}\")\n",
    "\n",
    "# Scrape HTML from stackoverflow.com and upload to GCS\n",
    "df[\"gcs_uri\"] = df[\"question_url\"].apply(scrape_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restructure the embeddings data to follow Vertex AI Search format (Unstructured with Metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_FIELD_NAME = \"embedding_vector\"\n",
    "\n",
    "\n",
    "def format_row(row):\n",
    "    return {\n",
    "        \"id\": row[\"id\"],\n",
    "        \"content\": {\"mimeType\": HTML_MIME_TYPE, \"uri\": row[\"gcs_uri\"]},\n",
    "        \"structData\": {\n",
    "            {EMBEDDINGS_FIELD_NAME}: row[\"embedding\"],\n",
    "            \"title\": row[\"title\"],\n",
    "            \"body\": row[\"body\"],\n",
    "            \"answer_count\": row[\"answer_count\"],\n",
    "            \"question_url\": row[\"question_url\"],\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "jsonl_filename = \"vais_embeddings.jsonl\"\n",
    "\n",
    "with open(jsonl_filename, \"w\") as f:\n",
    "    f.write(\n",
    "        df.apply(format_row, axis=1)\n",
    "        .to_json(orient=\"records\", lines=True, force_ascii=False)\n",
    "        .replace(\"\\/\", \"/\")  # To prevent escaping the / characters\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the JSONL file to Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_file = f\"gs://{BUCKET_NAME}/{DIRECTORY}/{jsonl_filename}\"\n",
    "!gsutil mv {jsonl_filename} {embeddings_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Vertex AI Search & Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import discoveryengine_v1alpha as discoveryengine\n",
    "\n",
    "DATA_STORE_LOCATION = \"global\"\n",
    "\n",
    "client_options = (\n",
    "    ClientOptions(api_endpoint=f\"{DATA_STORE_LOCATION}-discoveryengine.googleapis.com\")\n",
    "    if DATA_STORE_LOCATION != \"global\"\n",
    "    else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core.exceptions import GoogleAPICallError\n",
    "\n",
    "\n",
    "def create_data_store(\n",
    "    project_id: str, location: str, data_store_name: str, data_store_id: str\n",
    "):\n",
    "    # Create a client\n",
    "    client = discoveryengine.DataStoreServiceClient(client_options=client_options)\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    data_store = discoveryengine.DataStore(\n",
    "        display_name=data_store_name,\n",
    "        industry_vertical=\"GENERIC\",\n",
    "        content_config=\"CONTENT_REQUIRED\",\n",
    "        solution_types=[\"SOLUTION_TYPE_SEARCH\"],\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.CreateDataStoreRequest(\n",
    "        parent=discoveryengine.DataStoreServiceClient.collection_path(\n",
    "            project_id, location, \"default_collection\"\n",
    "        ),\n",
    "        data_store=data_store,\n",
    "        data_store_id=data_store_id,\n",
    "    )\n",
    "    operation = client.create_data_store(request=request)\n",
    "\n",
    "    try:\n",
    "        operation.result()\n",
    "    except GoogleAPICallError:\n",
    "        pass\n",
    "\n",
    "\n",
    "def update_schema(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "):\n",
    "    client = discoveryengine.SchemaServiceClient(client_options=client_options)\n",
    "\n",
    "    schema = discoveryengine.Schema(\n",
    "        name=client.schema_path(project_id, location, data_store_id, \"default_schema\"),\n",
    "        struct_schema={\n",
    "            \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                EMBEDDINGS_FIELD_NAME: {\n",
    "                    \"type\": \"array\",\n",
    "                    \"keyPropertyMapping\": \"embedding_vector\",\n",
    "                    \"dimension\": 768,\n",
    "                    \"items\": {\"type\": \"number\"},\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "\n",
    "    operation = client.update_schema(\n",
    "        request=discoveryengine.UpdateSchemaRequest(schema=schema)\n",
    "    )\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "\n",
    "    response = operation.result()\n",
    "\n",
    "    # Handle the response\n",
    "    print(response)\n",
    "\n",
    "\n",
    "def import_documents(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    gcs_uri: str,\n",
    "):\n",
    "    client = discoveryengine.DocumentServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the search engine branch.\n",
    "    # e.g. projects/{project}/locations/{location}/dataStores/{data_store_id}/branches/{branch}\n",
    "    parent = client.branch_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        data_store=data_store_id,\n",
    "        branch=\"default_branch\",\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.ImportDocumentsRequest(\n",
    "        parent=parent,\n",
    "        gcs_source=discoveryengine.GcsSource(input_uris=[gcs_uri]),\n",
    "        # Options: `FULL`, `INCREMENTAL`\n",
    "        reconciliation_mode=discoveryengine.ImportDocumentsRequest.ReconciliationMode.FULL,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.import_documents(request=request)\n",
    "\n",
    "\n",
    "def create_engine(\n",
    "    project_id: str, location: str, data_store_name: str, data_store_id: str\n",
    "):\n",
    "    client = discoveryengine.EngineServiceClient(client_options=client_options)\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    config = discoveryengine.Engine.SearchEngineConfig(\n",
    "        search_tier=\"SEARCH_TIER_ENTERPRISE\", search_add_ons=[\"SEARCH_ADD_ON_LLM\"]\n",
    "    )\n",
    "\n",
    "    engine = discoveryengine.Engine(\n",
    "        display_name=data_store_name,\n",
    "        solution_type=\"SOLUTION_TYPE_SEARCH\",\n",
    "        industry_vertical=\"GENERIC\",\n",
    "        data_store_ids=[data_store_id],\n",
    "        search_engine_config=config,\n",
    "    )\n",
    "\n",
    "    request = discoveryengine.CreateEngineRequest(\n",
    "        parent=discoveryengine.DataStoreServiceClient.collection_path(\n",
    "            project_id, location, \"default_collection\"\n",
    "        ),\n",
    "        engine=engine,\n",
    "        engine_id=engine.display_name,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.create_engine(request=request)\n",
    "    response = operation.result(timeout=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_STORE_NAME = \"stackoverflow-embeddings\"\n",
    "DATA_STORE_ID = f\"{DATA_STORE_NAME}-id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data Store\n",
    "create_data_store(PROJECT_ID, DATA_STORE_LOCATION, DATA_STORE_NAME, DATA_STORE_ID)\n",
    "\n",
    "# Update the Data Store Schema for embeddings\n",
    "update_schema(PROJECT_ID, DATA_STORE_LOCATION, DATA_STORE_ID)\n",
    "\n",
    "# Import the embeddings JSONL file\n",
    "import_documents(PROJECT_ID, DATA_STORE_LOCATION, DATA_STORE_ID, embeddings_file)\n",
    "\n",
    "# Create a Search App and attach the Data Store\n",
    "create_engine(PROJECT_ID, DATA_STORE_LOCATION, DATA_STORE_NAME, DATA_STORE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to set the embedding specification for the data store. We will set the same spec for all search requests.\n",
    "\n",
    "`0.5 * relevance_score`\n",
    "\n",
    "- This is not supported in client libraries, so we will use the  `requests` module to make a REST request\n",
    "- Documentation: https://cloud.google.com/generative-ai-app-builder/docs/bring-embeddings#global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import subprocess\n",
    "\n",
    "access_token = (\n",
    "    subprocess.check_output([\"gcloud\", \"auth\", \"print-access-token\"])\n",
    "    .decode(\"utf-8\")\n",
    "    .strip()\n",
    ")\n",
    "\n",
    "response = requests.patch(\n",
    "    url=f\"https://discoveryengine.googleapis.com/v1alpha/projects/{PROJECT_ID}/locations/{DATA_STORE_LOCATION}/collections/default_collection/dataStores/{DATA_STORE_ID}/servingConfigs/default_search?updateMask=embeddingConfig,rankingExpression\",\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {access_token}\",\n",
    "        \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "        \"X-Goog-User-Project\": PROJECT_ID,\n",
    "    },\n",
    "    json={\n",
    "        \"name\": f\"projects/{PROJECT_ID}/locations/{DATA_STORE_LOCATION}/collections/default_collection/dataStores/{DATA_STORE_ID}/servingConfigs/default_search\",\n",
    "        \"embeddingConfig\": {\"fieldPath\": EMBEDDINGS_FIELD_NAME},\n",
    "        \"ranking_expression\": \"0.5 * relevance_score\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Search App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def search_data_store(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    data_store_id: str,\n",
    "    search_query: str,\n",
    ") -> List[discoveryengine.SearchResponse]:\n",
    "    # Create a client\n",
    "    client = discoveryengine.SearchServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the search engine serving config\n",
    "    # e.g. projects/{project_id}/locations/{location}/dataStores/{data_store_id}/servingConfigs/{serving_config_id}\n",
    "    serving_config = client.serving_config_path(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "        data_store=data_store_id,\n",
    "        serving_config=\"default_config\",\n",
    "    )\n",
    "\n",
    "    # Optional: Configuration options for search\n",
    "    # Refer to the `ContentSearchSpec` reference for all supported fields:\n",
    "    # https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1.types.SearchRequest.ContentSearchSpec\n",
    "    content_search_spec = discoveryengine.SearchRequest.ContentSearchSpec(\n",
    "        # For information about snippets, refer to:\n",
    "        # https://cloud.google.com/generative-ai-app-builder/docs/snippets\n",
    "        snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(\n",
    "            return_snippet=True\n",
    "        ),\n",
    "        # For information about search summaries, refer to:\n",
    "        # https://cloud.google.com/generative-ai-app-builder/docs/get-search-summaries\n",
    "        summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(\n",
    "            summary_result_count=5,\n",
    "            include_citations=True,\n",
    "            ignore_adversarial_query=True,\n",
    "            ignore_non_summary_seeking_query=True,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Refer to the `SearchRequest` reference for all supported fields:\n",
    "    # https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1.types.SearchRequest\n",
    "    request = discoveryengine.SearchRequest(\n",
    "        serving_config=serving_config,\n",
    "        query=search_query,\n",
    "        page_size=10,\n",
    "        content_search_spec=content_search_spec,\n",
    "        query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(\n",
    "            condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,\n",
    "        ),\n",
    "        spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(\n",
    "            mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    response = client.search(request)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"How do I create an array in Java?\"\n",
    "\n",
    "response = search_data_store(\n",
    "    PROJECT_ID, DATA_STORE_LOCATION, DATA_STORE_ID, search_query\n",
    ")\n",
    "\n",
    "print(f\"Summary: {response.summary.summary_text}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
