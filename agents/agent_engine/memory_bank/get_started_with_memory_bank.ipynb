{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Get started with Vertex AI Memory Bank\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/memory_bank/get_started_with_memory_bank.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fagents%2Fagent_engine%2Fmemory_bank%2Fget_started_with_memory_bank.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/agents/agent_engine/memory_bank/get_started_with_memory_bank.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/memory_bank/get_started_with_memory_bank.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/memory_bank/get_started_with_memory_bank.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/memory_bank/get_started_with_memory_bank.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/memory_bank/get_started_with_memory_bank.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/memory_bank/get_started_with_memory_bank.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/memory_bank/get_started_with_memory_bank.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| Authors |\n",
        "| --- |\n",
        "| [Kimberly Milam](https://github.com/klmilam) |\n",
        " |[Ivan Nardini](https://github.com/inardini) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook is a hands-on guide to mastering **Vertex AI Memory Bank**, a service for building stateful, context-aware conversational AI agents. You will learn how to give your agent a persistent, long-term memory, allowing it to recall user preferences and past interactions across multiple sessions to provide truly personalized experiences. We will apply these concepts to a practical, real-world retail scenario: building a sophisticated assistant for an online fashion store.\n",
        "\n",
        "By the end of this tutorial, you will not only understand the core concepts of Memory Bank but also know how to apply them to build an assistant that remembers preferences, recalls purchase history, and maintains context across conversations.\n",
        "\n",
        "Here's a high-level overview of the steps we'll take:\n",
        "\n",
        "* **Initial Setup**: We will begin with the fundamentals, configuring a new Memory Bank instance and learning how to create user sessions to store and retrieve conversation history.\n",
        "* **Advanced Retrieval & Personalization**: We will explore advanced retrieval capabilities, leveraging similarity search to recall the most relevant memories and use them to personalize the agent's responses.\n",
        "* **Memory Customization**: We will dive into domain-specific adaptation by defining custom memory topics and providing few-shot examples to improve the accuracy of data extraction.\n",
        "* **Lifecycle Management**: Finally, we will address essential operational aspects like configuring Time-To-Live (TTL) for data retention and compliance, and managing the overall lifecycle of memories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Google Gen AI SDK and other required packages\n",
        "\n",
        "First, let's install the Vertex AI SDK. We're specifying a version greater than 1.111.0 to ensure we have all the latest Memory Bank features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet google-cloud-aiplatform>=1.111.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "# Use the environment variable if the user doesn't provide Project ID.\n",
        "import os\n",
        "\n",
        "import vertexai\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "client = vertexai.Client(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5303c05f7aa6"
      },
      "source": [
        "### Import libraries\n",
        "\n",
        "We're importing standard Python libraries and, importantly, several class-based types from the Vertex AI SDK.\n",
        "\n",
        "You can configure Memory Bank using plain Python dictionaries, but using these dedicated classes (MemoryBankConfig, TtlConfig, etc.) is a best practice. It provides type safety and makes your code more readable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fc324893334"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import os\n",
        "import uuid\n",
        "import warnings\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from google.genai.types import Content, Part\n",
        "\n",
        "# Import class-based types for Memory Bank\n",
        "from vertexai import types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKNfLSp3cP7T"
      },
      "source": [
        "To make the code more readable, we're creating shorter aliases for these long class names. This is a common Python practice that helps keep our code clean and concise without sacrificing the benefits of using the typed classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2BqjbVdcSko"
      },
      "outputs": [],
      "source": [
        "# Basic configuration types\n",
        "MemoryBankConfig = types.ReasoningEngineContextSpecMemoryBankConfig\n",
        "SimilaritySearchConfig = (\n",
        "    types.ReasoningEngineContextSpecMemoryBankConfigSimilaritySearchConfig\n",
        ")\n",
        "GenerationConfig = types.ReasoningEngineContextSpecMemoryBankConfigGenerationConfig\n",
        "\n",
        "# Advanced configuration types\n",
        "TtlConfig = types.ReasoningEngineContextSpecMemoryBankConfigTtlConfig\n",
        "GranularTtlConfig = (\n",
        "    types.ReasoningEngineContextSpecMemoryBankConfigTtlConfigGranularTtlConfig\n",
        ")\n",
        "CustomizationConfig = types.MemoryBankCustomizationConfig\n",
        "MemoryTopic = types.MemoryBankCustomizationConfigMemoryTopic\n",
        "ManagedMemoryTopic = types.MemoryBankCustomizationConfigMemoryTopicManagedMemoryTopic\n",
        "CustomMemoryTopic = types.MemoryBankCustomizationConfigMemoryTopicCustomMemoryTopic\n",
        "GenerateMemoriesExample = types.MemoryBankCustomizationConfigGenerateMemoriesExample\n",
        "ConversationSource = (\n",
        "    types.MemoryBankCustomizationConfigGenerateMemoriesExampleConversationSource\n",
        ")\n",
        "ConversationSourceEvent = (\n",
        "    types.MemoryBankCustomizationConfigGenerateMemoriesExampleConversationSourceEvent\n",
        ")\n",
        "ExampleGeneratedMemory = (\n",
        "    types.MemoryBankCustomizationConfigGenerateMemoriesExampleGeneratedMemory\n",
        ")\n",
        "ManagedTopicEnum = types.ManagedTopicEnum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHsP9oU5MoWO"
      },
      "source": [
        "## The basics of Vertex AI Memory Bank\n",
        "\n",
        "Let's start with the fundamentals. We'll create a Memory Bank, add a conversation, and perform basic memory generation and retrieval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jsG4B-7wwvF"
      },
      "source": [
        "### Create Agent Engine with Simple Configuration\n",
        "\n",
        "The AgentEngine resource acts as the top-level container for your Memory Bank instance. To create one, we need to provide a configuration.\n",
        "\n",
        "Here, MemoryBankConfig has two key parts:\n",
        "\n",
        "1. `similarity_search_config`: This specifies the **embedding model** used for similarity searches. Choosing the right model is important. If you expect multilingual conversations, you should opt for a model like `text-multilingual-embedding-002`. For now, `text-embedding-005` is a great default.  \n",
        "2. `generation_config`: This defines the **LLM** that will extract and consolidate memories from conversations. The default, `gemini-2.5-flash`, is a fast and capable model perfect for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6CBq3whwzqW"
      },
      "outputs": [],
      "source": [
        "print(\"üß† Creating simple memory configuration...\\n\")\n",
        "\n",
        "basic_memory_config = MemoryBankConfig(\n",
        "    # Which embedding model to use for similarity search\n",
        "    similarity_search_config=SimilaritySearchConfig(\n",
        "        embedding_model=f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/text-embedding-005\"\n",
        "    ),\n",
        "    # Which LLM to use for extracting memories from conversations\n",
        "    generation_config=GenerationConfig(\n",
        "        model=f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/gemini-2.5-flash\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Simple memory configuration created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifU6gZZnZ2LC"
      },
      "source": [
        "Now, we create the AgentEngine resource. In this context, the AgentEngine acts as the top-level container for our Memory Bank instance. By default, Memory Bank is enabled when you create an Agent Engine. This call provisions the necessary backend infrastructure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGbqSDOH3OfI"
      },
      "outputs": [],
      "source": [
        "print(\"üõ†Ô∏è Creating agent engine with basic configuration...\\n\")\n",
        "\n",
        "agent_engine = client.agent_engines.create(\n",
        "    config={\"context_spec\": {\"memory_bank_config\": basic_memory_config}}\n",
        ")\n",
        "\n",
        "agent_engine_name = agent_engine.api_resource.name\n",
        "print(\"‚úÖ Agent Engine created with basic configuration!\")\n",
        "print(f\"   Resource Name: {agent_engine_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6Yf1Tdq3uru"
      },
      "source": [
        "### Create a Session and Store a Simple Conversation\n",
        "\n",
        "A **Session** is a chronological log of a single interaction between a user and your agent. It's the raw material from which memories are made. A critical piece of information here is the user\\_id. Memories are mapped to this ID, which allows the agent to recall information for a specific user across different sessions.\n",
        "\n",
        "> Note: Using Vertex AI Agent Engine Session is not the only option supported. [Provide the source conversation directly in JSON format](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/memory-bank/generate-memories#json-format) if you're using a different session storage from Agent Engine Sessions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3oirRxi3z7t"
      },
      "outputs": [],
      "source": [
        "print(\"üí¨ Creating a session for our customer...\\n\")\n",
        "\n",
        "user_id = \"customer_sarah_\" + str(uuid.uuid4())[:4]\n",
        "\n",
        "# Create a session\n",
        "session = client.agent_engines.sessions.create(\n",
        "    name=agent_engine_name,\n",
        "    user_id=user_id,\n",
        "    config={\"display_name\": f\"Shopping session for {user_id}\"},\n",
        ")\n",
        "\n",
        "session_name = session.response.name\n",
        "print(f\"‚úÖ Session created: {session_name}\")\n",
        "print(f\"   Customer: {user_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXdtAotNaC9N"
      },
      "source": [
        "This is the raw conversational data we'll use. It's a simple list of dictionaries, each representing a turn in the dialogue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NP6EgymN4v6I"
      },
      "outputs": [],
      "source": [
        "# Add a simple conversation\n",
        "simple_conversation = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"message\": \"Hi! I'm Sarah. I bought a navy blazer from you last month for $159 and it fits perfectly!\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"model\",\n",
        "        \"message\": \"Hello Sarah! Wonderful to hear you're enjoying your navy blazer!\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"message\": \"Yes! I wear size M in jackets but size L in sweaters. I prefer fitted jackets.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"model\",\n",
        "        \"message\": \"I've noted your size preferences - M for fitted jackets and L for sweaters.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"message\": \"I'm looking for a winter coat now. I only buy during sales though - never pay full price! Budget is $150-200.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"model\",\n",
        "        \"message\": \"I'll help you find winter coats on sale within your $150-200 budget.\",\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV9aBl00cry2"
      },
      "source": [
        "Here, we loop through our conversation and append each turn as an event to the session we created earlier. This persists the conversation history, making it available for memory generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51Rxi0nQ4tlO"
      },
      "outputs": [],
      "source": [
        "print(\"‚¨ÜÔ∏è Adding conversation to session...\\n\")\n",
        "\n",
        "invocation_id = 0\n",
        "\n",
        "for turn in simple_conversation:\n",
        "    client.agent_engines.sessions.events.append(\n",
        "        name=session_name,\n",
        "        author=user_id,  # Required by Sessions\n",
        "        invocation_id=str(invocation_id),  # Required by Sessions\n",
        "        timestamp=datetime.datetime.now(\n",
        "            tz=datetime.timezone.utc\n",
        "        ),  # Required by Sessions\n",
        "        config={\n",
        "            \"content\": {\"role\": turn[\"role\"], \"parts\": [{\"text\": turn[\"message\"]}]}\n",
        "        },\n",
        "    )\n",
        "\n",
        "    invocation_id += 1\n",
        "    icon = \"üë§\" if turn[\"role\"] == \"user\" else \"ü§ñ\"\n",
        "    print(f\"{icon} {turn['message']}\")\n",
        "\n",
        "print(\"\\n‚úÖ Conversation added to session!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vCs_ZrKJYCB"
      },
      "source": [
        "### Generate Memories from Conversation\n",
        "\n",
        "Now let's see what memories are automatically extracted using the default configuration.\n",
        "\n",
        "This is the core of memory generation. The generate method kicks off an asynchronous, long-running operation that performs two main steps:\n",
        "\n",
        "1. **Extraction**: The generation model reads the conversation and extracts key facts. With the default configuration, it looks for information that matches pre-defined **Managed Topics** like `USER_PERSONAL_INFO` and `USER_PREFERENCES`.  \n",
        "2. **Consolidation**: Memory Bank intelligently merges new facts with existing memories, avoiding duplicates and resolving contradictions.\n",
        "\n",
        "> Note: The `wait_for_completion=True` flag is the default setting and makes this a blocking call, which is useful for this tutorial. In production, you would typically set it to `False` to run in the background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UQjJAfYJezr"
      },
      "outputs": [],
      "source": [
        "print(\"üß† Generating memories with default configuration...\\n\")\n",
        "\n",
        "# Generate memories from the session\n",
        "operation = client.agent_engines.memories.generate(\n",
        "    name=agent_engine_name,\n",
        "    vertex_session_source={\"session\": session_name},\n",
        "    config={\"wait_for_completion\": True},\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Memories generated!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ill5ZQSagV3"
      },
      "source": [
        "The result of the generate operation is a list of generated memories, each with an associated action (CREATED, UPDATED, or DELETED). We'll loop through the response and use the get method to fetch the full text (fact) of each newly created memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxR5eHvEMC4w"
      },
      "outputs": [],
      "source": [
        "if operation.response and operation.response.generated_memories:\n",
        "    print(f\"‚úÖ Generated {len(operation.response.generated_memories)} memories:\\n\")\n",
        "\n",
        "    for i, gen_memory in enumerate(operation.response.generated_memories, 1):\n",
        "        if gen_memory.action != \"DELETED\" and gen_memory.memory:\n",
        "            try:\n",
        "                full_memory = client.agent_engines.memories.get(\n",
        "                    name=gen_memory.memory.name\n",
        "                )\n",
        "                print(f\"   {i}. {full_memory.fact}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not retrieve memory: {e}\")\n",
        "else:\n",
        "    print(\"No memories generated\")\n",
        "\n",
        "print(\"\\nüí° Note: These memories were extracted using default managed topics\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvXzpZM2Lfvj"
      },
      "source": [
        "### Simple Memory Retrieval\n",
        "\n",
        "Let's retrieve all memories for our customer.\n",
        "Now, let's retrieve the memories we just created. The simplest method is scope-based retrieval. A \"scope\" is a set of key-value pairs that defines a collection of memories. By providing {\"user_id\": user_id}, we are asking for all memories that exactly match this scope."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OuDehrgLnwB"
      },
      "outputs": [],
      "source": [
        "print(f\"üìö Retrieving all memories for {user_id}...\\n\")\n",
        "\n",
        "# Simple retrieval - get all memories\n",
        "results = client.agent_engines.memories.retrieve(\n",
        "    name=agent_engine_name, scope={\"user_id\": user_id}\n",
        ")\n",
        "\n",
        "all_memories = list(results)\n",
        "print(f\"Found {len(all_memories)} memories:\\n\")\n",
        "\n",
        "for i, retrieved_memory in enumerate(all_memories, 1):\n",
        "    print(f\"{i}. {retrieved_memory.memory.fact}\")\n",
        "\n",
        "print(\"\\n‚úÖ Basic Memory Bank setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unkw7gzqMyJa"
      },
      "source": [
        "## Advanced Retrieval and Personalization\n",
        "\n",
        "Retrieving all memories is good, but retrieving the most relevant memories is great. This is where similarity search shines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kqt5jklNBBI"
      },
      "source": [
        "### **Similarity Search**\n",
        "\n",
        "Now let's use similarity search to find only relevant memories for specific queries.\n",
        "\n",
        "To make our similarity search more interesting, let's add more conversational turns to our session, which will generate a richer set of memories.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgvend-mNDMN"
      },
      "outputs": [],
      "source": [
        "# Add more conversation to have richer memories\n",
        "additional_conversation = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"message\": \"Hi! I bought a black leather jacket from you last year for $299. It was perfect!\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"model\",\n",
        "        \"message\": \"Great to hear you loved the black leather jacket Sarah! Let me find similar styles.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"message\": \"Also, remember I prefer shopping during sales. My shipping address is 123 Main St, San Francisco.\",\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQf20RmAdLGg"
      },
      "source": [
        "We append these new turns to the same session object as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnRsjBjcNTWZ"
      },
      "outputs": [],
      "source": [
        "print(\"üí¨ Adding more conversation...\\n\")\n",
        "\n",
        "# Add each turn to the session\n",
        "for turn in additional_conversation:\n",
        "    client.agent_engines.sessions.events.append(\n",
        "        name=session_name,\n",
        "        author=user_id,  # Required by Sessions\n",
        "        invocation_id=str(invocation_id),  # Required by Sessions\n",
        "        timestamp=datetime.datetime.now(\n",
        "            tz=datetime.timezone.utc\n",
        "        ),  # Required by Sessions\n",
        "        config={\n",
        "            \"content\": {\"role\": turn[\"role\"], \"parts\": [{\"text\": turn[\"message\"]}]}\n",
        "        },\n",
        "    )\n",
        "\n",
        "    invocation_id += 1\n",
        "    icon = \"üë§\" if turn[\"role\"] == \"user\" else \"ü§ñ\"\n",
        "    print(f\"{icon} {turn['message']}\")\n",
        "\n",
        "print(\"\\n‚úÖ Conversation added to session!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMxnGbrRdOgT"
      },
      "source": [
        "Now, we run the generate process again. Memory Bank will process the *entire* conversation history in the session, extract new facts, and consolidate them with the memories that already exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfeacloTOdl5"
      },
      "outputs": [],
      "source": [
        "print(\"üß† Generating additional memories with default configuration...\\n\")\n",
        "\n",
        "operation = client.agent_engines.memories.generate(\n",
        "    name=agent_engine_name,\n",
        "    vertex_session_source={\"session\": session_name},\n",
        "    config={\"wait_for_completion\": True},\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Additional memories generated!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlJgprSssWMM"
      },
      "source": [
        "Let's look at the new memories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn3EZdNfsZIX"
      },
      "outputs": [],
      "source": [
        "if operation.response and operation.response.generated_memories:\n",
        "    print(f\"‚úÖ Generated {len(operation.response.generated_memories)} new memories:\\n\")\n",
        "\n",
        "    for i, gen_memory in enumerate(operation.response.generated_memories, 1):\n",
        "        if gen_memory.action != \"DELETED\" and gen_memory.memory:\n",
        "            try:\n",
        "                full_memory = client.agent_engines.memories.get(\n",
        "                    name=gen_memory.memory.name\n",
        "                )\n",
        "                print(f\"   {i}. {full_memory.fact}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not retrieve memory: {e}\")\n",
        "else:\n",
        "    print(\"No new memories generated\")\n",
        "\n",
        "print(\"\\nüí° Note: These memories were extracted using default managed topics\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AH90QWAdSlH"
      },
      "source": [
        "Now, instead of retrieving all memories, we provide a search_query. Memory Bank embeds this query and compares it to the embedded memory facts, returning the most similar ones.\n",
        "\n",
        "* `top_k`: Limits the number of results returned.  \n",
        "* `distance`: The Euclidean distance between the query and memory embedding. A smaller distance means higher relevance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hTimWzJPj_2"
      },
      "outputs": [],
      "source": [
        "# Similarity search - find relevant memories for specific queries\n",
        "search_queries = [\n",
        "    \"What's the customer's name?\",\n",
        "    \"What are the customer's style preferences?\",\n",
        "    \"What is the customer's budget?\",\n",
        "]\n",
        "\n",
        "print(\"üîç Testing similarity search:\\n\")\n",
        "\n",
        "for query in search_queries:\n",
        "    print(f'Query: \"{query}\"')\n",
        "\n",
        "    # Similarity search with top_k parameter\n",
        "    results = client.agent_engines.memories.retrieve(\n",
        "        name=agent_engine_name,\n",
        "        scope={\"user_id\": user_id},\n",
        "        similarity_search_params={\n",
        "            \"search_query\": query,\n",
        "            \"top_k\": 2,  # Get top 2 most relevant\n",
        "        },\n",
        "    )\n",
        "\n",
        "    memories = list(results)\n",
        "    if memories:\n",
        "        for mem in memories:\n",
        "            distance = mem.distance if hasattr(mem, \"distance\") else \"N/A\"\n",
        "            print(f\"   ‚Üí {mem.memory.fact}\")\n",
        "            print(f\"     (Distance: {distance})\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPcvVCb9QTJ0"
      },
      "source": [
        "### Use memories for personalization\n",
        "\n",
        "This function demonstrates the real-world application of Memory Bank using the **Retrieval-Augmented Generation (RAG)** pattern.\n",
        "\n",
        "1. **Retrieve**: First, we use similarity search to fetch memories relevant to the user's current query.  \n",
        "2. **Augment**: We then insert these retrieved memories directly into the prompt we send to Gemini.  \n",
        "3. **Generate**: Gemini uses this augmented context to produce a highly personalized, factually-grounded response that it couldn't have generated on its own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY0CtQ_EQZO2"
      },
      "outputs": [],
      "source": [
        "def personalize_shopping_experience(customer_id, product_query):\n",
        "    \"\"\"Use memories to personalize product recommendations with Gemini.\"\"\"\n",
        "    # Initialize Gemini client\n",
        "    from google import genai\n",
        "\n",
        "    genai_client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "    print(f\"üõçÔ∏è Personalizing experience for: {product_query}\\n\")\n",
        "\n",
        "    # Retrieve relevant memories\n",
        "    results = client.agent_engines.memories.retrieve(\n",
        "        name=agent_engine_name,\n",
        "        scope={\"user_id\": customer_id},\n",
        "        similarity_search_params={\"search_query\": product_query, \"top_k\": 3},\n",
        "    )\n",
        "\n",
        "    memories = list(results)\n",
        "\n",
        "    print(\"üìã Customer Context (from memories):\")\n",
        "    memory_context = []\n",
        "    for mem in memories:\n",
        "        print(f\"   ‚Ä¢ {mem.memory.fact}\")\n",
        "        memory_context.append(mem.memory.fact)\n",
        "\n",
        "    # Use Gemini to generate personalized recommendations based on memories\n",
        "    print(\"\\nü§ñ Generating personalized recommendations with Gemini...\\n\")\n",
        "\n",
        "    # Create prompt with memory context\n",
        "    prompt = f\"\"\"You are a personal shopping assistant for an online fashion store.\n",
        "    Based on the following customer information from their history, provide 3 personalized product recommendations.\n",
        "\n",
        "    Customer History:\n",
        "    {chr(10).join(f\"- {fact}\" for fact in memory_context)}\n",
        "\n",
        "    Customer Query: {product_query}\n",
        "\n",
        "    Please provide 3 specific product recommendations with:\n",
        "    1. Product name and price\n",
        "    2. Why it matches their preferences\n",
        "    3. Any special offers or alerts relevant to their shopping behavior\n",
        "\n",
        "    Format your response as a numbered list with clear explanations.\"\"\"\n",
        "\n",
        "    # Generate recommendations with Gemini\n",
        "    response = genai_client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=prompt,\n",
        "    )\n",
        "\n",
        "    print(\"üéØ Personalized Recommendations from Gemini:\")\n",
        "    display(Markdown(response.text))\n",
        "\n",
        "    return response.text\n",
        "\n",
        "\n",
        "# Test personalization with Gemini\n",
        "recommendations = personalize_shopping_experience(\n",
        "    user_id, \"winter jacket recommendations\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVDCEHJCSvoc"
      },
      "source": [
        "## Customizing Memory Extraction\n",
        "\n",
        "The default managed topics are great for general-purpose agents, but for our specialized retail assistant, we can do better. We can teach Memory Bank about our specific domain using **Custom Topics** and **Few-Shot Examples**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F07muBiCbiOz"
      },
      "source": [
        "#### Custom Topics\n",
        "\n",
        "Now let's customize what types of memories we want to extract by defining custom topics.\n",
        "\n",
        "By default, Memory Bank uses pre-defined \"managed topics\" to identify and save meaningful information from conversations. These topics include:\n",
        "\n",
        "* **Personal information (`USER_PERSONAL_INFO`)**: Key details about the user, like their name or hobbies.\n",
        "* **User preferences (`USER_PREFERENCES`)**: The user's stated likes and dislikes.\n",
        "* **Key conversation events (`KEY_CONVERSATION_DETAILS`)**: Important outcomes or milestones reached in the dialogue.\n",
        "* **Explicit instructions (`EXPLICIT_INSTRUCTIONS`)**: Information the user directly asks the agent to remember or forget.\n",
        "\n",
        "You can customize which information is saved by providing a `CustomizationConfig` to use a subset of these topics or to define your own custom topics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxmnwS1sTH4q"
      },
      "source": [
        "##### Define Custom Memory Topics\n",
        "\n",
        "While Memory Bank provides general-purpose **Managed Topics**, the real power comes from defining your own **Custom Topics** to tailor memory extraction to your specific domain. For our retail assistant, topics like purchase_history and size_information are far more useful than generic ones. Each custom topic has a label and a detailed description that instructs the extraction LLM on what to look for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV7EmlhwTEY8"
      },
      "outputs": [],
      "source": [
        "print(\"üé® Defining custom topics...\\n\")\n",
        "\n",
        "custom_topics = [\n",
        "    # Keep some managed topics\n",
        "    MemoryTopic(\n",
        "        managed_memory_topic=ManagedMemoryTopic(\n",
        "            managed_topic_enum=ManagedTopicEnum.USER_PERSONAL_INFO\n",
        "        )\n",
        "    ),\n",
        "    MemoryTopic(\n",
        "        managed_memory_topic=ManagedMemoryTopic(\n",
        "            managed_topic_enum=ManagedTopicEnum.USER_PREFERENCES\n",
        "        )\n",
        "    ),\n",
        "    # Add custom topics specific to e-commerce\n",
        "    MemoryTopic(\n",
        "        custom_memory_topic=CustomMemoryTopic(\n",
        "            label=\"purchase_history\",\n",
        "            description=\"\"\"Details about past purchases including product names,\n",
        "                          prices, dates, and customer satisfaction with the products.\"\"\",\n",
        "        )\n",
        "    ),\n",
        "    MemoryTopic(\n",
        "        custom_memory_topic=CustomMemoryTopic(\n",
        "            label=\"size_information\",\n",
        "            description=\"\"\"Customer's clothing and shoe sizes for different types\n",
        "                          of apparel (shirts, pants, jackets, shoes).\"\"\",\n",
        "        )\n",
        "    ),\n",
        "    MemoryTopic(\n",
        "        custom_memory_topic=CustomMemoryTopic(\n",
        "            label=\"shopping_behavior\",\n",
        "            description=\"\"\"Shopping patterns including preferred shopping times,\n",
        "                          budget ranges, sale preferences, and brand loyalties.\"\"\",\n",
        "        )\n",
        "    ),\n",
        "]\n",
        "\n",
        "print(\"‚úÖ Custom topics defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4jmn5G5ULiu"
      },
      "source": [
        "##### Create customization configuration and Memory Bank config with customization\n",
        "\n",
        "We now package our list of custom topics into a CustomizationConfig object. This object is then included in a new MemoryBankConfig. This tells our Agent Engine to use our specific topics for memory extraction instead of the defaults.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3pTurO9T8ld"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    \"üß† Creating customization configuration and Memory Bank config with customization...\\n\"\n",
        ")\n",
        "\n",
        "# Create customization configuration\n",
        "customization_config = CustomizationConfig(memory_topics=custom_topics)\n",
        "\n",
        "# Create Memory Bank config with customization\n",
        "custom_memory_config = MemoryBankConfig(\n",
        "    similarity_search_config=SimilaritySearchConfig(\n",
        "        embedding_model=f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/text-embedding-005\"\n",
        "    ),\n",
        "    generation_config=GenerationConfig(\n",
        "        model=f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/gemini-2.5-flash\"\n",
        "    ),\n",
        "    # NEW: Add customization\n",
        "    customization_configs=[customization_config],\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Customization configuration created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT5EE9yJVEJn"
      },
      "source": [
        "##### Create new agent engine with custom configuration\n",
        "\n",
        "To see the effects of our new configuration clearly, we'll create a brand new `AgentEngine`. This ensures that its memory generation process is governed only by our new custom topics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-vcczayUcVq"
      },
      "outputs": [],
      "source": [
        "print(\"üõ†Ô∏è Creating new agent engine with custom configuration...\\n\")\n",
        "\n",
        "# Create new agent engine with custom configuration\n",
        "custom_agent_engine = client.agent_engines.create(\n",
        "    config={\"context_spec\": {\"memory_bank_config\": custom_memory_config}}\n",
        ")\n",
        "\n",
        "custom_engine_name = custom_agent_engine.api_resource.name\n",
        "print(\"‚úÖ Agent Engine created with custom topics!\")\n",
        "print(\"   Custom topics: purchase_history, size_information, shopping_behavior\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdqyH4zjY7xy"
      },
      "source": [
        "##### Check Memories change with Custom Topics\n",
        "\n",
        "Before we created custom topics, Memory Bank used default managed topics. Now with custom topics, let's generate memories from the same conversation and see the difference\\!\n",
        "\n",
        "We need a new session associated with our new, custom-configured Agent Engine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-vG_oVGfKAS"
      },
      "outputs": [],
      "source": [
        "print(\"üí¨ Creating session for custom engine...\")\n",
        "\n",
        "# Create session for custom engine\n",
        "custom_session = client.agent_engines.sessions.create(\n",
        "    name=custom_engine_name,\n",
        "    user_id=user_id,\n",
        "    config={\"display_name\": f\"Custom topics session for {user_id}\"},\n",
        ")\n",
        "print(f\"‚úÖ Session created: {custom_session.response.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IONuN5xDeDTp"
      },
      "source": [
        "We'll add the exact same conversation from the beginning of the tutorial to this new session. This allows for a direct, \"apples-to-apples\" comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hy3ckzDfNE4"
      },
      "outputs": [],
      "source": [
        "print(\"‚¨ÜÔ∏è Adding conversation to session...\")\n",
        "\n",
        "full_conversation = simple_conversation + additional_conversation\n",
        "\n",
        "invocation_id = 1\n",
        "\n",
        "# Add full conversation to the new session\n",
        "for turn in full_conversation:\n",
        "    client.agent_engines.sessions.events.append(\n",
        "        name=custom_session.response.name,\n",
        "        author=turn[\"role\"],\n",
        "        invocation_id=str(invocation_id),\n",
        "        timestamp=datetime.datetime.now(tz=datetime.timezone.utc),\n",
        "        config={\n",
        "            \"content\": {\"role\": turn[\"role\"], \"parts\": [{\"text\": turn[\"message\"]}]}\n",
        "        },\n",
        "    )\n",
        "    invocation_id += 1\n",
        "print(\"‚úÖ Conversation added to session!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIW8cUWYeGiD"
      },
      "source": [
        "Now, we trigger memory generation on our new engine. The underlying extraction process will now be guided by the descriptions of our custom topics (purchase_history, size_information, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdLDLsK9fOzk"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüß† Generating memories WITH custom topics...\")\n",
        "\n",
        "# Generate new memories with custom topics\n",
        "custom_operation = client.agent_engines.memories.generate(\n",
        "    name=custom_engine_name,\n",
        "    vertex_session_source={\"session\": custom_session.response.name},\n",
        "    config={\"wait_for_completion\": True},\n",
        ")\n",
        "print(\"‚úÖ Memories generated with Custom Topics!\")\n",
        "print()\n",
        "print(\n",
        "    \"**‚ö†Ô∏è Note**: It might require few minutes for the new topics to be processed. Please be patient.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCMxRxrmwhVk"
      },
      "source": [
        "Let's check memories generated with custom topics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEfJIfGKwokP"
      },
      "outputs": [],
      "source": [
        "# Return memories with custom topics\n",
        "print(\"Memories with custom topics:\")\n",
        "if custom_operation.response and custom_operation.response.generated_memories:\n",
        "    for i, gen_memory in enumerate(custom_operation.response.generated_memories, 1):\n",
        "        if gen_memory.action != \"DELETED\" and gen_memory.memory:\n",
        "            try:\n",
        "                full_memory = client.agent_engines.memories.get(\n",
        "                    name=gen_memory.memory.name\n",
        "                )\n",
        "                print(f\"   {i}. {full_memory.fact}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not retrieve memory: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufU9OGOBeJz2"
      },
      "source": [
        "By comparing the memories generated by the default engine with those from our custom-topic engine, you can see the direct impact of the customization. The new memories are more structured and aligned with our specific retail domain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuv80jCCwOkY"
      },
      "outputs": [],
      "source": [
        "print(\"üìä Check How Custom Topics Change Memory Extraction...\\n\")\n",
        "\n",
        "# Return memories with default topics\n",
        "print(\"Memories with default topics:\")\n",
        "pager = client.agent_engines.memories.list(name=agent_engine_name)\n",
        "all_memories = list(pager)\n",
        "for i, retrieved_memory in enumerate(all_memories, 1):\n",
        "    print(f\"   {i}. {retrieved_memory.fact}\")\n",
        "print()\n",
        "\n",
        "# Return memories with custom topics\n",
        "print(\"Memories with custom topics:\")\n",
        "custom_pager = client.agent_engines.memories.list(name=custom_engine_name)\n",
        "custom_memories = []\n",
        "for page in custom_pager:\n",
        "    custom_memories.append(page)\n",
        "for i, retrieved_memory in enumerate(custom_memories, 1):\n",
        "    print(f\"   {i}. {retrieved_memory.fact}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_YjbxR5gfLT"
      },
      "source": [
        "### Add Few-Shot Examples for Better Extraction\n",
        "\n",
        "Few-shot examples help Memory Bank understand exactly how to extract memories for your custom topics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "movgq_TNg8DK"
      },
      "source": [
        "#### Create few-shot examples\n",
        "\n",
        "When using custom topics, you should **always** provide few-shot examples. These examples demonstrate the desired extraction behavior to the model. You provide a sample conversation and the exact memory fact you expect to be generated, which helps the model learn the nuances of your domain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26Viw3F-g8wI"
      },
      "outputs": [],
      "source": [
        "print(\"üé® Defining few-shot examples...\\n\")\n",
        "\n",
        "few_shot_examples = [\n",
        "    GenerateMemoriesExample(\n",
        "        conversation_source=ConversationSource(\n",
        "            events=[\n",
        "                ConversationSourceEvent(\n",
        "                    content=Content(\n",
        "                        role=\"user\",\n",
        "                        parts=[\n",
        "                            Part(\n",
        "                                text=\"I bought a blue denim jacket last month for $89 and love it!\"\n",
        "                            )\n",
        "                        ],\n",
        "                    )\n",
        "                ),\n",
        "                ConversationSourceEvent(\n",
        "                    content=Content(\n",
        "                        role=\"model\",\n",
        "                        parts=[\n",
        "                            Part(\n",
        "                                text=\"Great to hear you're enjoying your denim jacket!\"\n",
        "                            )\n",
        "                        ],\n",
        "                    )\n",
        "                ),\n",
        "            ]\n",
        "        ),\n",
        "        generated_memories=[\n",
        "            ExampleGeneratedMemory(\n",
        "                fact=\"Customer purchased a blue denim jacket for $89 last month and is satisfied with it\"\n",
        "            )\n",
        "        ],\n",
        "    ),\n",
        "    GenerateMemoriesExample(\n",
        "        conversation_source=ConversationSource(\n",
        "            events=[\n",
        "                ConversationSourceEvent(\n",
        "                    content=Content(\n",
        "                        role=\"user\",\n",
        "                        parts=[\n",
        "                            Part(\n",
        "                                text=\"I wear size L in shirts but size M in jackets because I like a fitted look\"\n",
        "                            )\n",
        "                        ],\n",
        "                    )\n",
        "                )\n",
        "            ]\n",
        "        ),\n",
        "        generated_memories=[\n",
        "            ExampleGeneratedMemory(\n",
        "                fact=\"Customer wears size L in shirts and size M in jackets, prefers fitted look for jackets\"\n",
        "            )\n",
        "        ],\n",
        "    ),\n",
        "]\n",
        "\n",
        "print(\"‚úÖ Few-shot examples defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0qFaFMihI0R"
      },
      "source": [
        "#### Create customization with few-shot examples\n",
        "\n",
        "Now we add our list of few-shot examples to the CustomizationConfig object, alongside our custom topics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKD1VI_chFCE"
      },
      "outputs": [],
      "source": [
        "print(\"‚öôÔ∏è Creating customization with few-shot examples...\\n\")\n",
        "\n",
        "# Add examples to configuration\n",
        "advanced_customization = CustomizationConfig(\n",
        "    memory_topics=custom_topics,\n",
        "    generate_memories_examples=few_shot_examples,  # NEW: Add examples\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Customization created with few-shot examples!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e5i3c1eieJO"
      },
      "source": [
        "#### Update the agent engine memory configuration with few-shot examples\n",
        "\n",
        "We're now creating our most advanced memory configuration. It includes the base model settings, our custom topics, and the new few-shot examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l2AL5bdizKM"
      },
      "outputs": [],
      "source": [
        "print(\"üß† Updating the agent engine with few-shot examples...\\n\")\n",
        "\n",
        "# Update the agent engine memory bank config\n",
        "advanced_memory_config = MemoryBankConfig(\n",
        "    similarity_search_config=SimilaritySearchConfig(\n",
        "        embedding_model=f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/text-embedding-005\"\n",
        "    ),\n",
        "    generation_config=GenerationConfig(\n",
        "        model=f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/gemini-2.5-flash\"\n",
        "    ),\n",
        "    customization_configs=[advanced_customization],\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Customization added to engine configuration!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYfg7bIoi_5s"
      },
      "source": [
        "#### Update the existing engine with the new memory configuration\n",
        "\n",
        "Instead of creating a new engine, this time we'll use the update method. This allows us to apply a new configuration to an existing engine *without* losing any of the memories already stored within it. This is how you would evolve your agent's memory capabilities in a production environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KPTYYwfghGh"
      },
      "outputs": [],
      "source": [
        "# Update existing engine\n",
        "updated_engine = client.agent_engines.update(\n",
        "    name=custom_engine_name,\n",
        "    config={\"context_spec\": {\"memory_bank_config\": advanced_memory_config}},\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Agent Engine updated with few-shot examples!\")\n",
        "print(\"   Memory Bank now better understands your domain-specific patterns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HejpbgpjjVMm"
      },
      "source": [
        "#### Check Memories change with Few-shot Examples\n",
        "\n",
        "To test the impact of our few-shot examples, we create another new session on the *updated* engine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIK6DuG2jdbN"
      },
      "outputs": [],
      "source": [
        "# Create a new session to test few-shot impact\n",
        "\n",
        "print(\"üõ†Ô∏è Creating new session for few-shot engine...\")\n",
        "fewshot_session = client.agent_engines.sessions.create(\n",
        "    name=custom_engine_name,  # Using the updated engine with few-shot examples\n",
        "    user_id=user_id,\n",
        "    config={\"display_name\": f\"Few-shot test session for {user_id}\"},\n",
        ")\n",
        "print(f\"‚úÖ Session created: {fewshot_session.response.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMq2bFGeeypF"
      },
      "source": [
        "Once again, we add the same original conversation to this new session to ensure a fair test.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHMrOEpxkXaQ"
      },
      "outputs": [],
      "source": [
        "print(\"‚¨ÜÔ∏è Adding conversation to session...\")\n",
        "\n",
        "# Add original conversation to the new\n",
        "invocation_id = 1\n",
        "\n",
        "for turn in full_conversation:\n",
        "    client.agent_engines.sessions.events.append(\n",
        "        name=fewshot_session.response.name,\n",
        "        author=turn[\"role\"],\n",
        "        invocation_id=str(invocation_id),\n",
        "        timestamp=datetime.datetime.now(tz=datetime.timezone.utc),\n",
        "        config={\n",
        "            \"content\": {\"role\": turn[\"role\"], \"parts\": [{\"text\": turn[\"message\"]}]}\n",
        "        },\n",
        "    )\n",
        "    invocation_id += 1\n",
        "\n",
        "print(\"‚úÖ Conversation added to session!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOuPn_RAe1Hl"
      },
      "source": [
        "We generate memories one last time. The extraction model is now guided by our custom topics and our specific examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8_IK2PAkd68"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüß† Generating memories WITH few-shot examples...\")\n",
        "\n",
        "# Generate memories with few-shot configuration\n",
        "fewshot_operation = client.agent_engines.memories.generate(\n",
        "    name=custom_engine_name,\n",
        "    vertex_session_source={\"session\": fewshot_session.response.name},\n",
        "    config={\"wait_for_completion\": True},\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Memories Generated with Few-Shot Examples:\\n\")\n",
        "print(\n",
        "    \"‚ö†Ô∏è Note: It might require few minutes for the new topics to be processed. Please be patient.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX_tXSz_e4mv"
      },
      "source": [
        "Comparing the initial memories to this final set demonstrates the power of few-shot examples. The extracted facts are now much more precise, granular, and useful for our retail agent, showing that the model has learned the specific patterns we demonstrated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abjE5QmYyeXq"
      },
      "outputs": [],
      "source": [
        "print(\"üìä Check How Few-shot Examples Change Memory Extraction...\")\n",
        "\n",
        "# Return memories with default topics\n",
        "print(\"Memories without few-shot examples:\")\n",
        "pager = client.agent_engines.memories.list(name=agent_engine_name)\n",
        "all_memories = list(pager)\n",
        "for i, retrieved_memory in enumerate(all_memories, 1):\n",
        "    print(f\"   {i}. {retrieved_memory.fact}\")\n",
        "print()\n",
        "\n",
        "# Return memories with custom topics\n",
        "print(\"Memories with custom topics and few-shot examples:\")\n",
        "custom_pager = client.agent_engines.memories.list(name=custom_engine_name)\n",
        "custom_memories = []\n",
        "for page in custom_pager:\n",
        "    custom_memories.append(page)\n",
        "for i, retrieved_memory in enumerate(custom_memories, 1):\n",
        "    print(f\"   {i}. {retrieved_memory.fact}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y24YjNaDm4OT"
      },
      "source": [
        "### Time-To-Live (TTL) & Memory Management\n",
        "\n",
        "Managing data responsibly is crucial. Memory Bank provides Time-To-Live (TTL) settings to automatically expire and delete memories after their expiration time elapses. This is essential for privacy regulations (like GDPR), data hygiene, and cost management."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1IQ484-nn-5"
      },
      "source": [
        "#### Add TTL for compliance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjuVecoUnevi"
      },
      "source": [
        "##### Define TTL configuration\n",
        "\n",
        " Here, we define a granular_ttl_config to set different retention periods for memories based on how they were created or updated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZEGPhDundTs"
      },
      "outputs": [],
      "source": [
        "print(\"‚è±Ô∏è Define TTL configuration...\")\n",
        "\n",
        "# Define granular TTL for different operations\n",
        "ttl_config = TtlConfig(\n",
        "    granular_ttl_config=GranularTtlConfig(\n",
        "        create_ttl=\"2592000s\",  # 30 days for manually created memories\n",
        "        generate_created_ttl=\"7776000s\",  # 90 days for generated memories\n",
        "        generate_updated_ttl=\"7776000s\",  # 90 days for updated memories\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"‚úÖ TTL configuration defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eqj_8uPoKQH"
      },
      "source": [
        "##### Update the agent engine memory configuration with TTL configuration\n",
        "\n",
        "We now create our final configuration object, which includes our advanced customization (topics and examples) and the new TTL settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kja6DNghoKs4"
      },
      "outputs": [],
      "source": [
        "print(\"üß† Updating the agent engine with TTL configuration...\")\n",
        "\n",
        "advanced_memory_config = MemoryBankConfig(\n",
        "    # Basic configuration\n",
        "    similarity_search_config=SimilaritySearchConfig(\n",
        "        embedding_model=f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/text-embedding-005\"\n",
        "    ),\n",
        "    generation_config=GenerationConfig(\n",
        "        model=f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/gemini-2.5-flash\"\n",
        "    ),\n",
        "    # Customization\n",
        "    customization_configs=[advanced_customization],\n",
        "    # NEW: TTL configuration\n",
        "    ttl_config=ttl_config,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ TTL configuration added to engine configuration!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37uzMRnBnaAc"
      },
      "source": [
        "##### Update the existing Agent Engine with TTL configuration\n",
        "\n",
        "We use the update method one last time to apply our TTL policy to the Agent Engine. From this point forward, any new or updated memories in this engine will automatically have an expiration time set according to these rules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1riENFDynTLb"
      },
      "outputs": [],
      "source": [
        "print(\"üõ†Ô∏è Updating the agent engine with TTL configuration...\\n\")\n",
        "\n",
        "updated_engine = client.agent_engines.update(\n",
        "    name=custom_engine_name,\n",
        "    config={\"context_spec\": {\"memory_bank_config\": advanced_memory_config}},\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Agent Engine updated with TTL configuration!\")\n",
        "print(\"   Memory Bank now will retain memories for a limited time\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YM4UQyupyVX"
      },
      "source": [
        "##### (Optional) Create memories with specific TTL\n",
        "\n",
        "In addition to engine-level TTL policies, you can specify a per-memory TTL when you create it manually using memories.create. This overrides the engine's default. This is useful for short-lived data, like the contents of a shopping cart, which you might only want to remember for 7 days for a cart recovery campaign.\n",
        "\n",
        "> Note: The `create` method has limited features. It does not perform memory consolidation and it might generate duplicate memories. For production applications, we recommend to [use `generate` method](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/memory-bank/generate-memories#consolidate-pre-extracted-memories) with pre-extracted memories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5odIjx5drrxP"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüìù Creating memories with TTL...\\n\")\n",
        "\n",
        "# Create a memory that will expire\n",
        "temporary_memory = client.agent_engines.memories.create(\n",
        "    name=custom_engine_name,\n",
        "    fact=\"Customer has items in cart: 2 jackets worth $350\",\n",
        "    scope={\"user_id\": user_id},\n",
        "    config={\"ttl\": \"604800s\"},  # 7 days - for cart recovery\n",
        ")\n",
        "print(\"‚úÖ Created temporary memory (7-day TTL):\")\n",
        "print(\"   Customer has items in cart: 2 jackets worth $350\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upi9-lg2hKr6"
      },
      "source": [
        "Here's another example of manual creation, this time for a long-term fact like a customer's VIP status, which we want to retain for a full year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9Dojwwgpw5j"
      },
      "outputs": [],
      "source": [
        "# Create a longer-term memory\n",
        "permanent_memory = client.agent_engines.memories.create(\n",
        "    name=custom_engine_name,\n",
        "    fact=\"Customer is a VIP member since 2024\",\n",
        "    scope={\"user_id\": user_id},\n",
        "    config={\"ttl\": \"31536000s\"},  # 1 year - for loyalty\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Created long-term memory (1-year TTL):\")\n",
        "print(\"     Customer is a VIP member since 2024\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA_5Eiw6skOs"
      },
      "source": [
        "#### Memory Management Operations\n",
        "\n",
        "Let's explore memory management: updating, listing, and deleting memories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B75gKMHcs5o1"
      },
      "source": [
        "##### List memories\n",
        "\n",
        "The list method allows you to fetch all memories stored within a Memory Bank instance. It returns a pager object, which you can iterate through to handle large numbers of memories efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tz6eKzsRsvz0"
      },
      "outputs": [],
      "source": [
        "# List memories using pager\n",
        "pager = client.agent_engines.memories.list(name=custom_engine_name)\n",
        "all_memories = list(pager)\n",
        "\n",
        "print(f\"Total memories in Memory Bank: {len(all_memories)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31xWB1mTuslI"
      },
      "source": [
        "##### Get a specific memory\n",
        "\n",
        "If you know the full resource name of a memory, you can fetch its complete content directly using the get method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxFr4iOSutXM"
      },
      "outputs": [],
      "source": [
        "if temporary_memory:\n",
        "    retrieved_memory = client.agent_engines.memories.get(\n",
        "        name=temporary_memory.response.name\n",
        "    )\n",
        "    print(f\"   Memory Resource Name: {retrieved_memory.name}\")\n",
        "    print(f\"   Memory created in: {retrieved_memory.create_time}\")\n",
        "    print(f\"   Memory updated in: {retrieved_memory.update_time}\")\n",
        "    print(f\"   Memory expires in: {retrieved_memory.expire_time}\")\n",
        "    print(f\"   Retrieved specific memory: {retrieved_memory.fact}\")\n",
        "    print(f\"   Scope: {retrieved_memory.scope}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqAmJo2Bu_Ob"
      },
      "source": [
        "##### (Optional) Delete a memory\n",
        "\n",
        "Finally, you can permanently delete a specific memory by its resource name using the delete method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3GoQEhivAvE"
      },
      "outputs": [],
      "source": [
        "client.agent_engines.memories.delete(name=temporary_memory.response.name)\n",
        "print(\"Memory deleted!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a4e033321ad"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "It's always a best practice in cloud development to clean up resources you no longer need to avoid incurring unexpected costs. This final cell deletes the AgentEngine resources we created throughout this tutorial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BLXB-iRvQ3Q"
      },
      "outputs": [],
      "source": [
        "delete_agent_engines = True\n",
        "\n",
        "if delete_agent_engines:\n",
        "    # Delete agent engines\n",
        "    client.agent_engines.delete(name=agent_engine_name, force=True)\n",
        "    client.agent_engines.delete(name=custom_engine_name, force=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "get_started_with_memory_bank.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
