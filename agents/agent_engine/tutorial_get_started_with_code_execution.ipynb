{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Get started with Code Execution on Vertex AI Agent Engine\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/tutorial_get_started_with_code_execution.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fagents%2Fagent_engine%2Ftutorial_get_started_with_code_execution.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/agents/agent_engine/tutorial_get_started_with_code_execution.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/tutorial_get_started_with_code_execution.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/tutorial_get_started_with_code_execution.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/tutorial_get_started_with_code_execution.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/tutorial_get_started_with_code_execution.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/tutorial_get_started_with_code_execution.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/tutorial_get_started_with_code_execution.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| Authors |\n",
        "| --- |\n",
        "| Shaoxiong Zhang |\n",
        "| [Ivan Nardini](https://github.com/inardini) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook is your comprehensive guide to the **Code Execution** feature on Vertex AI Agent Engine. We'll show you how to give your AI agents the ability to run code in a secure, managed environment, transforming them from simple conversationalists into capable problem-solvers.\n",
        "\n",
        "In this tutorial, you'll learn how to:\n",
        "\n",
        "* Create and manage a secure **Agent Engine Sandbox** for code execution.  \n",
        "* Execute Python code **directly** using the Vertex AI SDK.  \n",
        "* Integrate the sandbox with Large Language Models like **Gemini** and **Claude** for dynamic code generation and execution.  \n",
        "* Build robust, stateful agents with the **Agent Development Kit (ADK)** that leverage the sandbox as a first-class tool.  \n",
        "* Manage the lifecycle of your sandboxes, from creation to cleanup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi4w1JV5GQix"
      },
      "source": [
        "### What is Agent Engine Sandbox?\n",
        "\n",
        "**Agent Engine Sandbox** is Google's managed service for securely executing code generated by AI models. Think of it as a secure, isolated environment where your AI agents can run Python or JavaScript code without any risk to your underlying infrastructure. It's stateful, fast, and framework-agnostic, meaning you can integrate it with any agent framework and any LLM.\n",
        "\n",
        "### Why Use Agent Engine Sandbox?\n",
        "\n",
        "Key Benefits:\n",
        "\n",
        "1. Security: Code runs in an isolated sandbox, preventing interference with your host system's resources, files, or network.\n",
        "2. Scalability: Designed to handle production workloads with low latency for sandbox creation and execution.\n",
        "3. Model-agnostic: Works with any LLM, not just Gemini.\n",
        "4. Managed: No infrastructure to maintain. Google handles the environment, letting you focus on building great agents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started\n",
        "\n",
        "Let's begin by setting up our environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Google Gen AI SDK and other required packages\n",
        "\n",
        "Install the necessary Python libraries:\n",
        "\n",
        "* **Vertex AI SDK:** To interact with Google Cloud's AI services, including the new Agent Engine.  \n",
        "* **Anthropic SDK:** To use Claude models on Vertex AI.  \n",
        "* **Google ADK:** The Agent Development Kit for building structured and powerful agents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet --force-reinstall \"google-cloud-aiplatform>=1.112.0\" anthropic google-adk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, the next cell will authenticate you with your Google account, allowing the notebook to access Google Cloud services on your behalf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To use Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Configure the notebook to use your specific project and chosen region.\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "# Use the environment variable if the user doesn't provide Project ID.\n",
        "import os\n",
        "\n",
        "import vertexai\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "# ADK env variables\n",
        "GOOGLE_GENAI_USE_VERTEXAI = 1\n",
        "\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = LOCATION\n",
        "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = str(GOOGLE_GENAI_USE_VERTEXAI)\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "client = vertexai.Client(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5303c05f7aa6"
      },
      "source": [
        "### Import libraries\n",
        "\n",
        "Import all the necessary classes and types from the installed SDKs that we'll use throughout the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fc324893334"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from vertexai import types\n",
        "from vertexai.generative_models import (\n",
        "    Content,\n",
        "    FunctionDeclaration,\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    Part,\n",
        "    Tool,\n",
        ")\n",
        "from anthropic import AnthropicVertex\n",
        "import re\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import logging\n",
        "\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.artifacts import InMemoryArtifactService\n",
        "from google.adk.code_executors import BuiltInCodeExecutor\n",
        "from google.adk.events import Event\n",
        "from google.adk.memory import InMemoryMemoryService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.tools import FunctionTool, ToolContext\n",
        "from google.genai import types as genai_types\n",
        "from pydantic import BaseModel, Field"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyMI-T-9Biga"
      },
      "source": [
        "### Helpers\n",
        "\n",
        "To make the output of our agent interactions easier to read, we'll use this helper function. It parses the event stream from the ADK Runner and prints the important parts—like tool calls, code execution steps, and final responses—in a clear, structured way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YR2_pxrjBkjF"
      },
      "outputs": [],
      "source": [
        "def parse_event(event: Event):\n",
        "    \"\"\"Parse agent events to highlight function calls and code execution.\"\"\"\n",
        "    if event.content and event.content.parts:\n",
        "        for part in event.content.parts:\n",
        "            # Check for function call (agent using tool)\n",
        "            if hasattr(part, \"function_call\") and part.function_call:\n",
        "                print(f\"\\nTOOL CALL: {part.function_call.name}\")\n",
        "                if \"code\" in part.function_call.args:\n",
        "                    print(\"Code to execute:\")\n",
        "                    print(part.function_call.args[\"code\"].strip())\n",
        "\n",
        "            # Check for function response (tool result)\n",
        "            elif hasattr(part, \"function_response\") and part.function_response:\n",
        "                resp = part.function_response.response\n",
        "                if isinstance(resp, dict) and resp.get(\"status\") == \"success\":\n",
        "                    print(\"\\nEXECUTION RESULT:\")\n",
        "                    print(resp.get(\"output\", \"\").strip())\n",
        "\n",
        "            # Check for Code Interpreter Extension executable code\n",
        "            elif hasattr(part, \"executable_code\") and part.executable_code:\n",
        "                print(\"\\nCODE INTERPRETER EXECUTION:\")\n",
        "                print(f\"Language: {part.executable_code.language}\")\n",
        "                print(\"Code:\")\n",
        "                print(part.executable_code.code.strip())\n",
        "\n",
        "            # Check for Code Interpreter Extension execution result\n",
        "            elif hasattr(part, \"code_execution_result\") and part.code_execution_result:\n",
        "                print(\"\\nCODE INTERPRETER RESULT:\")\n",
        "                print(f\"Status: {part.code_execution_result.outcome}\")\n",
        "                if part.code_execution_result.output:\n",
        "                    print(\"Output:\")\n",
        "                    print(part.code_execution_result.output.strip())\n",
        "                if (\n",
        "                    hasattr(part.code_execution_result, \"error\")\n",
        "                    and part.code_execution_result.error\n",
        "                ):\n",
        "                    print(f\"Error: {part.code_execution_result.error}\")\n",
        "\n",
        "            # Check for text responses (explanatory text or final response)\n",
        "            elif hasattr(part, \"text\") and part.text:\n",
        "                # For final responses, show with special formatting\n",
        "                if event.is_final_response():\n",
        "                    print(\"\\nAGENT RESPONSE:\")\n",
        "                    print(part.text.strip())\n",
        "                # For intermediate text (explanations before code)\n",
        "                elif len(part.text.strip()) > 0:\n",
        "                    print(\"\\nEXPLANATION:\")\n",
        "                    print(part.text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDm0an9O8dfN"
      },
      "source": [
        "## Your First Code Execution\n",
        "\n",
        "Let's start with the simplest possible example \\- executing code directly in an Agent Engine Sandbox.\n",
        "\n",
        "First, we need to create an AgentEngine resource. This acts as a top-level container for your sandboxes and other agent-related resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS-m5UVd8l4V"
      },
      "outputs": [],
      "source": [
        "# Create a sandbox environment\n",
        "agent_engine = client.agent_engines.create()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nf0b5n8HXci"
      },
      "source": [
        "Now, within that engine, we'll create our first sandbox. You initialize a secure, isolated runtime environment ready to execute code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSnSo_fB9GaL"
      },
      "outputs": [],
      "source": [
        "sandbox_operation = client.agent_engines.sandboxes.create(\n",
        "    name=agent_engine.api_resource.name,\n",
        "    config=types.CreateAgentEngineSandboxConfig(display_name=\"my_first_sandbox\"),\n",
        "    spec={\"code_execution_environment\": {}},\n",
        ")\n",
        "\n",
        "sandbox_resource_name = sandbox_operation.response.name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHJzqS0UHb8-"
      },
      "source": [
        "With the sandbox created, we can now send a string of Python code to it for execution. The sandbox runs the code and captures any output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8q-cnZm8uA4"
      },
      "outputs": [],
      "source": [
        "# Execute simple Python code\n",
        "response = client.agent_engines.sandboxes.execute_code(\n",
        "    name=sandbox_resource_name,\n",
        "    input_data={\n",
        "        \"code\": \"import math\\nprint(f'Square root of 15376: {math.sqrt(15376)}')\"\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3HtiPkIHfRo"
      },
      "source": [
        "The response from the sandbox is a JSON object encoded in bytes. We need to decode it to see the standard output (msg_out) from our executed code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ILv6TxV8vQV"
      },
      "outputs": [],
      "source": [
        "# Parse and display result\n",
        "result = json.loads(response.outputs[0].data.decode(\"utf-8\"))\n",
        "print(result.get(\"msg_out\"))  # Output: Square root of 15376: 124.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5kFG3VP-orn"
      },
      "source": [
        "**What just happened?**\n",
        "\n",
        "With this code:\n",
        "\n",
        "1. We created a secure sandbox environment.  \n",
        "2. We sent a string of Python code to be executed.  \n",
        "3. We received the standard output back safely.\n",
        "\n",
        "This direct execution is the fundamental capability. Now, let's see how to make it can be integrated with LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5rFVnl9-qZv"
      },
      "source": [
        "## Integration with LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMnRiIyITJSj"
      },
      "source": [
        "### Create a sandbox with customized configs\n",
        "\n",
        "Agent Engine allows you to customize the sandbox environment. You can specify the programming language (Python or JavaScript) and the machine configuration (vCPUs and RAM) to fit your task's needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VED9E8FrTfYm"
      },
      "outputs": [],
      "source": [
        "language_config = \"LANGUAGE_PYTHON\"  # @param [\"LANGUAGE_UNSPECIFIED\", \"LANGUAGE_PYTHON\", \"LANGUAGE_JAVASCRIPT\"] {type:\"string\"}\n",
        "machine_config = \"MACHINE_CONFIG_VCPU4_RAM4GIB\"  # @param [\"MACHINE_CONFIG_UNSPECIFIED\", \"MACHINE_CONFIG_VCPU4_RAM4GIB\"] {type:\"string\"}\n",
        "\n",
        "sandbox_operation = client.agent_engines.sandboxes.create(\n",
        "    name=agent_engine.api_resource.name,\n",
        "    config=types.CreateAgentEngineSandboxConfig(display_name=\"my_custom_sandbox\"),\n",
        "    spec={\n",
        "        \"code_execution_environment\": {\n",
        "            \"code_language\": language_config,\n",
        "            \"machine_config\": machine_config,\n",
        "        }\n",
        "    },\n",
        ")\n",
        "\n",
        "sandbox_resource_name = sandbox_operation.response.name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CH5hE85IlAO"
      },
      "source": [
        "### Use Code Execution with Gemini\n",
        "\n",
        "Let's start using Code Execution with Gemini."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nND59-MX-uSu"
      },
      "source": [
        "#### Gemini Integration - Direct Approach\n",
        "\n",
        "The most straightforward way to use the sandbox with an LLM is a two-step process: first, ask the LLM to generate code, and second, execute that code in the sandbox.\n",
        "\n",
        "Here, we ask Gemini to write Python code to perform a statistical calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "latRErZ2-1zL"
      },
      "outputs": [],
      "source": [
        "# Initialize Gemini model\n",
        "model = GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "# Ask Gemini to generate code for a calculation\n",
        "prompt = \"\"\"\n",
        "Write Python code to calculate the mean and standard deviation of these numbers:\n",
        "[23, 45, 67, 89, 12, 34, 56]\n",
        "\n",
        "Return only the Python code, no explanations.\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "generated_code = response.text.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "print(\"Gemini generated code:\")\n",
        "print(generated_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbkXs2eWH_sd"
      },
      "source": [
        "Now, we take the code string generated by Gemini and execute it in the sandbox we created earlier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wf-q_1Dx-9j4"
      },
      "outputs": [],
      "source": [
        "# Execute the generated code in Agent Engine Sandbox\n",
        "exec_response = client.agent_engines.sandboxes.execute_code(\n",
        "    name=sandbox_resource_name,  # Reuse sandbox from Part 1\n",
        "    input_data={\"code\": generated_code},\n",
        ")\n",
        "\n",
        "result = json.loads(exec_response.outputs[0].data.decode(\"utf-8\"))\n",
        "print(f\"\\nExecution result:\\n{result.get('msg_out')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu1vkEqbAX97"
      },
      "source": [
        "#### Gemini with Tool Calling\n",
        "\n",
        "A more robust and integrated approach is to expose the Agent Engine Sandbox to Gemini as a **tool**. This allows the model to decide *when* and *how* to execute code to answer a user's query, which is the foundation of building AI agents.\n",
        "\n",
        "First, we define a Python function that wraps the sandbox execute_code call. The docstring is critical here, as it's the primary way the LLM understands what the tool does and what its parameters are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV9lAMnoAgic"
      },
      "outputs": [],
      "source": [
        "# Define the code execution as a function for Gemini\n",
        "def execute_python_code(code: str) -> str:\n",
        "    \"\"\"Execute Python code in a secure sandbox.\n",
        "\n",
        "    Args:\n",
        "        code: Python code to execute\n",
        "    Returns:\n",
        "        The output from code execution\n",
        "    \"\"\"\n",
        "    # Extract code block if wrapped in markdown\n",
        "    code_match = re.search(r\"```python\\n(.*?)\\n```\", code, re.DOTALL)\n",
        "    if code_match:\n",
        "        code_to_execute = code_match.group(1)\n",
        "    else:\n",
        "        code_to_execute = code\n",
        "\n",
        "    response = client.agent_engines.sandboxes.execute_code(\n",
        "        name=sandbox_resource_name, input_data={\"code\": code_to_execute}\n",
        "    )\n",
        "    result = json.loads(response.outputs[0].data.decode(\"utf-8\"))\n",
        "\n",
        "    if result.get(\"msg_err\"):\n",
        "        return f\"Error: {result.get('msg_err')}\"\n",
        "    return result.get(\"msg_out\", \"Code executed successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6rQCRCzIJkK"
      },
      "source": [
        "Next, we declare this function as a Tool that the Gemini model can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTJOdwF0A2Vg"
      },
      "outputs": [],
      "source": [
        "# Create a tool from the function\n",
        "code_tool = Tool(\n",
        "    function_declarations=[FunctionDeclaration.from_func(execute_python_code)]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAtAXWEnILNp"
      },
      "source": [
        "Now, we send a prompt to Gemini and provide it with our new code_tool. The model analyzes the prompt and determines that it needs to call our tool to get the answer. It returns a function_call request.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_SvLbFtDfiX"
      },
      "outputs": [],
      "source": [
        "# Send a request that will trigger tool use\n",
        "response = model.generate_content(\n",
        "    contents=[\n",
        "        Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                Part.from_text(\n",
        "                    \"Calculate the factorial of 10 and check if it's divisible by 100\"\n",
        "                ),\n",
        "            ],\n",
        "        )\n",
        "    ],\n",
        "    generation_config=GenerationConfig(temperature=0),\n",
        "    tools=[code_tool],\n",
        ")\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZPpNqmZIP2A"
      },
      "source": [
        "This is the second turn of the conversation. We execute the code that Gemini requested in our sandbox and send the result back to the model as a function_response. The model then uses this result to formulate a final, natural language answer for the user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp3Cher_CsBd"
      },
      "outputs": [],
      "source": [
        "# Process the function call\n",
        "function_response_parts = []\n",
        "\n",
        "for function_call in response.candidates[0].function_calls:\n",
        "    print(f\"Function call: {function_call.name}\")\n",
        "    print(f\"Generated code: {function_call.args['code']}\")\n",
        "\n",
        "    # Execute the code in Agent Engine Sandbox\n",
        "    exec_response = client.agent_engines.sandboxes.execute_code(\n",
        "        name=sandbox_resource_name, input_data={\"code\": function_call.args[\"code\"]}\n",
        "    )\n",
        "\n",
        "    result = json.loads(exec_response.outputs[0].data.decode(\"utf-8\"))\n",
        "\n",
        "    # Prepare the function response\n",
        "    execution_output = result.get(\"msg_out\", \"\")\n",
        "    if result.get(\"msg_err\"):\n",
        "        execution_output = f\"Error: {result.get('msg_err')}\"\n",
        "\n",
        "    function_response_parts.append(\n",
        "        Part.from_function_response(\n",
        "            name=function_call.name, response={\"result\": execution_output}\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Send the function response back to the model\n",
        "function_response_content = Content(role=\"function\", parts=function_response_parts)\n",
        "\n",
        "# Get the final response\n",
        "final_response = model.generate_content(\n",
        "    [\n",
        "        Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                Part.from_text(\n",
        "                    \"Calculate the factorial of 10 and check if it's divisible by 100\"\n",
        "                )\n",
        "            ],\n",
        "        ),\n",
        "        response.candidates[0].content,  # Original function call\n",
        "        function_response_content,  # Function execution results\n",
        "    ],\n",
        "    tools=[code_tool],\n",
        ")\n",
        "\n",
        "print(\"\\nGemini's final response:\")\n",
        "print(final_response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kOgU2g2EBz5"
      },
      "source": [
        "### Use Code Execution with other models\n",
        "\n",
        "Because the **Agent Engine Sandbox is model-agnostic**, you can use it with other LLMs available on Vertex AI, like Anthropic's Claude."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsR6rafWE9CL"
      },
      "source": [
        "#### Claude - Direct Approach\n",
        "\n",
        "The direct, two-step approach works seamlessly with Claude. First, we initialize the Claude client on Vertex AI.\n",
        "\n",
        "Note that Claude model availability varies by region.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGmiuaYXFDf_"
      },
      "outputs": [],
      "source": [
        "# Initialize Claude on Vertex\n",
        "claude = AnthropicVertex(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=\"us-east5\",  # Claude availability varies by region\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m3Z_uCvJE_f"
      },
      "source": [
        "Now, we ask Claude to generate Python code to perform a more complex task: calculating prime numbers and creating a data visualization with matplotlib.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eF6Cj79-Gb3s"
      },
      "outputs": [],
      "source": [
        "# Ask Claude to generate code\n",
        "message = claude.messages.create(\n",
        "    model=\"claude-sonnet-4@20250514\",\n",
        "    max_tokens=1000,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"Generate Python code to:\n",
        "        1. Create a list of the first 10 prime numbers\n",
        "        2. Calculate their sum and average\n",
        "        3. Create a simple bar chart showing each prime number\n",
        "\n",
        "        Use matplotlib for the chart. Save the chart as 'primes_chart.png'.\n",
        "        Return only the Python code.\"\"\",\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Extract code from Claude's response\n",
        "claude_response = message.content[0].text\n",
        "\n",
        "# Extract code block if wrapped in markdown\n",
        "code_match = re.search(r\"```python\\n(.*?)\\n```\", claude_response, re.DOTALL)\n",
        "if code_match:\n",
        "    code_to_execute = code_match.group(1)\n",
        "else:\n",
        "    code_to_execute = claude_response\n",
        "\n",
        "print(\"Claude generated code:\")\n",
        "print(code_to_execute)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4sICOX0JIuI"
      },
      "source": [
        "We execute the code generated by Claude. The sandbox handles the matplotlib library and file I/O, generating the chart image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHzZYBAKENl1"
      },
      "outputs": [],
      "source": [
        "# Execute in Agent Engine Sandbox\n",
        "exec_response = client.agent_engines.sandboxes.execute_code(\n",
        "    name=sandbox_resource_name, input_data={\"code\": code_to_execute}\n",
        ")\n",
        "\n",
        "result = json.loads(exec_response.outputs[0].data.decode(\"utf-8\"))\n",
        "print(f\"\\nExecution result:\\n{result.get('msg_out')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIHCDOfMJWBD"
      },
      "source": [
        "The Agent Engine Sandbox can get input files and return generated files. They are included in the output_files field of the response, with their content encoded in Base64. The following code checks for any output files, decodes the content, and displays the generated chart directly in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxeJA5lrJMvJ"
      },
      "outputs": [],
      "source": [
        "# Handle generated files (like charts)\n",
        "if result.get(\"output_files\"):\n",
        "    print(f\"\\nGenerated {len(result.get('output_files'))} file(s)\")\n",
        "\n",
        "    for file_info in result.get(\"output_files\"):\n",
        "        file_name = file_info.get(\"name\")\n",
        "        print(f\"Processing: {file_name}\")\n",
        "\n",
        "        # Decode the base64 content\n",
        "        file_content_b64 = file_info.get(\"content\")\n",
        "        decoded_bytes = base64.b64decode(file_content_b64)\n",
        "\n",
        "        # If it's an image file (PNG, JPG, etc.), display it\n",
        "        if file_name.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "            print(f\"Displaying chart: {file_name}\")\n",
        "            img = plt.imread(BytesIO(decoded_bytes))\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "            ax.imshow(img)\n",
        "            ax.axis(\"off\")\n",
        "            plt.show()\n",
        "\n",
        "            # Optionally save to local file\n",
        "            with open(file_name, \"wb\") as f:\n",
        "                f.write(decoded_bytes)\n",
        "            print(f\"Saved to: {file_name}\")\n",
        "        else:\n",
        "            # For text files, display content\n",
        "            print(f\"File content:\\n{decoded_bytes.decode('utf-8')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3km4oL1iMi9g"
      },
      "source": [
        "#### Using Claude's Native Tool Support\n",
        "\n",
        "Claude on Vertex AI also supports native tool calling.We can define a tool schema that describes our code execution function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9xt1NbsMoD_"
      },
      "outputs": [],
      "source": [
        "# Define the tool schema for Claude\n",
        "code_execution_tool = {\n",
        "    \"name\": \"execute_python\",\n",
        "    \"description\": \"Execute Python code in a secure Agent Engine Sandbox\",\n",
        "    \"input_schema\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"code\": {\"type\": \"string\", \"description\": \"Python code to execute\"}\n",
        "        },\n",
        "        \"required\": [\"code\"],\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUIiRCjPJiZ-"
      },
      "source": [
        "This is the implementation of our tool. It will be called when the Claude model decides to use it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD10jRDVMqZr"
      },
      "outputs": [],
      "source": [
        "# Function to handle tool execution\n",
        "def execute_code_tool(code: str) -> str:\n",
        "    \"\"\"Execute code when Claude calls the tool.\"\"\"\n",
        "    try:\n",
        "        response = client.agent_engines.sandboxes.execute_code(\n",
        "            name=sandbox_resource_name, input_data={\"code\": code}\n",
        "        )\n",
        "        result = json.loads(response.outputs[0].data.decode(\"utf-8\"))\n",
        "\n",
        "        if result.get(\"msg_err\"):\n",
        "            return f\"Error: {result.get('msg_err')}\"\n",
        "        return result.get(\"msg_out\", \"Code executed successfully\")\n",
        "    except Exception as e:\n",
        "        return f\"Execution failed: {e!s}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RLDIoxTJkUw"
      },
      "source": [
        "Now we orchestrate the multi-turn conversation. Claude responds with a tool_use request, we execute the tool, send the result back, and Claude generates the final answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LgTuL0wM7Q0"
      },
      "outputs": [],
      "source": [
        "# Send a message with tool support\n",
        "message = claude.messages.create(\n",
        "    model=\"claude-sonnet-4@20250514\",\n",
        "    max_tokens=1000,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Calculate the 10th Fibonacci number for me.\"}\n",
        "    ],\n",
        "    tools=[code_execution_tool],\n",
        ")\n",
        "\n",
        "# Handle tool use in the response\n",
        "if message.stop_reason == \"tool_use\":\n",
        "    tool_results = []\n",
        "\n",
        "    for content in message.content:\n",
        "        if content.type == \"tool_use\":\n",
        "            print(f\"Claude wants to use tool: {content.name}\")\n",
        "            print(f\"With parameters: {content.input}\")\n",
        "\n",
        "            # Execute the tool\n",
        "            if content.name == \"execute_python\":\n",
        "                result = execute_code_tool(content.input[\"code\"])\n",
        "                print(f\"\\nExecution result: {result}\")\n",
        "\n",
        "                tool_results.append(\n",
        "                    {\n",
        "                        \"type\": \"tool_result\",\n",
        "                        \"tool_use_id\": content.id,\n",
        "                        \"content\": result,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "    # Send tool results back to Claude for final response\n",
        "    final_response = claude.messages.create(\n",
        "        model=\"claude-sonnet-4@20250514\",\n",
        "        max_tokens=1000,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": \"Calculate the 10th Fibonacci number for me.\"},\n",
        "            {\"role\": \"assistant\", \"content\": message.content},\n",
        "            {\"role\": \"user\", \"content\": tool_results},\n",
        "        ],\n",
        "        tools=[code_execution_tool],\n",
        "    )\n",
        "\n",
        "    print(f\"\\nClaude's final answer: {final_response.content[0].text}\")\n",
        "else:\n",
        "    # Claude responded without using tools\n",
        "    print(f\"Claude's response: {message.content[0].text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ltXNjy4Nglk"
      },
      "source": [
        "Note: This uses Claude's native tool support. For production MCP servers (with HTTP/SSE endpoints), you would use the `mcp_servers` parameter with the beta API as shown in the [MCP documentation](https://docs.anthropic.com/en/docs/agents-and-tools/mcp-connector#limitations)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is6_qRwXNq9q"
      },
      "source": [
        "## Building agents with ADK using the code executor tool\n",
        "\n",
        "While direct LLM integration is powerful, building complex applications requires a more structured approach.\n",
        "\n",
        "The **Agent Development Kit (ADK)** is a code-first Python toolkit for building, evaluating, and deploying sophisticated AI agents with flexibility and control. Let's build a proper ADK agent that uses our sandbox."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ElCppeUOIjW"
      },
      "source": [
        "### Creating a Custom Tool for ADK\n",
        "\n",
        "First, we wrap our sandbox API call in an ADK-compatible tool function. A key feature of ADK tools is the optional ToolContext parameter. This special object, automatically injected by ADK, gives the tool access to the current session's state, allowing it to read and write data, and even control the agent's flow. Here, we use it to save any files generated by the code as **artifacts** in the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8QA1qVWOQEY"
      },
      "outputs": [],
      "source": [
        "def execute_python_code(code: str, tool_context: ToolContext) -> dict:\n",
        "    \"\"\"Execute Python code in Agent Engine Sandbox and return the results.\n",
        "\n",
        "    Use this tool when you need to run Python code for calculations, data processing,\n",
        "    or any computational task. The code runs in an isolated, secure environment.\n",
        "\n",
        "    Args:\n",
        "        code: Valid Python code to execute. Include print statements for output visibility.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary with execution results.\n",
        "        On success: {'status': 'success', 'output': '<code output>', 'files': [<generated files>]}\n",
        "        On error: {'status': 'error', 'error_message': '<error details>'}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Access sandbox name from state or use default\n",
        "        sandbox_name = tool_context.state.get(\"sandbox_name\", sandbox_resource_name)\n",
        "\n",
        "        response = client.agent_engines.sandboxes.execute_code(\n",
        "            name=sandbox_name, input_data={\"code\": code}\n",
        "        )\n",
        "        result = json.loads(response.outputs[0].data.decode(\"utf-8\"))\n",
        "\n",
        "        if result.get(\"msg_err\"):\n",
        "            return {\"status\": \"error\", \"error_message\": result.get(\"msg_err\")}\n",
        "\n",
        "        output = result.get(\"msg_out\", \"\")\n",
        "        files = result.get(\"output_files\", [])\n",
        "\n",
        "        response_dict = {\n",
        "            \"status\": \"success\",\n",
        "            \"output\": output if output else \"Code executed successfully (no output)\",\n",
        "        }\n",
        "\n",
        "        if files:\n",
        "            response_dict[\"files\"] = [f[\"name\"] for f in files]\n",
        "            # Optionally save generated files as artifacts\n",
        "            for file_info in files:\n",
        "                if file_info.get(\"content\"):\n",
        "                    file_content = base64.b64decode(file_info[\"content\"])\n",
        "                    artifact = genai_types.Part(\n",
        "                        inline_data=types.Blob(\n",
        "                            mime_type=\"application/octet-stream\", data=file_content\n",
        "                        )\n",
        "                    )\n",
        "                    tool_context.save_artifact(file_info[\"name\"], artifact)\n",
        "\n",
        "        return response_dict\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"error_message\": \"Invalid response format from sandbox\",\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"error_message\": f\"Execution failed: {e!s}\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ImlvPgCJ8jo"
      },
      "source": [
        "Now we wrap our Python function in ADK's FunctionTool class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ymk8CcnNOWI6"
      },
      "outputs": [],
      "source": [
        "# Create the tool instance\n",
        "custom_code_executor = FunctionTool(execute_python_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0X4YGpHb-rB"
      },
      "source": [
        "### Simple agent with Code executor tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euVDw5mdOeTl"
      },
      "source": [
        "#### Creating your first ADK Agent\n",
        "\n",
        "Now let's create a simple calculation agent. The LlmAgent class is the core of ADK. We define its identity, its instruction (which tells the LLM how to behave), and the tools it has access to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6-IFrz_PX76"
      },
      "outputs": [],
      "source": [
        "# Create a calculation agent\n",
        "calc_agent = LlmAgent(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    name=\"calculator\",\n",
        "    description=\"An agent that performs complex calculations\",\n",
        "    instruction=\"\"\"You are a helpful calculation assistant. When asked to calculate:\n",
        "    1. Write clear Python code to solve the problem\n",
        "    2. Use the custom_code_executor tool to run it\n",
        "    3. Explain the results clearly\n",
        "\n",
        "    Always include print statements to show intermediate steps.\n",
        "    \"\"\",\n",
        "    tools=[custom_code_executor],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsnARKypPkU-"
      },
      "source": [
        "#### Run the agent\n",
        "\n",
        "To run an ADK agent, we need a SessionService to manage conversation state and a Runner to orchestrate the execution. For this tutorial, we'll use the simple InMemorySessionService."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcRT6u4PPBxu"
      },
      "outputs": [],
      "source": [
        "# Set up session and runner\n",
        "session_service = InMemorySessionService()\n",
        "await session_service.create_session(\n",
        "    app_name=\"calc_app\", user_id=\"user1\", session_id=\"session1\"\n",
        ")\n",
        "\n",
        "runner = Runner(agent=calc_agent, app_name=\"calc_app\", session_service=session_service)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K59XBdtWKSPZ"
      },
      "source": [
        "Finally, we run the agent with a user query. We iterate through the event stream and use our parse_event helper to see the agent's step-by-step reasoning process: it calls the tool with the generated code, gets the result, and then formulates a final answer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOVnF22oPDoM"
      },
      "outputs": [],
      "source": [
        "# Run the agent\n",
        "code_query = \"Calculate compound interest for $1000 at 5% annual rate for 10 years\"\n",
        "\n",
        "message = genai_types.Content(role=\"user\", parts=[genai_types.Part(text=code_query)])\n",
        "\n",
        "async for event in runner.run_async(\n",
        "    user_id=\"user1\", session_id=\"session1\", new_message=message\n",
        "):\n",
        "    parse_event(event=event)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWoI0mihcaQY"
      },
      "source": [
        "### (Optional) Compare with an agent using BuiltInCodeExecutor tool\n",
        "\n",
        "ADK also provides a BuiltInCodeExecutor. This is an alternative to our custom tool and the Agent Engine Sandbox. It runs code in a more tightly integrated way within the ADK framework itself. This can be a simpler option if you don't need the fine-grained control of the sandbox API. But it works when the agent uses Gemini models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ8w4Tq8edhv"
      },
      "source": [
        "##### Create the agent\n",
        "\n",
        "Notice the agent is configured with code_executor=BuiltInCodeExecutor() instead of a tools list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe-UDcybei0-"
      },
      "outputs": [],
      "source": [
        "builtin_calc_agent = LlmAgent(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    name=\"builtin_calculator\",\n",
        "    description=\"An agent that performs complex calculations\",\n",
        "    instruction=\"\"\"You are a helpful calculation assistant. When asked to calculate:\n",
        "    1. Write clear Python code to solve the problem\n",
        "    2. Use the code tool to run it\n",
        "    3. Explain the results clearly\n",
        "    Always include print statements to show intermediate steps.\n",
        "    \"\"\",\n",
        "    code_executor=BuiltInCodeExecutor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouCHkAOOeqRR"
      },
      "source": [
        "##### Run the agent\n",
        "\n",
        "The setup is the same as our other ADK agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXZZaV0qeqRS"
      },
      "outputs": [],
      "source": [
        "# Set up session and runner\n",
        "built_in_session_service = InMemorySessionService()\n",
        "await built_in_session_service.create_session(\n",
        "    app_name=\"builtin_calc_app\", user_id=\"user1\", session_id=\"session1\"\n",
        ")\n",
        "\n",
        "built_in_runner = Runner(\n",
        "    agent=builtin_calc_agent,\n",
        "    app_name=\"builtin_calc_app\",\n",
        "    session_service=built_in_session_service,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a914871c8853"
      },
      "source": [
        "When we run this agent, our `parse_event` helper will show CODE INTERPRETER EXECUTION and CODE INTERPRETER RESULT events instead of TOOL CALL events. This highlights the different, more integrated execution path of the `BuiltInCodeExecutor`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s1tany5eqRS"
      },
      "outputs": [],
      "source": [
        "async for event in built_in_runner.run_async(\n",
        "    user_id=\"user1\", session_id=\"session1\", new_message=message\n",
        "):\n",
        "    parse_event(event)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JP1CfI7cFEF"
      },
      "source": [
        "### (Advanced) Data analyst agent\n",
        "\n",
        "Let's build a more sophisticated agent. This Data Analyst agent will use the same code execution tool but with more advanced instructions for analyzing data using the pandas library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5Th_T0LtIbt"
      },
      "source": [
        "#### Define structured output for data analysis\n",
        "\n",
        "Pydantic models can be used to define a desired output schema for an agent, though we won't enforce it in this example. It's a good practice for ensuring reliable, structured data from your agents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6gVJ5kGtMwq"
      },
      "outputs": [],
      "source": [
        "class DataAnalysisResult(BaseModel):\n",
        "    \"\"\"Structured output for data analysis results.\"\"\"\n",
        "\n",
        "    total_sales: float = Field(description=\"Total sales amount\")\n",
        "    average_sales: float = Field(description=\"Average sales per product\")\n",
        "    top_product: str = Field(description=\"Product with highest sales\")\n",
        "    insights: str = Field(description=\"Key insights from the analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrhlPc3ztPzL"
      },
      "source": [
        "#### Create a data analysis agent\n",
        "\n",
        "Note the more detailed instruction prompt, guiding the agent to act as an expert data analyst.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi2hagXOdKVS"
      },
      "outputs": [],
      "source": [
        "data_analyst = LlmAgent(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    name=\"data_analyst\",\n",
        "    description=\"Expert data analyst for sales and business metrics\",\n",
        "    instruction=\"\"\"You are an expert data analyst. When given data:\n",
        "\n",
        "    1. First, load and explore the data structure\n",
        "    2. Calculate key metrics (totals, averages, trends) using code tool\n",
        "    3. Identify top performers and outliers\n",
        "    4. Generate actionable insights\n",
        "\n",
        "    Always use pandas for data manipulation and include clear print statements.\n",
        "    Format numbers nicely (e.g., currency with commas).\n",
        "    \"\"\",\n",
        "    tools=[custom_code_executor],\n",
        "    output_key=\"analysis_result\",  # Store result in session state\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FLKG-L-tVaT"
      },
      "source": [
        "#### Run the agent\n",
        "\n",
        "We set up a new runner for our analyst agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwb-S5ridaau"
      },
      "outputs": [],
      "source": [
        "# Initialize session\n",
        "session_service = InMemorySessionService()\n",
        "memory_service = InMemoryMemoryService()\n",
        "artifact_service = InMemoryArtifactService()\n",
        "\n",
        "session = await session_service.create_session(\n",
        "    app_name=\"sales_analysis\",\n",
        "    user_id=\"analyst_001\",\n",
        "    session_id=\"analysis_123\",\n",
        "    state={},  # Empty initial state\n",
        ")\n",
        "\n",
        "# Create runner\n",
        "runner = Runner(\n",
        "    agent=data_analyst,\n",
        "    app_name=\"sales_analysis\",\n",
        "    session_service=session_service,\n",
        "    memory_service=memory_service,\n",
        "    artifact_service=artifact_service,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTikzbUidhGF"
      },
      "outputs": [],
      "source": [
        "# Prepare the analysis request\n",
        "analysis_request = genai_types.Content(\n",
        "    role=\"user\",\n",
        "    parts=[\n",
        "        genai_types.Part(\n",
        "            text=\"\"\"\n",
        "    Analyze this sales data and provide insights:\n",
        "\n",
        "    Product,Sales,Units,Region\n",
        "    Widget A,5000,100,North\n",
        "    Widget B,7500,150,South\n",
        "    Widget C,3000,60,East\n",
        "    Widget D,9000,180,West\n",
        "    Widget E,6500,130,North\n",
        "\n",
        "    Calculate:\n",
        "    1. Total and average sales\n",
        "    2. Best performing product\n",
        "    3. Sales per unit for each product\n",
        "    4. Regional performance summary\n",
        "    \"\"\"\n",
        "        )\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Run the analysis\n",
        "async for event in runner.run_async(\n",
        "    user_id=\"analyst_001\", session_id=\"analysis_123\", new_message=analysis_request\n",
        "):\n",
        "    parse_event(event)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPLNMFXYiXux"
      },
      "source": [
        "## Sandbox Management\n",
        "\n",
        "Now that we know how to use Agent Engine Code Execution, it's important to know how to manage it asssociated resources.\n",
        "\n",
        "The Vertex AI SDK provides simple methods for listing, inspecting, and deleting your sandboxes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDDeSakPieA8"
      },
      "source": [
        "### Listing Sandboxes\n",
        "\n",
        "You can list all sandboxes created within a specific AgentEngine resource."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvQHn92wigFj"
      },
      "outputs": [],
      "source": [
        "sandboxes = client.agent_engines.sandboxes.list(name=agent_engine.api_resource.name)\n",
        "\n",
        "print(f\"Found {len(sandboxes)} sandbox(es)\")\n",
        "for sandbox in sandboxes:\n",
        "    print(f\"- {sandbox.display_name}: {sandbox.name}\")\n",
        "    print(f\"  State: {sandbox.state}\")\n",
        "    print(f\"  Created: {sandbox.create_time}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQANII0tioGI"
      },
      "source": [
        "### Get details of a specific sandbox\n",
        "\n",
        "Retrieve detailed information about a single sandbox using its resource name.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBLFYtC3inV4"
      },
      "outputs": [],
      "source": [
        "sandbox_name = sandboxes[0].name\n",
        "sandbox = client.agent_engines.sandboxes.get(name=sandbox_name)\n",
        "print(f\"Sandbox: {sandbox.display_name}\")\n",
        "print(f\"State: {sandbox.state}\")\n",
        "print(f\"Created: {sandbox.create_time}\")\n",
        "print(f\"Spec: {sandbox.spec}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3m1H0I4i8m4"
      },
      "source": [
        "### Delete a specific sandbox\n",
        "\n",
        "Delete sandboxes you no longer need to avoid incurring costs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df5Z71TLjAwm"
      },
      "outputs": [],
      "source": [
        "delete_operation = client.agent_engines.sandboxes.delete(name=sandbox_name)\n",
        "\n",
        "if delete_operation.done:\n",
        "    print(\"Sandbox deleted successfully\")\n",
        "else:\n",
        "    print(\"Deletion in progress...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_MCAESZjFnu"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "Finally, clean up the top-level AgentEngine resource. Using force=True will also delete any remaining child resources, like other sandboxes you may have created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nz0tVs09xdW"
      },
      "outputs": [],
      "source": [
        "delete_agent_engine = True\n",
        "\n",
        "if delete_agent_engine:\n",
        "    agent_engine.delete(force=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tutorial_get_started_with_code_execution.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
