{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjTHAV8FgEza"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdL4uvQQs76x"
      },
      "source": [
        "# Intro to Veo 2 Video Generation\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/veo/intro_veo.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fvision%2Fveo%2Fintro_veo.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/vision/veo/intro_veo.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/veo/intro_veo.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/veo/intro_veo.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/veo/intro_veo.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/veo/intro_veo.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/X_logo_2023_original.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/veo/intro_veo.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/veo/intro_veo.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "638512614391"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Dave Wang](https://github.com/wadave/) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDjAqcgigwdX"
      },
      "source": [
        "## Overview\n",
        "\n",
        "### Veo 2\n",
        "\n",
        "Vertex AI now offers [Veo 2](https://blog.google/technology/google-labs/video-image-generation-update-december-2024/), Google's cutting-edge video generation technology, empowering developers to create stunningly detailed videos.  Veo 2 simulates real-world physics and supports a diverse range of visual styles.\n",
        "\n",
        "This tutorial demonstrates how to use the REST API to generate videos from both text prompts and input images.\n",
        "\n",
        "Veo 2 is currently in private preview. you can sign up for early access via [VideoFX](https://labs.google/fx/tools/video-fx). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2_iOv5uhXVg"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4uerc9Xhf1f"
      },
      "source": [
        "### Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJyFNKoQhiwF"
      },
      "outputs": [],
      "source": [
        "%pip install -q --upgrade google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f42d12d15616"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3d98395d9a4"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89cf56cd5a4d"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWYnCW0-h6HI"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqz5LUG6h8fA"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxBkUEqdiB1g"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GtjPBmYHiEfx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "BUCKET_NAME = \"[your-bucket-name]\"\n",
        "IMG_PATH = \"[your-image-path]\"\n",
        "LOCATION = \"us-central1\"\n",
        "MODEL_ID = \"veo-2.0-generate-exp\"  # This is model id for veo 2\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVrasKoriKZn"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMQf_BkyiMgF"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import json\n",
        "import mimetypes\n",
        "import os\n",
        "import pprint\n",
        "import time\n",
        "\n",
        "from IPython.display import HTML, Image, display\n",
        "from google import genai\n",
        "import google.auth\n",
        "import google.auth.transport.requests\n",
        "from google.cloud import storage\n",
        "from google.genai import types\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0cb30292d14"
      },
      "source": [
        "### Set up endpoint parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "af98462dba1a"
      },
      "outputs": [],
      "source": [
        "video_model = f\"https://us-central1-aiplatform.googleapis.com/v1beta1/projects/{PROJECT_ID}/locations/us-central1/publishers/google/models/{MODEL_ID}\"\n",
        "prediction_endpoint = f\"{video_model}:predictLongRunning\"\n",
        "fetch_endpoint = f\"{video_model}:fetchPredictOperation\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_bwA9hiMzL"
      },
      "source": [
        "### Define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c13b6a23d9df"
      },
      "outputs": [],
      "source": [
        "def send_request_to_google_api(api_endpoint, data=None):\n",
        "    \"\"\"Sends an HTTP request to a Google API endpoint.\n",
        "\n",
        "    Args:\n",
        "        api_endpoint: The URL of the Google API endpoint.\n",
        "        data: (Optional) Dictionary of data to send in the request body.\n",
        "\n",
        "    Returns:\n",
        "        The response from the Google API as a JSON object, or None if an error occurs.\n",
        "        Raises an exception for bad status codes.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        creds, _ = google.auth.default()  # _ is often used for variables we don't need\n",
        "        auth_req = google.auth.transport.requests.Request()\n",
        "        creds.refresh(auth_req)\n",
        "        access_token = creds.token\n",
        "\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {access_token}\",\n",
        "            \"Content-Type\": \"application/json\",\n",
        "        }\n",
        "\n",
        "        response = requests.post(api_endpoint, headers=headers, json=data)\n",
        "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:  # Catch potential request errors\n",
        "        print(f\"Error sending request: {e}\")  # Handle or log the error appropriately\n",
        "        return None  # Or re-raise the exception if you want the caller to handle it\n",
        "\n",
        "\n",
        "def compose_video_gen_request(\n",
        "    prompt,\n",
        "    image_uri,\n",
        "    gcs_uri,\n",
        "    seed,\n",
        "    aspect_ratio,\n",
        "    sample_count,\n",
        "    negative_prompt,\n",
        "    person_generation=\"allow_adult\",\n",
        "):\n",
        "    \"\"\"Composes the request body for the video generation API.\n",
        "    Args:\n",
        "        prompt: The text prompt describing the desired video.\n",
        "        image_uri: The GCS URI of the initial image (optional).  If provided,\n",
        "            it should point to a PNG image.\n",
        "        gcs_uri: The GCS URI where the generated video(s) will be stored.\n",
        "        seed: A random seed for video generation reproducibility.\n",
        "        aspect_ratio: The desired aspect ratio of the generated video (e.g., \"16:9\", \"9:16\", \"square\").\n",
        "        sample_count: The number of videos to generate.\n",
        "        negative_prompt: A text prompt describing what to avoid in the generated video.\n",
        "        person_generation: Controls the generation of people in the video.\n",
        "            Defaults to \"allow_adult\". Other possible values might include\n",
        "            \"disallow\", \"allow_child\", etc. (check the API documentation for\n",
        "            all valid values).\n",
        "\n",
        "    Returns:\n",
        "        A dictionary representing the request body for the video generation API.\n",
        "    \"\"\"\n",
        "\n",
        "    instance = {\"prompt\": prompt}\n",
        "    if image_uri:\n",
        "        instance[\"image\"] = {\"gcsUri\": image_uri, \"mimeType\": \"png\"}\n",
        "\n",
        "    request = {\n",
        "        \"instances\": [instance],\n",
        "        \"parameters\": {\n",
        "            \"storageUri\": gcs_uri,\n",
        "            \"sampleCount\": sample_count,\n",
        "            \"seed\": seed,\n",
        "            \"aspectRatio\": aspect_ratio,\n",
        "            \"negativePrompt\": negative_prompt,\n",
        "            \"personGeneration\": person_generation,\n",
        "        },\n",
        "    }\n",
        "    return request\n",
        "\n",
        "\n",
        "def fetch_operation(lro_name, timeout_seconds=300, poll_interval_seconds=10):\n",
        "    \"\"\"Fetches the status of a Long-Running Operation (lro).\n",
        "\n",
        "    Args:\n",
        "        lro_name: The name of the lro.\n",
        "        timeout_seconds: The maximum time to wait for the operation to complete.\n",
        "        poll_interval_seconds: The time to wait between polls.\n",
        "\n",
        "    Returns:\n",
        "        The lro response if successful, None if it times out, or raises an exception for API errors.\n",
        "    \"\"\"\n",
        "    request = {\"operationName\": lro_name}\n",
        "    end_time = time.time() + timeout_seconds\n",
        "\n",
        "    while time.time() < end_time:\n",
        "        resp = send_request_to_google_api(fetch_endpoint, request)\n",
        "        if resp is None:  # Handle API errors during polling.\n",
        "            return None  # or raise the exception if you prefer.\n",
        "        if \"done\" in resp and resp[\"done\"]:\n",
        "            return resp\n",
        "        time.sleep(poll_interval_seconds)\n",
        "\n",
        "    print(\n",
        "        f\"lro {lro_name} timed out after {timeout_seconds} seconds.\"\n",
        "    )  # Informative message\n",
        "    return None  # Indicate timeout\n",
        "\n",
        "\n",
        "def text_to_video(\n",
        "    prompt, seed, aspect_ratio, sample_count, output_gcs, negative_prompt=\"\"\n",
        "):\n",
        "    \"\"\"Generates videos from a text prompt using the Google Cloud Video Generation API.\n",
        "\n",
        "    Args:\n",
        "        prompt: The text prompt describing the desired video.\n",
        "        seed: A random seed for video generation reproducibility.\n",
        "        aspect_ratio: The desired aspect ratio of the generated video (e.g., \"16:9\", \"9:16\", \"square\").\n",
        "        sample_count: The number of videos to generate.\n",
        "        output_gcs: The GCS URI where the generated video(s) will be stored.\n",
        "        negative_prompt: A text prompt describing what to avoid in the generated video (optional).\n",
        "\n",
        "    Returns:\n",
        "        The lro (Long-Running Operation) response from the API, which can be used\n",
        "        to track the video generation progress. Returns None if the initial API\n",
        "        request fails.\n",
        "    \"\"\"\n",
        "    req = compose_video_gen_request(\n",
        "        prompt, None, output_gcs, seed, aspect_ratio, sample_count, negative_prompt\n",
        "    )\n",
        "    resp = send_request_to_google_api(prediction_endpoint, req)\n",
        "    if resp is None:  # Handle API errors during initial request.\n",
        "        return None\n",
        "    print(resp)\n",
        "    return fetch_operation(resp[\"name\"])\n",
        "\n",
        "\n",
        "def image_to_video(\n",
        "    prompt, image_gcs, seed, aspect_ratio, sample_count, output_gcs, negative_prompt=\"\"\n",
        "):\n",
        "    \"\"\"Generates videos from an image and a text prompt using the Google Cloud Video Generation API.\n",
        "\n",
        "    Args:\n",
        "        prompt: The text prompt describing the desired video.\n",
        "        image_gcs: The GCS URI of the input image.\n",
        "        seed: A random seed for video generation reproducibility.\n",
        "        aspect_ratio: The desired aspect ratio of the generated video (e.g., \"16:9\", \"9:16\", \"square\").\n",
        "        sample_count: The number of videos to generate.\n",
        "        output_gcs: The GCS URI where the generated video(s) will be stored.\n",
        "        negative_prompt: A text prompt describing what to avoid in the generated video (optional).\n",
        "\n",
        "    Returns:\n",
        "        The lro (Long-Running Operation) response from the API, which can be used\n",
        "        to track the video generation progress. Returns None if the initial API\n",
        "        request fails.\n",
        "    \"\"\"\n",
        "    req = compose_video_gen_request(\n",
        "        prompt, image_gcs, output_gcs, seed, aspect_ratio, sample_count, negative_prompt\n",
        "    )\n",
        "    resp = send_request_to_google_api(prediction_endpoint, req)\n",
        "    if resp is None:  # Handle API errors during initial request.\n",
        "        return None\n",
        "    print(resp)\n",
        "    return fetch_operation(resp[\"name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0fd12c1990ae"
      },
      "outputs": [],
      "source": [
        "def play_video(op, bucket_name=None):\n",
        "    \"\"\"Displays generated videos from an lro response using HTML5 video tag.\n",
        "\n",
        "    Args:\n",
        "        op: The lro response dictionary.\n",
        "        bucket_name: The GCS bucket name (optional, auto-detected if None).\n",
        "    \"\"\"\n",
        "\n",
        "    if op and op.get(\"response\") and op[\"response\"].get(\"generatedSamples\"):\n",
        "        storage_client = storage.Client()\n",
        "\n",
        "        for video in op[\"response\"][\"generatedSamples\"]:\n",
        "            gcs_uri = video[\"video\"][\"uri\"]\n",
        "            parts = gcs_uri.replace(\"gs://\", \"\").split(\"/\")\n",
        "            if bucket_name is None:\n",
        "                bucket_name = parts[0]\n",
        "                blob_name = \"/\".join(parts[1:])\n",
        "            else:\n",
        "                blob_name = \"/\".join(parts[1:])\n",
        "\n",
        "            bucket = storage_client.bucket(bucket_name)\n",
        "            blob = bucket.blob(blob_name)\n",
        "\n",
        "            file_name = blob_name.split(\"/\")[-1]\n",
        "            local_filepath = file_name\n",
        "\n",
        "            try:\n",
        "                blob.download_to_filename(local_filepath)\n",
        "                print(f\"Downloaded {gcs_uri} to {local_filepath}\")\n",
        "\n",
        "                mime_type, _ = mimetypes.guess_type(local_filepath)\n",
        "                if mime_type and mime_type.startswith(\n",
        "                    \"video/\"\n",
        "                ):  # Check if it's a video\n",
        "                    with open(local_filepath, \"rb\") as f:\n",
        "                        video_bytes = f.read()\n",
        "                    video_base64 = base64.b64encode(video_bytes).decode(\"utf-8\")\n",
        "\n",
        "                    video_html = f\"\"\"\n",
        "                    <video width=\"640\" height=\"480\" controls>\n",
        "                        <source src=\"data:{mime_type};base64,{video_base64}\" type=\"{mime_type}\">\n",
        "                        Your browser does not support the video tag.\n",
        "                    </video>\n",
        "                    \"\"\"\n",
        "                    display(HTML(video_html))  # Use display() for Jupyter\n",
        "\n",
        "                else:\n",
        "                    print(f\"File {local_filepath} is not a supported video format.\")\n",
        "\n",
        "                os.remove(local_filepath)\n",
        "                print(f\"Deleted local file: {local_filepath}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {gcs_uri}: {e}\")\n",
        "                if os.path.exists(local_filepath):\n",
        "                    os.remove(local_filepath)\n",
        "                    print(f\"Deleted partially downloaded local file: {local_filepath}\")\n",
        "\n",
        "    else:\n",
        "        print(\"No videos to display in the lro response.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "fea2e70b61c8"
      },
      "outputs": [],
      "source": [
        "def display_image_from_gcs_local(\n",
        "    bucket_name, blob_name, local_filepath=\"temp_image.jpg\"\n",
        "):  # Added default local path\n",
        "    \"\"\"Downloads an image from GCS, saves it locally, and displays it.\n",
        "\n",
        "    Args:\n",
        "        bucket_name: The name of the GCS bucket.\n",
        "        blob_name: The name of the blob (file) in the bucket.\n",
        "        local_filepath: path to save image locally before display.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        storage_client = storage.Client()\n",
        "        bucket = storage_client.bucket(bucket_name)\n",
        "        blob = bucket.blob(blob_name)\n",
        "\n",
        "        blob.download_to_filename(local_filepath)  # Download to local file\n",
        "        display(Image(local_filepath, width=800, height=600))  # Display from local file\n",
        "        os.remove(local_filepath)  # Clean up the local file\n",
        "        print(f\"Removed local file: {local_filepath}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error displaying image: {e}\")\n",
        "        if os.path.exists(local_filepath):\n",
        "            os.remove(local_filepath)\n",
        "            print(f\"Removed partially downloaded local file: {local_filepath}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h08xBSeUCW-r"
      },
      "source": [
        "##  1. Create Veo 2 Prompt (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu3VMEZ8Cqp3"
      },
      "source": [
        "This step is optional. If you have a satisfactory prompt, please go to step 2 directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xMP2heN5IkrK"
      },
      "outputs": [],
      "source": [
        "def create_veo_prompt(user_intent):\n",
        "    client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
        "    # model = \"gemini-2.0-flash-exp\"\n",
        "    # model = \"gemini-1.5-pro-002\"\n",
        "    model = \"gemini-exp-1206\"\n",
        "    prompt = f\"\"\"\n",
        "     Generate a high quality rewrite of user_intent for a text-to-video service. It adds details , but does not change the user's intent.\n",
        "\n",
        "     Consider extra details to enhance creativity. Consider adding visual details IF it would support the user query:\n",
        "     - camera angle and composition: wide angle, drone camera, low angle view, closeup, macro, view from below looking up, centered, fisheye\n",
        "     - lighting: silhouette, backlit, dim ambient lighting, long shadows, natural light, sunrise / sunset, daylight\n",
        "     - camera settings and motion: depth of field, in focus, long exposure, tracking shot, POV\n",
        "     - general quality identifiers: professional, award winning, high-quality\n",
        "     - styles: cinematic shot, street photography, fashion photography, architectural photography, dramatic, vintage, retro\n",
        "     - background: blurred background, bokeh, pink background, solid light blue background\n",
        "     - color scheme: high contrast, cold muted tones, muted orange warm tones, dark tones, pastel colors\n",
        "     - subject actions: walking, running, ski, snowboarding, turning head\n",
        "     - subject poses: rotation, flip, inversions\n",
        "     \n",
        "     To get the most out of Veo, incorporate specific video terminology into your prompts. Veo understands a wide range of terms related to:\n",
        "\n",
        "     Shot composition: Specify the framing and number of subjects in the shot (e.g., \"single shot,\" \"two shot,\" \"over-the-shoulder shot\").\n",
        "     Camera positioning and movement: Control the camera's location and movement using terms like \"eye level,\" \"high angle,\" \"worms eye,\" \"dolly shot,\" \"zoom shot,\" \"pan shot,\" and \"tracking shot.\"\n",
        "     Focus and lens effects: Use terms like \"shallow focus,\" \"deep focus,\" \"soft focus,\" \"macro lens,\" and \"wide-angle lens\" to achieve specific visual effects.\n",
        "     Overall style and subject: Guide Veo's creative direction by specifying styles like \"sci-fi,\" \"romantic comedy,\" \"action movie,\" or \"animation.\" You can also describe the subjects and backgrounds you want, such as \"cityscape,\" \"nature,\" \"vehicles,\" or \"animals.\"\n",
        "\n",
        "\n",
        "     Now, provide 4 different REWRITES for the following user_intent in the style above using about 100 words each. Only produce the final four rewrites, one on each line, no intermediate thoughts. The rewrites should be distinct from each other, while following the user's intent.\n",
        "     Here's user_intent: {user_intent}\n",
        "\n",
        "     * **Output Format:** Return your analysis as a JSON object with the following structure:\n",
        "       'prompt1': 'Text prompt for the first rewrite',\n",
        "       'prompt2': 'Text prompt for the second rewrite',\n",
        "\n",
        "     \"\"\"\n",
        "\n",
        "    contents = [prompt]\n",
        "\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        temperature=1,\n",
        "        top_p=0.95,\n",
        "        max_output_tokens=8192,\n",
        "        response_modalities=[\"TEXT\"],\n",
        "        response_mime_type=\"application/json\",\n",
        "        # response_schema=response_schema,\n",
        "        safety_settings=[\n",
        "            types.SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
        "            types.SafetySetting(\n",
        "                category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"\n",
        "            ),\n",
        "            types.SafetySetting(\n",
        "                category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"\n",
        "            ),\n",
        "            types.SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        contents=contents,\n",
        "        config=generate_content_config,\n",
        "    )\n",
        "\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-aox2jVdI3Rt"
      },
      "outputs": [],
      "source": [
        "user_intent = \"\"\"An xgames snowboarder performs super pipe snowboarding Frontside 1080 trick at X Games Aspen. The snowboarder initiates a jump while facing downhill, then rotates their body and board a full three rotations (1080 degrees) in the air,\n",
        " at X Games Aspen\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "b3iWouoCI3Y6"
      },
      "outputs": [],
      "source": [
        "resp = create_veo_prompt(user_intent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0PZhmIiI3dT"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(json.loads(resp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhRHUmru6CHl"
      },
      "outputs": [],
      "source": [
        "prompt = json.loads(resp)[\"prompt2\"]\n",
        "prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7cYZuR3CSX2"
      },
      "source": [
        "# 2. Create videos using Veo 2 REST API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "RbRpFDO6zOSh"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "A high-angle tracking shot with a wide-angle lens, capturing an xgames snowboarder in action. \n",
        "The snowboarder executes a Frontside 1080 trick at X Games Aspen. The athlete initiates a jump while facing downhill, \n",
        "then rotates their body and board a full three rotations (1080 degrees) mid-air. \n",
        "The shot is in focus with dim ambient lighting, creating a dramatic effect. \n",
        "The background is a cityscape of Aspen, with a solid light blue sky. \n",
        "The overall style is professional, with a vintage, retro feel.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hdc0GXUAeyO"
      },
      "source": [
        "### 2.1 Generate video from a text prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tygfLLlWyTo_"
      },
      "outputs": [],
      "source": [
        "aspect_ratio = \"16:9\"  # @param [\"16:9\", \"9:16\"]\n",
        "output_gcs = f\"gs://{BUCKET_NAME}\"  # @param {type: 'string'}\n",
        "negative_prompt = \"\"  # @param {type: 'string'}\n",
        "seed = 200\n",
        "sample_count = 1\n",
        "\n",
        "text_to_video_response = text_to_video(\n",
        "    prompt, seed, aspect_ratio, sample_count, output_gcs, negative_prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h14My7VQ7zou"
      },
      "outputs": [],
      "source": [
        "play_video(text_to_video_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YysYLyiVj8Zd"
      },
      "source": [
        "### 2.2 Generate video from an image and text prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd360abc6a3e"
      },
      "source": [
        "#### The below image will be used to generate video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4e6e148d79c"
      },
      "outputs": [],
      "source": [
        "display_image_from_gcs_local(BUCKET_NAME, IMG_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gNxNj9N2R4o"
      },
      "outputs": [],
      "source": [
        "image_gcs = f\"gs://{BUCKET_NAME}/{IMG_PATH}\"  # @param {type: 'string'}\n",
        "aspect_ratio = \"16:9\"  # @param [\"16:9\", \"9:16\"]\n",
        "output_gcs = f\"gs://{BUCKET_NAME}\"  # @param {type: 'string'}\n",
        "negative_prompt = \"\"  # @param {type: 'string'}\n",
        "seed = 200\n",
        "sample_count = 1\n",
        "\n",
        "image_to_video_response = image_to_video(\n",
        "    prompt, image_gcs, seed, aspect_ratio, sample_count, output_gcs, negative_prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqDeAihl800v"
      },
      "outputs": [],
      "source": [
        "play_video(image_to_video_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "971392a1879a"
      },
      "source": [
        "# References\n",
        "1. https://cloud.google.com/vertex-ai/generative-ai/docs/video/generate-videos\n",
        "2. https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/veo-video-generation"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_veo.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
