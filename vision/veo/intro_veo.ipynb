{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjTHAV8FgEza"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdL4uvQQs76x"
      },
      "source": [
        "# Intro to Veo 2 Video Generation\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/veo/intro_veo.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fvision%2Fveo%2Fintro_veo.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/vision/veo/intro_veo.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/veo/intro_veo.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/X_logo_2023_original.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Dave Wang](https://github.com/wadave/) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDjAqcgigwdX"
      },
      "source": [
        "## Overview\n",
        "\n",
        "### Veo 2\n",
        "\n",
        "Vertex AI now offers Veo 2, Google's cutting-edge video generation technology, empowering developers to create stunningly detailed videos.  Veo 2 simulates real-world physics and supports a diverse range of visual styles.\n",
        "\n",
        "This tutorial demonstrates how to use the Vertex AI API to generate videos from both text prompts and input images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2_iOv5uhXVg"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4uerc9Xhf1f"
      },
      "source": [
        "### Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "executionInfo": {
          "elapsed": 3897,
          "status": "ok",
          "timestamp": 1737999360673,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "rJyFNKoQhiwF"
      },
      "outputs": [],
      "source": [
        "%pip install -q --upgrade mediapy google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWYnCW0-h6HI"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqz5LUG6h8fA"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxBkUEqdiB1g"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "executionInfo": {
          "elapsed": 170,
          "status": "ok",
          "timestamp": 1738018812321,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "GtjPBmYHiEfx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "BUCKET_URI = \"[your-bucket-uri ]\"\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVrasKoriKZn"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "executionInfo": {
          "elapsed": 173,
          "status": "ok",
          "timestamp": 1738018824236,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "oMQf_BkyiMgF"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import google.auth\n",
        "import google.auth.transport.requests\n",
        "import mediapy as media\n",
        "import requests\n",
        "from google.cloud import storage\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import base64\n",
        "import json\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_bwA9hiMzL"
      },
      "source": [
        "### Define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def send_request_to_google_api(api_endpoint, data=None):\n",
        "    \"\"\"Sends an HTTP request to a Google API endpoint.\n",
        "\n",
        "    Args:\n",
        "        api_endpoint: The URL of the Google API endpoint.\n",
        "        data: (Optional) Dictionary of data to send in the request body.\n",
        "\n",
        "    Returns:\n",
        "        The response from the Google API as a JSON object, or None if an error occurs.\n",
        "        Raises an exception for bad status codes.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        creds, _ = google.auth.default()  # _ is often used for variables we don't need\n",
        "        auth_req = google.auth.transport.requests.Request()\n",
        "        creds.refresh(auth_req)\n",
        "        access_token = creds.token\n",
        "\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {access_token}\",\n",
        "            \"Content-Type\": \"application/json\",\n",
        "        }\n",
        "\n",
        "        response = requests.post(api_endpoint, headers=headers, json=data)\n",
        "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:  # Catch potential request errors\n",
        "        print(f\"Error sending request: {e}\")  # Handle or log the error appropriately\n",
        "        return None  # Or re-raise the exception if you want the caller to handle it\n",
        "\n",
        "\n",
        "def compose_videogen_request(\n",
        "    prompt,\n",
        "    image_uri,\n",
        "    gcs_uri,\n",
        "    seed,\n",
        "    aspect_ratio,\n",
        "    sample_count,\n",
        "    negative_prompt,\n",
        "    person_generation=\"allow_adult\"\n",
        "):\n",
        "    \"\"\"Composes the request body for the video generation API.\"\"\"\n",
        "\n",
        "    instance = {\"prompt\": prompt}\n",
        "    if image_uri:\n",
        "        instance[\"image\"] = {\"gcsUri\": image_uri, \"mimeType\": \"png\"}\n",
        "\n",
        "    request = {\n",
        "        \"instances\": [instance],\n",
        "        \"parameters\": {\n",
        "            \"storageUri\": gcs_uri,\n",
        "            \"sampleCount\": sample_count,\n",
        "            \"seed\": seed,\n",
        "            \"aspectRatio\": aspect_ratio,\n",
        "            \"negativePrompt\": negative_prompt,\n",
        "            \"personGeneration\": person_generation,\n",
        "        },\n",
        "    }\n",
        "    return request\n",
        "\n",
        "def fetch_operation(lro_name, timeout_seconds=300, poll_interval_seconds=10):\n",
        "    \"\"\"Fetches the status of a Long-Running Operation (LRO).\n",
        "\n",
        "    Args:\n",
        "        lro_name: The name of the LRO.\n",
        "        timeout_seconds: The maximum time to wait for the operation to complete.\n",
        "        poll_interval_seconds: The time to wait between polls.\n",
        "\n",
        "    Returns:\n",
        "        The LRO response if successful, None if it times out, or raises an exception for API errors.\n",
        "    \"\"\"\n",
        "    request = {\"operationName\": lro_name}\n",
        "    end_time = time.time() + timeout_seconds\n",
        "\n",
        "    while time.time() < end_time:\n",
        "        resp = send_request_to_google_api(fetch_endpoint, request)\n",
        "        if resp is None: # Handle API errors during polling.\n",
        "          return None # or raise the exception if you prefer.\n",
        "        if \"done\" in resp and resp[\"done\"]:\n",
        "            return resp\n",
        "        time.sleep(poll_interval_seconds)\n",
        "\n",
        "    print(f\"LRO {lro_name} timed out after {timeout_seconds} seconds.\") # Informative message\n",
        "    return None  # Indicate timeout\n",
        "\n",
        "\n",
        "def text_to_video(prompt, seed, aspect_ratio, sample_count, output_gcs, negative_prompt=\"\"):\n",
        "    req = compose_videogen_request(\n",
        "        prompt, None, output_gcs, seed, aspect_ratio, sample_count, negative_prompt\n",
        "    )\n",
        "    resp = send_request_to_google_api(prediction_endpoint, req)\n",
        "    if resp is None: # Handle API errors during initial request.\n",
        "      return None\n",
        "    print(resp)\n",
        "    return fetch_operation(resp[\"name\"])\n",
        "\n",
        "\n",
        "def image_to_video(\n",
        "    prompt, image_gcs, seed, aspect_ratio, sample_count, output_gcs, negative_prompt=\"\"\n",
        "):\n",
        "    req = compose_videogen_request(\n",
        "        prompt, image_gcs, output_gcs, seed, aspect_ratio, sample_count, negative_prompt\n",
        "    )\n",
        "    resp = send_request_to_google_api(prediction_endpoint, req)\n",
        "    if resp is None: # Handle API errors during initial request.\n",
        "      return None\n",
        "    print(resp)\n",
        "    return fetch_operation(resp[\"name\"])\n",
        "\n",
        "def show_video(op, bucket_name=None):  # Make bucket name configurable\n",
        "    \"\"\"Displays generated videos from an LRO response.\n",
        "\n",
        "    Args:\n",
        "        op: The LRO response dictionary.\n",
        "        bucket_name: The GCS bucket name (optional, auto-detected if None).\n",
        "    \"\"\"\n",
        "\n",
        "    print(op)\n",
        "    if op and op.get(\"response\") and op[\"response\"].get(\"generatedSamples\"):  # Safer checks\n",
        "        storage_client = storage.Client()\n",
        "\n",
        "        for video in op[\"response\"][\"generatedSamples\"]:\n",
        "            gcs_uri = video[\"video\"][\"uri\"]\n",
        "            # Extract bucket name and blob name more robustly\n",
        "            parts = gcs_uri.replace(\"gs://\", \"\").split(\"/\") # Remove \"gs://\" and split\n",
        "            if bucket_name is None:\n",
        "                bucket_name = parts[0]\n",
        "                blob_name = \"/\".join(parts[1:])\n",
        "            else:\n",
        "              blob_name = \"/\".join(parts[1:])\n",
        "\n",
        "            bucket = storage_client.bucket(bucket_name)\n",
        "            blob = bucket.blob(blob_name)\n",
        "\n",
        "            file_name = blob_name.split(\"/\")[-1] # Extract filename from blob name\n",
        "            local_filepath = file_name # Or specify a full local path if needed\n",
        "\n",
        "            try:\n",
        "                blob.download_to_filename(local_filepath)\n",
        "                print(f\"Downloaded {gcs_uri} to {local_filepath}\")\n",
        "                media.show_video(media.read_video(local_filepath), height=500)\n",
        "                os.remove(local_filepath) # Clean up the local file after display\n",
        "                print(f\"Deleted local file: {local_filepath}\")\n",
        "            except Exception as e:  # Handle potential download errors\n",
        "                print(f\"Error downloading {gcs_uri}: {e}\")\n",
        "                if os.path.exists(local_filepath): # Clean up even if download failed\n",
        "                    os.remove(local_filepath)\n",
        "                    print(f\"Deleted partially downloaded local file: {local_filepath}\")\n",
        "\n",
        "    else:\n",
        "        print(\"No videos to display in the LRO response.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "executionInfo": {
          "elapsed": 143,
          "status": "ok",
          "timestamp": 1738018825183,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "GUrEwbvFiPhJ"
      },
      "outputs": [],
      "source": [
        "def send_request_to_google_api(api_endpoint, data=None):\n",
        "    \"\"\"\n",
        "    Sends an HTTP request to a Google API endpoint.\n",
        "\n",
        "    Args:\n",
        "        api_endpoint: The URL of the Google API endpoint.\n",
        "        data: (Optional) Dictionary of data to send in the request body (for POST, PUT, etc.).\n",
        "\n",
        "    Returns:\n",
        "        The response from the Google API.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get access token calling API\n",
        "    creds, project = google.auth.default()\n",
        "    auth_req = google.auth.transport.requests.Request()\n",
        "    creds.refresh(auth_req)\n",
        "    access_token = creds.token\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {access_token}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "\n",
        "    response = requests.post(api_endpoint, headers=headers, json=data)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "def compose_videogen_request(\n",
        "    prompt,\n",
        "    image_uri,\n",
        "    gcs_uri,\n",
        "    seed,\n",
        "    aspect_ratio,\n",
        "    sample_count,\n",
        "    negative_prompt,\n",
        "    person_generation=\"allow_adult\"\n",
        "):\n",
        "    instance = {\"prompt\": prompt}\n",
        "    if image_uri:\n",
        "        instance[\"image\"] = {\"gcsUri\": image_uri, \"mimeType\": \"png\"}\n",
        "    request = {\n",
        "        \"instances\": [instance],\n",
        "        \"parameters\": {\n",
        "            \"storageUri\": gcs_uri,\n",
        "            \"sampleCount\": sample_count,\n",
        "            \"seed\": seed,\n",
        "            \"aspectRatio\": aspect_ratio,\n",
        "            \"negativePrompt\": negative_prompt,\n",
        "            \"personGeneration\": person_generation,\n",
        "        },\n",
        "    }\n",
        "    return request\n",
        "\n",
        "\n",
        "def fetch_operation(lro_name):\n",
        "    request = {\"operationName\": lro_name}\n",
        "    # The generation usually takes 2 minutes. Loop 30 times, around 5 minutes.\n",
        "    for i in range(30):\n",
        "        resp = send_request_to_google_api(fetch_endpoint, request)\n",
        "        if \"done\" in resp and resp[\"done\"]:\n",
        "            return resp\n",
        "        time.sleep(10)\n",
        "\n",
        "\n",
        "def text_to_video(prompt, seed, aspect_ratio, sample_count, output_gcs, negative_prompt=\"\"):\n",
        "    req = compose_videogen_request(\n",
        "        prompt, None, output_gcs, seed, aspect_ratio, sample_count, negative_prompt\n",
        "    )\n",
        "    resp = send_request_to_google_api(prediction_endpoint, req)\n",
        "    print(resp)\n",
        "    return fetch_operation(resp[\"name\"])\n",
        "\n",
        "\n",
        "def image_to_video(\n",
        "    prompt, image_gcs, seed, aspect_ratio, sample_count, output_gcs, negative_prompt=\"\"\n",
        "):\n",
        "    req = compose_videogen_request(\n",
        "        prompt, image_gcs, output_gcs, seed, aspect_ratio, sample_count, negative_prompt\n",
        "    )\n",
        "    resp = send_request_to_google_api(prediction_endpoint, req)\n",
        "    print(resp)\n",
        "    return fetch_operation(resp[\"name\"])\n",
        "\n",
        "\n",
        "def show_video(op):\n",
        "    print(op)\n",
        "    if op[\"response\"]:\n",
        "        for video in op[\"response\"][\"generatedSamples\"]:\n",
        "            gcs_uri = video[\"video\"][\"uri\"]\n",
        "            file_name = gcs_uri.split(\"/\")[-1]\n",
        "            !gsutil cp {gcs_uri} {file_name}\n",
        "            media.show_video(media.read_video(file_name), height=500)\n",
        "\n",
        "\n",
        "def show_sdk_video(op):\n",
        "    print(op)\n",
        "    if op.generate_videos_response.videos:\n",
        "        for video in op.generate_videos_response.videos:\n",
        "            gcs_uri = video.uri\n",
        "            file_name = gcs_uri.split(\"/\")[-1]\n",
        "            !gsutil cp {gcs_uri} {file_name}\n",
        "            media.show_video(media.read_video(file_name), height=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jaSOOadiUj6"
      },
      "source": [
        "### Load the video model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "executionInfo": {
          "elapsed": 164,
          "status": "ok",
          "timestamp": 1738018830557,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "APRfTklCiYR2"
      },
      "outputs": [],
      "source": [
        "video_model = f\"https://us-central1-aiplatform.googleapis.com/v1beta1/projects/{PROJECT_ID}/locations/us-central1/publishers/google/models/veo-2.0-generate-exp\"\n",
        "prediction_endpoint = f\"{video_model}:predictLongRunning\"\n",
        "fetch_endpoint = f\"{video_model}:fetchPredictOperation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc0JvVg4Ikeq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h08xBSeUCW-r"
      },
      "source": [
        "# 1. VEO prompt optimization (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu3VMEZ8Cqp3"
      },
      "source": [
        "##  This step is optional. If you have a statisfactory prompt, please go to step 2 directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiZa_P7oIrAI"
      },
      "source": [
        "### 1.1 Create prompt 1:Create prompt by gemini (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "executionInfo": {
          "elapsed": 155,
          "status": "ok",
          "timestamp": 1738018833167,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "RxI-nm4KIwx1"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import base64\n",
        "import json\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "executionInfo": {
          "elapsed": 169,
          "status": "ok",
          "timestamp": 1738018856030,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "xMP2heN5IkrK"
      },
      "outputs": [],
      "source": [
        "def create_veo_prompt(USER_QUERY):\n",
        "    client = genai.Client(\n",
        "        vertexai=True, project=\"ace-chatbot-demo\", location=\"us-central1\"\n",
        "    )\n",
        "    #model = \"gemini-2.0-flash-exp\"\n",
        "    #model = \"gemini-1.5-pro-002\"\n",
        "    model = \"gemini-exp-1206\"\n",
        "    prompt = f\"\"\"\n",
        "     Generate a high quality rewrite of USER_QUERY for a text-to-video service. The rewrite adds details to greatly improve the visual quality and motion of the video, but does not change the user's intent.\n",
        "\n",
        "     Refrain from adding children or minors to the rewrite if not necessary to satisfy the USER_QUERY.\n",
        "\n",
        "     Consider extra details to enhance creativity. Consider adding visual details IF it would support the user query:\n",
        "     - camera angle and composition: wide angle, drone camera, low angle view, closeup, macro, view from below looking up, centered, fisheye\n",
        "     - lighting: silhouette, backlit, dim ambient lighting, long shadows, natural light, sunrise / sunset, daylight\n",
        "     - camera settings and motion: depth of field, in focus, long exposure, tracking shot, POV\n",
        "     - general quality identifiers: professional, award winning, high-quality\n",
        "     - styles: cinematic shot, street photography, fashion photography, architectural photography, dramatic, vintage, retro\n",
        "     - background: blurred background, bokeh, pink background, solid light blue background\n",
        "     - color scheme: high contrast, cold muted tones, muted orange warm tones, dark tones, pastel colors\n",
        "     - subject actions: walking, running, ski, snowboarding, turning head\n",
        "     - subject poses: rotation, flip, inversions\n",
        "\n",
        "     Feel free to repeat the most important parts of the description! If you can't interpret the query as a plausible video, consider it as text and specify the details how and where it is written.\n",
        "\n",
        "     Remember, it is important to include every word or a synonym from the USER_QUERY. Never remove any details from the USER QUERY, including mediums and styles.\n",
        "\n",
        "     If USER_QUERY is long and detailed, either 1) add minor details in the variations, or 2) copy the USER_QUERY and only correct typos or misspellings.\n",
        "\n",
        "     Absolutely make sure that EVERY detail of the USER_QUERY is well captured in each variation.\n",
        "     Consider emphasizing the features of the USER_QUERY so that the video is rendered faithfully to the USER_QUERY.\n",
        "\n",
        "     Please follow this style of text prompt, each line is a different prompt example:\n",
        "\n",
        "     This close-up shot follows a happy queen as she ascends the steps of a candlelit throne room. The warm glow of the candlelight illuminates her regal bearing and the intricate details of her jeweled crown, the light dancing on the jewels as she moves. She turns her head, the happiness in her eyes becoming more prominent. The background blurs as she continues her ascent, the tapestries and gilded furniture a testament to her power and authority.\n",
        "\n",
        "     Close-up portrait of a Black woman dancing in a vibrant carnival in Trinidad and Tobago. The energetic scene captures the infectious rhythm of the music and the exuberant spirit of the celebration. Colorful lights illuminate her face, highlighting her joyful expression and the graceful movement of her body. Her eyes, a sparkling brown, radiate pure happiness and the unbridled passion of Caribbean culture.\n",
        "\n",
        "     Cinematic shot of a Caucasian man dressed in a weathered green trench coat, bathed in the eerie glow of a green neon sign. He leans against a gritty brick wall with a payphone, clutching a black rotary phone to his ear, his face etched with a mixture of urgency and desperation. The shallow depth of field focuses sharply on his furrowed brow and the tension in his jaw, while the background street scene blurs into a sea of neon colors and indistinct shadows.\n",
        "\n",
        "     This underwater film scene features a close-up of a man in a dark business suit swimming through murky water. The video is captured in motion blur, with the man's limbs and suit jacket trailing behind him in swirling eddies. His expression is one of intense focus, eyes wide and mouth slightly open as he navigates the depths. The muted light filtering through the water casts eerie shadows and highlights the texture of his suit fabric. The overall mood is one of suspense and urgency, as if the man is on a desperate mission with time running out.\n",
        "\n",
        "     Close-up shot of a quick cat briskly walking in the park, it’s crafted entirely of glass, illuminated by dramatic lighting. Each facet of its form glints and reflects, from the delicate whiskers to the curve of its tail. Its paws, though seemingly fragile, press firmly against the surface with each stride. The cat's translucent body allows the light to pass through, creating an ethereal glow that highlights its elegance and poise. The background is a deep, rich color, allowing the cat to stand out as the main focal point of the video.\n",
        "\n",
        "     Cinematic shot of a lone surfer's silhouette, walking on a vast beach with surfboard in hand. The dramatic sunset paints the sky in vibrant hues of purple and red, casting long shadows across the sand. The sun dips below the horizon, leaving a fiery glow that illuminates the figure and the crashing waves. The wide shot captures the vastness of the scene, emphasizing the surfer's solitude and the awe-inspiring beauty of nature.\n",
        "\n",
        "     Extreme close-up of a woman's eyes, bathed in the vibrant glow of neon lights. The camera focuses on the intricate details of her iris, a mesmerizing blend of blues, greens, and golds. Her long, dark lashes cast delicate shadows on her skin, and a single tear glistens at the corner of her eye. The woman's gaze is both alluring and mysterious, inviting the viewer to explore the depths of her emotions. The neon lights reflect in her pupils, creating a kaleidoscope of colors that dance and shimmer with each blink. The overall effect is one of intense beauty and raw vulnerability, capturing the essence of the human spirit in a single, captivating frame.\n",
        "\n",
        "     A close-up shot of a man made entirely of glass riding the New York City subway. Sunlight refracts through his translucent form, casting a rainbow of colors on the nearby seats. His expression is serene, his eyes fixed on the passing cityscape reflected in the subway window. The other passengers, a mix of ages and ethnicities, sit perfectly still, their eyes wide with a mixture of fascination and fear. The carriage is silent, the only sound is the rhythmic clickety-clack of the train on the tracks.\n",
        "\n",
        "     Close-up cinematic shot of an Indian man in a crisp white suit, bathed in the warm glow of an orange neon sign. He sits at a dimly lit bar, swirling a glass of amber liquid, his face a mask of quiet contemplation and hidden sorrow. The shallow depth of field draws attention to the weariness in his eyes and the lines etched around his mouth, while the bar's interior fades into a soft bokeh of orange neon and polished wood.\n",
        "\n",
        "     A cinematic close-up frames the face of a young Asian woman in the heart of Tokyo's Shibuya Crossing. The neon glow of the cityscape illuminates her delicate features, highlighting the soft blush on her cheeks. Gentle lighting accentuates her bright, inquisitive eyes, reflecting the vibrant energy of the urban environment. A faint smile plays on her lips, hinting at a sense of anticipation and wonder. The blurred motion of pedestrians and vehicles in the background emphasizes her serene presence amidst the bustling metropolis. Her youthful expression captures a moment of fleeting beauty and the boundless possibilities that lie ahead.\n",
        "\n",
        "     Medium close-up shot of a distinguished dog in a tailored business suit, engrossed in a newspaper on a moving train. Neon lights flicker through the window, casting high-contrast shadows on the dog's face and emphasizing the low vibrance of the scene. The dog's brow is furrowed in concentration, its eyes scanning the newsprint with an air of intelligence and determination. The train's rhythmic motion rocks the dog gently, creating a subtle blur in the background that accentuates the dog's stillness and focus.\n",
        "\n",
        "     Tracking shot of a vibrant yellow convertible cruising through a scenic Nevada desert. An orange filter bathes the scene in warm, golden light, highlighting the dramatic rock formations and vast sandy expanse. The car speeds along a winding road, leaving a trail of dust in its wake. The open top allows the driver and passengers to fully experience the breathtaking landscape, their hair tousled by the wind. The low camera angle captures the car's sleek design and emphasizes the sense of freedom and adventure. The orange filter adds a touch of nostalgia and creates a visually stunning scene that evokes the spirit of the open road and the allure of the desert.\n",
        "\n",
        "     This street style shot captures two chic women strolling through the fashionable streets of Paris. The first woman exudes elegance in a pair of crisp white pants, a pastel pink blazer cinched with a black belt and oversized black sunglasses. The second woman radiates confidence in her yellow wide leg trousers and an oversized hot pink blouson accessorized with a chunky gold necklace. Both women carry luxurious handbags adding to their effortless sophistication. The backdrop of Parisian architecture and bustling city life complements their stylish ensembles, creating a picture perfect moment of Parisian chic.\n",
        "\n",
        "     Now, provide 4 different REWRITES for the following USER_QUERY in the style above using about 100 words each. Only produce the final four rewrites, one on each line, no intermediate thoughts. The rewrites should be distinct from each other, while following the user's intent.\n",
        "     Here's User_Query: {USER_QUERY}\n",
        "\n",
        "     * **Output Format:** Return your analysis as a JSON object with the following structure:\n",
        "       'prompt1': 'Text prompt for the first rewrite',\n",
        "       'prompt2': 'Text prompt for the second rewrite',\n",
        "\n",
        "     \"\"\"\n",
        "\n",
        "    contents = [types.Content(role=\"user\", parts=[types.Part.from_text(prompt)])]\n",
        "\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        temperature=1,\n",
        "        top_p=0.95,\n",
        "        max_output_tokens=8192,\n",
        "        response_modalities=[\"TEXT\"],\n",
        "        response_mime_type=\"application/json\",\n",
        "        # response_schema=response_schema,\n",
        "        safety_settings=[\n",
        "            types.SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
        "            types.SafetySetting(\n",
        "                category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"\n",
        "            ),\n",
        "            types.SafetySetting(\n",
        "                category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"\n",
        "            ),\n",
        "            types.SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        contents=contents,\n",
        "        config=generate_content_config,\n",
        "    )\n",
        "\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "executionInfo": {
          "elapsed": 173,
          "status": "ok",
          "timestamp": 1738018859653,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "-aox2jVdI3Rt"
      },
      "outputs": [],
      "source": [
        "USER_QUERY=\"\"\"An xgames snowboarder performs superpipe snowboarding Frontside 1080 trick at X Games Aspen.\n",
        "The snowboarder initiates a jump while facing downhill, then rotates their body and board a full three rotations (1080 degrees) in the air,\n",
        " at X Games Aspen\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3iWouoCI3Y6"
      },
      "outputs": [],
      "source": [
        "resp=create_veo_prompt(USER_QUERY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 156,
          "status": "ok",
          "timestamp": 1737781064304,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "_0PZhmIiI3dT",
        "outputId": "dca85050-adb6-4c1e-c890-d9ffce3daec2"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(json.loads(resp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "executionInfo": {
          "elapsed": 172,
          "status": "ok",
          "timestamp": 1737781086734,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "qhRHUmru6CHl",
        "outputId": "c4bd46fa-bc06-42ff-d955-15ff5fb9b78c"
      },
      "outputs": [],
      "source": [
        "prompt =json.loads(resp)['prompt2']\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "executionInfo": {
          "elapsed": 153,
          "status": "ok",
          "timestamp": 1737999734928,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "PSWGnN8aTyFq"
      },
      "outputs": [],
      "source": [
        "prompt =\"\"\"\n",
        " Generate a photorealistic 8-second video of Snowboard SuperPipe competition at X Games Aspen 2025. The video should capture the high-energy atmosphere and focus on a snowboarder successfully executing a complex Haakon Flip maneuver, followed by a roaring crowd reaction.\n",
        "Video Structure & Key Moments with Veo-Specific Instructions:\n",
        "(0-1s) Crowd Anticipation: Establishing Shot\n",
        "Visual: Close-up shot of a diverse and energetic crowd at the base of the halfpipe. Faces should display expressions of excitement, anticipation, and awe. Include authentic winter attire, visible breath in the cold air, and prominent Monster Energy branding (banners, clothing, etc.).\n",
        "Camera: Start with a tight close-up on individual faces, then gradually widen to reveal the larger crowd.\n",
        "Veo Instructions: \"Generate a close-up shot of a diverse crowd at a winter sporting event. Faces should show excitement and anticipation. Include details like winter clothing, visible breath, and Monster Energy branding. The shot should gradually widen to reveal a larger crowd scene. Resolution: 4K. Aspect ratio: 16:9. Lighting: Bright, natural winter daylight with potential for lens flares. Style: Photorealistic. Focus: Sharp focus on individual faces in the foreground with a gradual softening of focus towards the background. Crowd density: High. Duration: 1 second.\"\n",
        "Keywords: close-up, diverse crowd, anticipation, excitement, X Games Aspen 2025, Monster Energy, winter attire, visible breath, cold weather, detailed textures, 4K, 16:9, natural lighting, lens flare\n",
        "(1-2s) Dynamic Descent: The Drop-In\n",
        "Visual: A snowboarder drops into the halfpipe, gaining speed.\n",
        "Camera: Initiate a rapid camera movement that starts from a high, wide-angle, top-down perspective at the top of the pipe and quickly pans downwards, following the rider's descent into the halfpipe. The camera movement should create a sense of speed and dynamism.\n",
        "Veo Instructions: \"Generate a high, wide-angle, top-down view of a snowboarder at the top of a halfpipe. The snowboarder drops into the halfpipe. Initiate a fast camera pan that follows the snowboarder's descent. The camera movement should be smooth and dynamic. Duration: 1 second. Speed: Fast. Camera movement: Top-down to eye-level tracking pan. Perspective: Bird's-eye view transitioning to eye-level. Lighting: Natural winter daylight. Focus: Sharp focus on the snowboarder throughout the movement.\"\n",
        "Keywords: snowboarder, halfpipe, drop-in, fast camera pan, top-down view, wide-angle, dynamic movement, bird's-eye view, tracking shot, high speed, winter sports, X Games, 4K, 16:9, natural lighting\n",
        "(2-7s) The Haakon Flip: Slow-Motion Hero Moment\n",
        "Visual: This is the core of the video. Generate a highly-detailed slow-motion sequence of the snowboarder performing a perfect Haakon Flip.\n",
        "Haakon Flip Execution:\n",
        "Rider ascends the halfpipe wall, gaining height.\n",
        "At the peak, initiate a backside 180-degree rotation.\n",
        "Simultaneously, the snowboard flips up and over the rider's head (invert).\n",
        "The rider grabs the board with their hand during the mid-air rotation.\n",
        "The rider rotates back, completing the flip.\n",
        "Land smoothly on the opposite wall, facing forward.\n",
        "Camera: The camera should be positioned at a side-profile perspective, slightly below the athlete (worm's-eye view) to emphasize the height and full rotation of the trick. Maintain a tight focus on the snowboarder throughout the maneuver.\n",
        "Veo Instructions: \"Generate a slow-motion sequence of a snowboarder performing a Haakon Flip. Camera angle: Side-profile, slightly lower angle (worm's-eye view). Focus: Maintain tight focus on the snowboarder. Detail: High level of detail on the snowboarder's form, the board's movement, and the snow spray. The snowboarder should ascend the halfpipe wall, perform a backside 180, flip the board over their head, grab the board mid-air, complete the rotation, and land smoothly on the opposite wall. Duration: 5 seconds. Speed: Slow-motion (approximately 1/8 speed). Resolution: 4K. Style: Photorealistic. Lighting: Natural winter daylight with emphasis on the contrast between light and shadow to highlight the trick.\"\n",
        "Keywords: Haakon Flip, slow-motion, snowboard trick, mid-air, backside 180, invert, board grab, aerial maneuver, detailed, athletic, high-resolution, 4K, side-profile, worm's-eye view, snow spray, dynamic lighting, photorealistic, X Games\n",
        "(7-8s) Triumphant Landing\n",
        "Visual: The snowboarder lands the Haakon Flip perfectly, continuing down the halfpipe.\n",
        "Camera: Continue the side-profile, slightly lower angle, tracking the snowboarder as they land.\n",
        "Veo Instructions: \"Generate the landing of a snowboarder after performing a Haakon Flip. Camera angle: side-profile, slightly lower angle, tracking the rider. Focus on the smooth landing and continuation down the halfpipe. Duration: 1 second. Resolution: 4K. Lighting: Natural winter daylight.\"\n",
        "Keywords: snowboard landing, successful trick, smooth landing, halfpipe, side-profile, tracking shot, 4K, natural lighting\n",
        "(Final Moment): Freeze Frame\n",
        "Visual: Conclude with a freeze frame of the athlete at the apex of the Haakon Flip, captured from the side-profile, slightly lower angle, highlighting the athleticism and skill involved.\n",
        "Veo Instructions: \"Generate a still image (freeze frame) of a snowboarder at the peak of a Haakon Flip. Camera angle: Side-profile, slightly lower angle. Focus: Sharp focus on the snowboarder. Style: Iconic, poster-worthy. Resolution: 4K.\"\n",
        "Keywords: freeze frame, Haakon Flip, mid-air, iconic, side-profile, worm's-eye view, snowboarder, apex, skill, athleticism, 4K, poster image\n",
        "Overall Stylistic Guidance:\n",
        "Realism: Strive for ultra-photorealistic visuals throughout the video. Pay meticulous attention to details such as snow texture, lighting, reflections, clothing textures, human anatomy, and facial expressions.\n",
        "Color Palette: Vibrant and energetic, accurately reflecting the X Games atmosphere and Monster Energy branding (green, black, white).\n",
        "Lighting: Utilize realistic winter lighting conditions. Consider the possibility of lens flares from the sun reflecting off the snow, especially during the drop-in and slow-motion segments.\n",
        "Motion: Ensure that all movements are fluid, natural, and physically accurate, particularly during the complex slow-motion Haakon Flip.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd3dUZLv1Oam"
      },
      "source": [
        "### 1.2 Create prompt 2: rewrite prompt (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYOnyKtxzODL"
      },
      "outputs": [],
      "source": [
        "def rewrite_veo_prompt(USER_QUERY):\n",
        "    client = genai.Client(\n",
        "        vertexai=True, project=\"ace-chatbot-demo\", location=\"us-central1\"\n",
        "    )\n",
        "    #model = \"gemini-2.0-flash-exp\"\n",
        "    #model = \"gemini-1.5-pro-002\"\n",
        "    model = \"gemini-exp-1206\"\n",
        "    prompt = f\"\"\"\n",
        "     Please polish the following prompt: {USER_QUERY}\n",
        "     Please return prompt content only\n",
        "     \"\"\"\n",
        "\n",
        "    contents = [types.Content(role=\"user\", parts=[types.Part.from_text(prompt)])]\n",
        "\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        temperature=1,\n",
        "        top_p=0.95,\n",
        "        max_output_tokens=8192,\n",
        "        response_modalities=[\"TEXT\"],\n",
        "        #response_mime_type=\"application/json\",\n",
        "        # response_schema=response_schema,\n",
        "        safety_settings=[\n",
        "            types.SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
        "            types.SafetySetting(\n",
        "                category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"\n",
        "            ),\n",
        "            types.SafetySetting(\n",
        "                category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"\n",
        "            ),\n",
        "            types.SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        contents=contents,\n",
        "        config=generate_content_config,\n",
        "    )\n",
        "\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 33274,
          "status": "ok",
          "timestamp": 1737786058556,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "wWaXK3IhzOGX",
        "outputId": "45961dd7-4940-4a09-8b0d-45750405b141"
      },
      "outputs": [],
      "source": [
        "resp=rewrite_veo_prompt(prompt)\n",
        "pprint.pprint(resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KQ64m7w-43Z"
      },
      "outputs": [],
      "source": [
        "prompt =resp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7cYZuR3CSX2"
      },
      "source": [
        "# 2. Veo 2 REST API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "executionInfo": {
          "elapsed": 183,
          "status": "ok",
          "timestamp": 1738018870054,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "RbRpFDO6zOSh"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "create a video shows a snowboarder perfoming a perfect Haakon Flip at superpipe\n",
        "\n",
        "Haakon Flip Execution:\n",
        "-Rider ascends the halfpipe wall, gaining height.\n",
        "-At the peak, initiate a backside 180-degree rotation.\n",
        "-Simultaneously, the snowboard flips up and over the rider's head (invert).\n",
        "-The rider grabs the board with their hand during the mid-air rotation.\n",
        "-The rider rotates back, completing the flip.\n",
        "-Land smoothly on the opposite wall, facing forward.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hdc0GXUAeyO"
      },
      "source": [
        "### 2.1 Generate video from a text prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNVoSOPFAbII"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 193100,
          "status": "ok",
          "timestamp": 1738020860256,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "tygfLLlWyTo_",
        "outputId": "04d7127d-a2e0-4f91-8741-137f486cab0a"
      },
      "outputs": [],
      "source": [
        "#prompt = \"A xgames snowboarder dress as super hero with 'G' on chest, performs 'triple cork' in half pipe\"  # @param {type: 'string'}\n",
        "aspect_ratio = \"16:9\"  # @param [\"16:9\", \"9:16\"]\n",
        "#output_gcs = \"gs://ace-chatbot-demo-bucket\"  # @param {type: 'string'}\n",
        "output_gcs = \"gs://dw-veo2-testing\"  # @param {type: 'string'}\n",
        "negative_prompt = \"\"  # @param {type: 'string'}\n",
        "seed = 200\n",
        "sample_count = 1\n",
        "\n",
        "ttv = text_to_video(prompt, seed, aspect_ratio, sample_count, output_gcs, negative_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "executionInfo": {
          "elapsed": 17384,
          "status": "ok",
          "timestamp": 1738020930386,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "h14My7VQ7zou",
        "outputId": "da275a42-432b-4367-9eee-2327bd27a282"
      },
      "outputs": [],
      "source": [
        "show_video(ttv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2E_VJNEBMew"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6-ZuUMoKPCM"
      },
      "outputs": [],
      "source": [
        "# prompts =list(json.loads(resp).values())\n",
        "# for prompt in prompts:\n",
        "#     op = text_to_video(prompt, seed, aspect_ratio, sample_count, output_gcs, rewrite_prompt)\n",
        "#     show_video(op)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YysYLyiVj8Zd"
      },
      "source": [
        "### 2.2 Generate video from an image and text prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 193246,
          "status": "ok",
          "timestamp": 1738020558570,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "5gNxNj9N2R4o",
        "outputId": "25471c7b-3a5a-49c2-acd7-2bc2d76de552"
      },
      "outputs": [],
      "source": [
        "#prompt = \"\"  # @param {type: 'string'}\n",
        "image_gcs = \"gs://dw-veo2-testing/img1.png\"  # @param {type: 'string'}\n",
        "aspect_ratio = \"16:9\"  # @param [\"16:9\", \"9:16\"]\n",
        "output_gcs = \"gs://dw-veo2-testing\"  # @param {type: 'string'}\n",
        "negative_prompt = \"\"  # @param {type: 'string'}\n",
        "seed = 200\n",
        "sample_count = 1\n",
        "\n",
        "itv = image_to_video(\n",
        "    prompt, image_gcs, seed, aspect_ratio, sample_count, output_gcs, negative_prompt\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "executionInfo": {
          "elapsed": 158,
          "status": "ok",
          "timestamp": 1738020648543,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "FqDeAihl800v"
      },
      "outputs": [],
      "source": [
        "show_video(itv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs7LdfFKvO-Q"
      },
      "source": [
        "# 3. Python SDK (Internal project WIP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ggsbKkM4314"
      },
      "outputs": [],
      "source": [
        "#https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/veo-video-generation\n",
        "\n",
        "!gsutil cp gs://unified-genai-dev/alexey-veo/google_genai-0.5.0-py3-none-any.whl .\n",
        "#!gsutil ls gs://veo_genai_sdk/\n",
        "#!gsutil cp gs://veo_genai_sdk/google_genai-0.5.0-py3-none-any.whl .\n",
        "%pip uninstall -y google-genai\n",
        "%pip install google_genai-0.5.0-py3-none-any.whl\n",
        "\n",
        "# %pip install -q google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "executionInfo": {
          "elapsed": 1164,
          "status": "ok",
          "timestamp": 1737999717036,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "WWug-YAHOjj9"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from google.genai import types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1737999717036,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "__TNhkEB804V"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "vertex_client = genai.Client(\n",
        "    vertexai=True, project='veo-testing', location='us-central1'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "executionInfo": {
          "elapsed": 181,
          "status": "ok",
          "timestamp": 1737999706315,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "6VZq9aq32sGC"
      },
      "outputs": [],
      "source": [
        "import mediapy as media\n",
        "def show_sdk_video(op):\n",
        "    print(op)\n",
        "    if op.generate_videos_response.videos:\n",
        "        for video in op.generate_videos_response.videos:\n",
        "            gcs_uri = video.uri\n",
        "            file_name = gcs_uri.split(\"/\")[-1]\n",
        "            !gsutil cp {gcs_uri} {file_name}\n",
        "            media.show_video(media.read_video(file_name), height=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVibvVqW5H5r"
      },
      "outputs": [],
      "source": [
        "prompt =\"\"\"\n",
        " Generate a photorealistic 8-second video of Snowboard SuperPipe competition at X Games Aspen 2025. The video should capture the high-energy atmosphere and focus on a snowboarder successfully executing a complex Haakon Flip maneuver, followed by a roaring crowd reaction.\n",
        "Video Structure & Key Moments with Veo-Specific Instructions:\n",
        "(0-1s) Crowd Anticipation: Establishing Shot\n",
        "Visual: Close-up shot of a diverse and energetic crowd at the base of the halfpipe. Faces should display expressions of excitement, anticipation, and awe. Include authentic winter attire, visible breath in the cold air, and prominent Monster Energy branding (banners, clothing, etc.).\n",
        "Camera: Start with a tight close-up on individual faces, then gradually widen to reveal the larger crowd.\n",
        "Veo Instructions: \"Generate a close-up shot of a diverse crowd at a winter sporting event. Faces should show excitement and anticipation. Include details like winter clothing, visible breath, and Monster Energy branding. The shot should gradually widen to reveal a larger crowd scene. Resolution: 4K. Aspect ratio: 16:9. Lighting: Bright, natural winter daylight with potential for lens flares. Style: Photorealistic. Focus: Sharp focus on individual faces in the foreground with a gradual softening of focus towards the background. Crowd density: High. Duration: 1 second.\"\n",
        "Keywords: close-up, diverse crowd, anticipation, excitement, X Games Aspen 2025, Monster Energy, winter attire, visible breath, cold weather, detailed textures, 4K, 16:9, natural lighting, lens flare\n",
        "(1-2s) Dynamic Descent: The Drop-In\n",
        "Visual: A snowboarder drops into the halfpipe, gaining speed.\n",
        "Camera: Initiate a rapid camera movement that starts from a high, wide-angle, top-down perspective at the top of the pipe and quickly pans downwards, following the rider's descent into the halfpipe. The camera movement should create a sense of speed and dynamism.\n",
        "Veo Instructions: \"Generate a high, wide-angle, top-down view of a snowboarder at the top of a halfpipe. The snowboarder drops into the halfpipe. Initiate a fast camera pan that follows the snowboarder's descent. The camera movement should be smooth and dynamic. Duration: 1 second. Speed: Fast. Camera movement: Top-down to eye-level tracking pan. Perspective: Bird's-eye view transitioning to eye-level. Lighting: Natural winter daylight. Focus: Sharp focus on the snowboarder throughout the movement.\"\n",
        "Keywords: snowboarder, halfpipe, drop-in, fast camera pan, top-down view, wide-angle, dynamic movement, bird's-eye view, tracking shot, high speed, winter sports, X Games, 4K, 16:9, natural lighting\n",
        "(2-7s) The Haakon Flip: Slow-Motion Hero Moment\n",
        "Visual: This is the core of the video. Generate a highly-detailed slow-motion sequence of the snowboarder performing a perfect Haakon Flip.\n",
        "Haakon Flip Execution:\n",
        "Rider ascends the halfpipe wall, gaining height.\n",
        "At the peak, initiate a backside 180-degree rotation.\n",
        "Simultaneously, the snowboard flips up and over the rider's head (invert).\n",
        "The rider grabs the board with their hand during the mid-air rotation.\n",
        "The rider rotates back, completing the flip.\n",
        "Land smoothly on the opposite wall, facing forward.\n",
        "Camera: The camera should be positioned at a side-profile perspective, slightly below the athlete (worm's-eye view) to emphasize the height and full rotation of the trick. Maintain a tight focus on the snowboarder throughout the maneuver.\n",
        "Veo Instructions: \"Generate a slow-motion sequence of a snowboarder performing a Haakon Flip. Camera angle: Side-profile, slightly lower angle (worm's-eye view). Focus: Maintain tight focus on the snowboarder. Detail: High level of detail on the snowboarder's form, the board's movement, and the snow spray. The snowboarder should ascend the halfpipe wall, perform a backside 180, flip the board over their head, grab the board mid-air, complete the rotation, and land smoothly on the opposite wall. Duration: 5 seconds. Speed: Slow-motion (approximately 1/8 speed). Resolution: 4K. Style: Photorealistic. Lighting: Natural winter daylight with emphasis on the contrast between light and shadow to highlight the trick.\"\n",
        "Keywords: Haakon Flip, slow-motion, snowboard trick, mid-air, backside 180, invert, board grab, aerial maneuver, detailed, athletic, high-resolution, 4K, side-profile, worm's-eye view, snow spray, dynamic lighting, photorealistic, X Games\n",
        "(7-8s) Triumphant Landing\n",
        "Visual: The snowboarder lands the Haakon Flip perfectly, continuing down the halfpipe.\n",
        "Camera: Continue the side-profile, slightly lower angle, tracking the snowboarder as they land.\n",
        "Veo Instructions: \"Generate the landing of a snowboarder after performing a Haakon Flip. Camera angle: side-profile, slightly lower angle, tracking the rider. Focus on the smooth landing and continuation down the halfpipe. Duration: 1 second. Resolution: 4K. Lighting: Natural winter daylight.\"\n",
        "Keywords: snowboard landing, successful trick, smooth landing, halfpipe, side-profile, tracking shot, 4K, natural lighting\n",
        "(Final Moment): Freeze Frame\n",
        "Visual: Conclude with a freeze frame of the athlete at the apex of the Haakon Flip, captured from the side-profile, slightly lower angle, highlighting the athleticism and skill involved.\n",
        "Veo Instructions: \"Generate a still image (freeze frame) of a snowboarder at the peak of a Haakon Flip. Camera angle: Side-profile, slightly lower angle. Focus: Sharp focus on the snowboarder. Style: Iconic, poster-worthy. Resolution: 4K.\"\n",
        "Keywords: freeze frame, Haakon Flip, mid-air, iconic, side-profile, worm's-eye view, snowboarder, apex, skill, athleticism, 4K, poster image\n",
        "Overall Stylistic Guidance:\n",
        "Realism: Strive for ultra-photorealistic visuals throughout the video. Pay meticulous attention to details such as snow texture, lighting, reflections, clothing textures, human anatomy, and facial expressions.\n",
        "Color Palette: Vibrant and energetic, accurately reflecting the X Games atmosphere and Monster Energy branding (green, black, white).\n",
        "Lighting: Utilize realistic winter lighting conditions. Consider the possibility of lens flares from the sun reflecting off the snow, especially during the drop-in and slow-motion segments.\n",
        "Motion: Ensure that all movements are fluid, natural, and physically accurate, particularly during the complex slow-motion Haakon Flip.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JysZe5leBAl7"
      },
      "source": [
        "### 3.1 SDK text to video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 302623,
          "status": "ok",
          "timestamp": 1738000046264,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "reDa8AQP80_A",
        "outputId": "ecfb1a1f-91be-4f44-ad32-ca129df50e4c"
      },
      "outputs": [],
      "source": [
        "vertex_operation = vertex_client.models.generate_videos(\n",
        "    model=\"veo-2.0-generate-exp\",\n",
        "    prompt=prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "        # Optional:\n",
        "        # Only works on Veo2 models at this moment\n",
        "        # image=types.Image(\n",
        "        #     gcs_uri=\"gs://cloud-samples-data/vertex-ai/llm/prompts/landmark1.png\",\n",
        "        #     mime_type=\"image/png\",\n",
        "        # ),\n",
        "        # Only works on Veo2 models at this moment\n",
        "        # video=types.SourceVideo(\n",
        "        #     # FPS must match. The defaul FPS of generated videos is 24.\n",
        "        #     gcs_uri=\"gs://unified-genai-tests/tmp/genai/video/outputs/17473846688579026039/sample_0.mp4\"\n",
        "        # ),\n",
        "        output_gcs_uri=\"gs://dw-veo2-testing/outputs\",\n",
        "        number_of_videos=1,\n",
        "        fps=24,\n",
        "        duration_seconds=8,\n",
        "        seed=1,\n",
        "        aspect_ratio=\"16:9\",\n",
        "        resolution=\"720p\",\n",
        "        person_generation=\"allow_adult\",\n",
        "        negative_prompt=\"ugly, low quality\",\n",
        "    ),\n",
        ")\n",
        "print(vertex_operation)\n",
        "while not vertex_operation.done:\n",
        "    time.sleep(20)\n",
        "    vertex_operation = vertex_client.models.get_generate_videos_operation(vertex_operation.name)\n",
        "    print(vertex_operation)\n",
        "\n",
        "vertex_operation.generate_videos_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 156,
          "status": "ok",
          "timestamp": 1738000147867,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "LaSopk3SzM-B",
        "outputId": "a202b768-eb4f-4d1a-e60d-b5008ff80456"
      },
      "outputs": [],
      "source": [
        "vertex_operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "executionInfo": {
          "elapsed": 177,
          "status": "ok",
          "timestamp": 1738000648827,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "YqL3WbUT0kXf"
      },
      "outputs": [],
      "source": [
        "show_sdk_video(vertex_operation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RziZbCav4CUE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjooAV2aBFeO"
      },
      "source": [
        "### 3.2 SDK image to video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LGSZ78M4CXU"
      },
      "outputs": [],
      "source": [
        "# Image to video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "executionInfo": {
          "elapsed": 2257,
          "status": "ok",
          "timestamp": 1738000132183,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "6htPG4lZ4CaT",
        "outputId": "02f449c2-a881-4530-dd6b-5dadfa49b0e1"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project veo-testing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from google.cloud import storage\n",
        "\n",
        "# Initialize a GCS client\n",
        "storage_client = storage.Client(project='veo-testing')\n",
        "\n",
        "# Replace with your bucket and image file\n",
        "bucket_name = \"dw-veo2-testing\"\n",
        "image_blob_name = \"img1.png\"\n",
        "\n",
        "# Get the image blob\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "blob = bucket.blob(image_blob_name)\n",
        "\n",
        "# Download the image as bytes\n",
        "image_bytes = blob.download_as_bytes()\n",
        "\n",
        "# Open the image using PIL\n",
        "image = Image.open(BytesIO(image_bytes))\n",
        "\n",
        "# Display the image using matplotlib\n",
        "plt.imshow(image)\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 665198,
          "status": "ok",
          "timestamp": 1738010613961,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "WyHLVIhG4Cdk",
        "outputId": "93a7b746-3e30-4bf1-8a21-ad00b6d8760e"
      },
      "outputs": [],
      "source": [
        "# Image to video\n",
        "import time\n",
        "from google.genai import types\n",
        "\n",
        "vertex_operation3 = vertex_client.models.generate_videos(\n",
        "    model=\"veo-2.0-generate-exp\",\n",
        "    prompt=prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "        # Optional:\n",
        "        image=types.Image(\n",
        "            #gcs_uri=\"gs://cloud-samples-data/vertex-ai/llm/prompts/landmark1.png\",\n",
        "            gcs_uri=\"gs://dw-veo2-testing/img1.png\",\n",
        "            mime_type=\"image/jpg\",\n",
        "        ),\n",
        "        # video=types.SourceVideo(\n",
        "        #     # FPS must match. The defaul FPS of generated videos is 24.\n",
        "        #     uri=\"gs://dw-veo2-testing/sample_videos/mens_Kaishu Hirano_2_trick1_24fps.mp4\"\n",
        "        # ),\n",
        "        output_gcs_uri=\"gs://dw-veo2-testing/outputs\",\n",
        "        number_of_videos=1,\n",
        "        fps=24,\n",
        "        duration_seconds=8,\n",
        "        seed=1,\n",
        "        aspect_ratio=\"16:9\",\n",
        "        resolution=\"720p\",\n",
        "        person_generation=\"allow_adult\",\n",
        "        # pubsub_topic=\"projects/<my-project>/topics/video-generation-test\",\n",
        "        negative_prompt=\"ugly, low quality\",\n",
        "        #enable_prompt_rewriting=True\n",
        "    ),\n",
        ")\n",
        "print(vertex_operation3)\n",
        "while not vertex_operation3.done:\n",
        "    time.sleep(20)\n",
        "    vertex_operation3 = vertex_client.models.get_generate_videos_operation(vertex_operation3.name)\n",
        "    print(vertex_operation3)\n",
        "\n",
        "vertex_operation3.generate_videos_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "executionInfo": {
          "elapsed": 151,
          "status": "ok",
          "timestamp": 1738017780165,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "TWx647vx4Cgj"
      },
      "outputs": [],
      "source": [
        "show_sdk_video(vertex_operation3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mt5G4xeaSw7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYoSI87yaS0Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l46g0sTjaS3h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LINLREzHaS6p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6pIAUpdaS96"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# References\n",
        "1. Internal SDK: https://colab.sandbox.google.com/drive/1QhfpazPc6v7xfTd5ev-1fX1pr3IDGB8X?resourcekey=0-v9htEwMli1Jo1Bt-no79_g\n",
        "2. https://cloud.google.com/vertex-ai/generative-ai/docs/video/generate-videos\n",
        "3. https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/veo-video-generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgSwlvTNERyG"
      },
      "source": [
        "# Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "errz0rvhaTdE"
      },
      "source": [
        "# Re create videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "executionInfo": {
          "elapsed": 176,
          "status": "ok",
          "timestamp": 1738008569064,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "IWUMlPcuYcu2"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import json\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "import tempfile\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict\n",
        "import glob\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "\n",
        "import PIL\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "executionInfo": {
          "elapsed": 150,
          "status": "ok",
          "timestamp": 1738008300003,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "pTHiuowx4Cjk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "def get_frames_only(video_path, FRAME_DIR):\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  video_name = video_path.split('/')[-1]\n",
        "  video_prefix = video_name.split('.')[0]\n",
        "\n",
        "  frame_array = []\n",
        "  frame_number = 0\n",
        "\n",
        "  while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret == True:\n",
        "      cv2.imwrite(f'./{FRAME_DIR}/{video_prefix}_{frame_number}.jpg', frame)\n",
        "\n",
        "      frame_number += 1\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "executionInfo": {
          "elapsed": 156,
          "status": "ok",
          "timestamp": 1738008645741,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "VYBdcABM4Cme"
      },
      "outputs": [],
      "source": [
        "def sort_by_last_number(file_list):\n",
        "  \"\"\"Sorts a list of filenames by the last number in the filename.\n",
        "\n",
        "  Args:\n",
        "    file_list: A list of filenames.\n",
        "\n",
        "  Returns:\n",
        "    A new list of filenames, sorted by the last number.\n",
        "  \"\"\"\n",
        "  return sorted(file_list, key=lambda x: int(re.findall(r'\\d+', x)[-1]))\n",
        "\n",
        "\n",
        "def create_video_from_frames(frames_folder, output_video_path, fps=24):\n",
        "  \"\"\"\n",
        "  Creates a video from a sequence of image frames.\n",
        "\n",
        "  Args:\n",
        "    frames_folder: Path to the folder containing the image frames.\n",
        "    output_video_path: Path to the output video file (e.g., \"output.mp4\").\n",
        "    fps: Frames per second for the output video. Default is 30.\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    # Get a list of image files in the folder\n",
        "    image_file_list = [f for f in os.listdir(frames_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    image_files =  sort_by_last_number(image_file_list) # Make sure frames are in order\n",
        "\n",
        "    # Read the first image to get dimensions\n",
        "    first_frame = cv2.imread(os.path.join(frames_folder, image_files[0]))\n",
        "    height, width, layers = first_frame.shape\n",
        "\n",
        "    # Create a VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
        "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Write each image frame to the video\n",
        "    for image_file in image_files:\n",
        "      frame = cv2.imread(os.path.join(frames_folder, image_file))\n",
        "      video_writer.write(frame)\n",
        "\n",
        "    # Release the VideoWriter\n",
        "    video_writer.release()\n",
        "    print(f\"Video created: {output_video_path}\")\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error creating video: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "executionInfo": {
          "elapsed": 187,
          "status": "ok",
          "timestamp": 1738008573208,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "fSG8Guht4Cpk"
      },
      "outputs": [],
      "source": [
        "def list_files(folder_path, extension=\"\"):\n",
        "    \"\"\"Lists all image paths in a folder in alphabetical order.\n",
        "\n",
        "    Args:\n",
        "        folder_path: The path to the folder containing the images.\n",
        "\n",
        "    Returns:\n",
        "        A list of image paths sorted alphabetically.\n",
        "    \"\"\"\n",
        "    image_paths = sorted(glob.glob(os.path.join(folder_path, f\"*{extension}\")))  # or use \"*\" for all image types\n",
        "    return image_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFE75JNcZB_O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "executionInfo": {
          "elapsed": 177,
          "status": "ok",
          "timestamp": 1738008703525,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "9ijhIgdAZCDm"
      },
      "outputs": [],
      "source": [
        "def create_folder_if_not_exists(folder_path):\n",
        "  \"\"\"Creates a folder if it doesn't exist.\n",
        "\n",
        "  Args:\n",
        "    folder_path: The path to the folder to create.\n",
        "  \"\"\"\n",
        "  if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "    print(f\"Folder '{folder_path}' created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "executionInfo": {
          "elapsed": 179,
          "status": "ok",
          "timestamp": 1738008607959,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "CUnTHBoEYWpf",
        "outputId": "7cc5fa7d-b6b0-48af-86dd-6f293aab4571"
      },
      "outputs": [],
      "source": [
        "videos = list_files(\"/content/videos\")\n",
        "videos[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 161,
          "status": "ok",
          "timestamp": 1738008765219,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "BzQc8FQeZLbw",
        "outputId": "3361487c-9a24-4a3e-c904-890ce5656fd6"
      },
      "outputs": [],
      "source": [
        "video = videos[0]\n",
        "print(video.split(\"/\")[-1].split(\".\")[0])\n",
        "video_name = video.split(\"/\")[-1].split(\".\")[0]\n",
        "FRAME_DIR = f'ori/{video_name}/frames'\n",
        "\n",
        "\n",
        "create_folder_if_not_exists(FRAME_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "executionInfo": {
          "elapsed": 2008,
          "status": "ok",
          "timestamp": 1738008786223,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "1oGxzJvJY8Ck"
      },
      "outputs": [],
      "source": [
        "get_frames_only(videos[0], FRAME_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3805,
          "status": "ok",
          "timestamp": 1738008954569,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "oO6FYlLeZmRo",
        "outputId": "4b41a530-eee2-4eff-d760-35918bf1723d"
      },
      "outputs": [],
      "source": [
        "video_name = video.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "\n",
        "\n",
        "OUTPUT_VIDEO_PATH = '/content/output_videos'\n",
        "create_folder_if_not_exists(OUTPUT_VIDEO_PATH)\n",
        "create_folder_if_not_exists(OUTPUT_VIDEO_PATH + f\"/{video_name}\")\n",
        "\n",
        "\n",
        "# 24 fps\n",
        "fps = 24\n",
        "output_video_file = OUTPUT_VIDEO_PATH + f\"/{video_name}/{video_name}_{int(fps)}fps.mp4\"\n",
        "create_video_from_frames(FRAME_DIR, output_video_file, fps)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgMcuykSZmUr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvwlviCBZmYT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5UH4QngZmat"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "veo_2_video_generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
