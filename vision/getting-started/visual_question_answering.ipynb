{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxCkB_DXTHzf"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hny4I-ODTIS6"
   },
   "source": [
    "# Visual Question Answering (VQA) with Imagen on Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/visual_question_answering.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/visual_question_answering.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/visual_question_answering.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nLS57E2TO5y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[Imagen on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/image/overview) (image Generative AI) offers a variety of features:\n",
    "- Image generation\n",
    "- Image editing\n",
    "- Visual captioning\n",
    "- Visual question answering\n",
    "\n",
    "This notebook focuses on **visual question answering** only.\n",
    "\n",
    "[Visual question answering (VQA) with Imagen](https://cloud.google.com/vertex-ai/docs/generative-ai/image/visual-question-answering) can understand the content of an image and answer questions about it. The model takes in an image and a question as input, and then using the image as context to produce one or more answers to the question.\n",
    "\n",
    "The visual question answering (VQA) can be used for a variety of use cases, including:\n",
    "- assisting the visually impaired to gain more information about the images\n",
    "- answering customer questions about products or services in the image\n",
    "- creating interactive learning environment and providing interactive learning experiences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXsvgIuwTPZw"
   },
   "source": [
    "### Objectives\n",
    "\n",
    "In this notebook, you will learn how to use the Vertex AI Python SDK to:\n",
    "\n",
    "- Answering questions about images using the Imagen's visual question answering features\n",
    "\n",
    "- Experiment with different parameters, such as:\n",
    "    - number of answers to be provided by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skXAu__iqks_"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "- Vertex AI (Imagen)\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvKl-BtQTRiQ"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwFMpIMrTV_4"
   },
   "source": [
    "### Install Vertex AI SDK, other packages and their dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYUu8VMdJs3V",
    "outputId": "3c71c927-b71c-42d1-8f5e-57b816420588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --user google-cloud-aiplatform>=1.29.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### Restart current runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRvKdaPDTznN",
    "outputId": "154a71b5-f302-4f53-ed2f-b3e5fef9195b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "import time\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opUxT_k5TdgP"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, you will need to authenticate your environment. To do this, run the new cell below. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vbNgv4q1T2Mi"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybBXSukZkgjg"
   },
   "source": [
    "### Define Google Cloud project information (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, you need to define Google Cloud project information to be used. In the following cell, you will define the information, import Vertex AI package, and initialize it. This step is also not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MkVX07nOC90T"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    \n",
    "    # Define project information\n",
    "    PROJECT_ID = \"[your-project-id]\" # @param {type:\"string\"}\n",
    "    LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
    "    \n",
    "    # Initialize Vertex AI\n",
    "    import vertexai\n",
    "    vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhfneknwEDHT"
   },
   "source": [
    "### Load the image question answering model\n",
    "\n",
    "The model names from Vertex AI Imagen have two components: model name and version number. The naming convention follow this format: `<model-name>@<version-number>`. For example, `imagetext@001` represents the version **001** of the **imagetext** model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VuEbYyfM4RR7"
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.vision_models import ImageQnAModel\n",
    "\n",
    "image_qna_model = ImageQnAModel.from_pretrained(\"imagetext@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zoPQnQoED10"
   },
   "source": [
    "### Load the image file\n",
    "\n",
    "To use the image question answering model, you first need to create an `Image` class using the image file. The model only accepts `Image` class objects, so this is a necessary step before you can ask questions.\n",
    "\n",
    "\n",
    "Addtinally, [Visual Question Answering with Imagen](https://cloud.google.com/vertex-ai/docs/generative-ai/image/visual-question-answering#img-vqa-rest) only accepts specific image file formats (e.g. PNG, JPEG), and may have file size is limitations (e.g. 10 MB). You can find out specific details from the [official documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/image/visual-question-answering#img-vqa-rest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-6xS6twAN4y",
    "outputId": "7fbea20e-75a0-45a2-8434-3ffb5e6536f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://github-repo/img/vision/google-cloud-next.jpeg...\n",
      "/ [1 files][240.3 KiB/240.3 KiB]                                                \n",
      "Operation completed over 1 objects/240.3 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# Download an image from Google Cloud Storage\n",
    "\n",
    "! gsutil cp \"gs://github-repo/img/vision/google-cloud-next.jpeg\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 777
    },
    "id": "xnH-MARxgGrX",
    "outputId": "682e6b8d-6c9f-4464-992e-2f15e1a6485b"
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.vision_models import Image\n",
    "\n",
    "# Load the image file as Image object\n",
    "cloud_next_image = Image.load_from_file(\"google-cloud-next.jpeg\")\n",
    "cloud_next_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYjS3nL5LTbY"
   },
   "source": [
    "### Ask questions about the image\n",
    "\n",
    "Now ask questions about the image using the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3FliDlsm6ah",
    "outputId": "ac01f0bb-31c0-481b-e211-73e06c413897"
   },
   "outputs": [],
   "source": [
    "# Ask a question about the image\n",
    "image_qna_model.ask_question(\n",
    "  image=cloud_next_image,\n",
    "  question=\"What is happening in this image?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVFKttepEPB9",
    "outputId": "3e16b46e-2761-48aa-dba1-467b3a0b583d"
   },
   "outputs": [],
   "source": [
    "# Ask a follow up question about the image\n",
    "image_qna_model.ask_question(\n",
    "    image=cloud_next_image,\n",
    "    question=\"What are the people in the image doing?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwBBeYNORmTf"
   },
   "source": [
    "You can get up to three answers from a single image by changing the `number_of_results` parameter from 1 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1GJwlZUt4-E",
    "outputId": "f3fbdf53-d7f8-4363-c704-af357944257d"
   },
   "outputs": [],
   "source": [
    "# Get 3 answers from the image\n",
    "image_qna_model.ask_question(\n",
    "    image=cloud_next_image,\n",
    "    question=\"What are the people in the image doing?\",\n",
    "    number_of_results=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0FVAjg-okiW"
   },
   "source": [
    "## Try it yourself\n",
    "\n",
    "You can also try using the visual question answering model with images of your choice. If you need to download an image file, you can use the provided auxiliary function `download_image`.\n",
    "\n",
    "Feel free to experiment with different images and model parameters to see how the results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAytTFqoINyl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download_image(url):\n",
    "    \"\"\"Downloads an image from the specified URL.\"\"\"\n",
    "\n",
    "    # Send a get request to the url\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # If the request is successful\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        # Define image related variables\n",
    "        image_path = os.path.basename(url)\n",
    "        image_bytes = response.content\n",
    "        image_type = response.headers['Content-Type'].split('/')[1]\n",
    "\n",
    "        # Check for image type, currently only PNG or JPEG format are supported\n",
    "        if image_type in (\"png\", \"jpg\", \"jpeg\"):\n",
    "\n",
    "            # Write image data to a file\n",
    "            with open(image_path, \"wb\") as f:\n",
    "                f.write(image_bytes)\n",
    "            return image_path\n",
    "        else:\n",
    "            raise Exception(\"Image can only be in PNG or JPEG format\")\n",
    "\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download image from {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ll8KFbCujQ9y",
    "outputId": "1d412537-34dc-418b-a74a-cef379dfb79f"
   },
   "outputs": [],
   "source": [
    "# Download an image\n",
    "url = \"https://storage.googleapis.com/gweb-cloudblog-publish/images/GettyImages-871168786.max-2600x2600.jpg\"\n",
    "image_path = download_image(url)\n",
    "\n",
    "# Load the newly downloaded image\n",
    "user_image = Image.load_from_file(image_path)\n",
    "user_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9g6DsfKWo5S-",
    "outputId": "a3822c37-2062-4f89-c667-e2027b062ffd"
   },
   "outputs": [],
   "source": [
    "# Ask a question about the image\n",
    "image_qna_model.ask_question(\n",
    "    image=user_image,\n",
    "    question=\"What is happening in this photo?\",\n",
    "    number_of_results=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YC90LG50Fcru",
    "outputId": "63dcd584-1f95-4086-bc72-8b43e8d2e8ec"
   },
   "outputs": [],
   "source": [
    "# Ask a question about the image\n",
    "image_qna_model.ask_question(\n",
    "    image=user_image,\n",
    "    question=\"What advertising channels would this image be suitable for?\",\n",
    "    number_of_results=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydXxZJvLKvtI",
    "outputId": "d51144c0-09b0-4b10-c7ff-0edc0fe3f40f"
   },
   "outputs": [],
   "source": [
    "# Ask a question about the image\n",
    "image_qna_model.ask_question(\n",
    "      image=user_image,\n",
    "      question=\"What type of insects could live in this area?\",\n",
    "      number_of_results=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
