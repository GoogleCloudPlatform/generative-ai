{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxCkB_DXTHzf"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hny4I-ODTIS6"
      },
      "source": [
        "# Image Segmentation on Vertex AI\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/image_segmentation.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fvision%2Fgetting-started%2Fimage_segmentation.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/vision/getting-started/image_segmentation.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/image_segmentation.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/image_segmentation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/image_segmentation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/image_segmentation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/X_logo_2023_original.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/image_segmentation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/image_segmentation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHQ6zSOLt102"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author | [Jorj Ismailyan](https://github.com/jismailyan-google) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nLS57E2TO5y"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Vertex Image Segmentation brings Google's state of the art segmentation models to developers as a scalable and reliable service.\n",
        "\n",
        "With Image Segmentation, developers can choose from five different modes to segment images and build AI products, including with a **text prompt** and **interactive** mode.\n",
        "\n",
        "Learn more about [Image Segmentation on Vertex](https://docs.google.com/document/d/1y5H_m29zGM3Xt6ba2lMw_di6bpbvtQagpU-xY30Kx78/edit?resourcekey=0-_-4WVkfl0oS3nfBwIEhWWQ&tab=t.0).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXsvgIuwTPZw"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this notebook, you will be exploring the features of Vertex Image Segmentation using the Vertex AI Python SDK. You will\n",
        "\n",
        "- Segment the foreground or background of an object\n",
        "  - Create a product image by removing the background\n",
        "  - Change the background color of an image\n",
        "- Control the generated mask by configuring dilation\n",
        "- Use an open-vocabulary text prompt to perform:\n",
        "  - Object detection\n",
        "  - Instance segmentation\n",
        "- Draw a scribble to guide segmentation\n",
        "  - Perform point-to-mask segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skXAu__iqks_"
      },
      "source": [
        "### Costs\n",
        "\n",
        "- This notebook uses billable components of Google Cloud:\n",
        "  - Vertex AI\n",
        "\n",
        "- Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvKl-BtQTRiQ"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-UOCMvJdmlq"
      },
      "source": [
        "### Install Vertex AI SDK for Python (Jupyter only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5lOntr-doIT"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --user google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tuaVGUJdsMm"
      },
      "source": [
        "### Restart runtime (Jupyter only)\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAp-TR9mdqw2"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opUxT_k5TdgP"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbNgv4q1T2Mi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybBXSukZkgjg"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and enable the Vertex AI API.\n",
        "\n",
        "Learn more about setting up a project and a development environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q7YvbXXdtzDT"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform.gapic import PredictResponse\n",
        "\n",
        "PROJECT_ID = \"<your-project-id-here>\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param [\"asia-northeast1\", \"asia-northeast3\", \"asia-southeast1\", \"europe-west1\", \"europe-west2\", \"europe-west3\", \"europe-west4\", \"europe-west9\", \"northamerica-northeast1\", \"us-central1\", \"us-east4\", \"us-west1\", \"us-west4\"]\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "api_regional_endpoint = f\"{LOCATION}-aiplatform.googleapis.com\"\n",
        "client_options = {\"api_endpoint\": api_regional_endpoint}\n",
        "client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
        "\n",
        "model_endpoint = f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/image-segmentation-001\"\n",
        "print(f\"Prediction client initiated on project {PROJECT_ID} in {LOCATION}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju_PctW22NUl"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "\n",
        "# @title Import libraries\n",
        "# @markdown Run this cell before proceeding to import libraries and define utility functions.\n",
        "import io\n",
        "import random\n",
        "import timeit\n",
        "\n",
        "from IPython.display import display\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Parses the generated mask bytes from the response prediction and converts it\n",
        "# to an Image PIL object.\n",
        "def prediction_to_mask_pil(prediction) -> Image:\n",
        "    encoded_mask_string = prediction[\"bytesBase64Encoded\"]\n",
        "    mask_bytes = base64.b64decode(encoded_mask_string)\n",
        "    mask_pil = Image.open(io.BytesIO(mask_bytes))\n",
        "    mask_pil.thumbnail((640, 640))\n",
        "    return mask_pil\n",
        "\n",
        "\n",
        "# Extracts masks from the response and overlays them onto the base image.\n",
        "def overlay(input_image: Image, response: PredictResponse) -> Image:\n",
        "    # Make the original image colors grayscale so the overlayed masks are easier to see\n",
        "    overlayed_image = INPUT_IMAGE_PIL.copy().convert(\"L\").convert(\"RGB\")\n",
        "\n",
        "    for prediction in response.predictions:\n",
        "        mask_pil = prediction_to_mask_pil(prediction)\n",
        "\n",
        "        # Gives the mask a distinct color and makes the background transparent\n",
        "        color = (\n",
        "            random.randint(0, 255),\n",
        "            random.randint(0, 255),\n",
        "            random.randint(0, 255),\n",
        "            128,\n",
        "        )\n",
        "        colored_mask = Image.new(\"RGBA\", mask_pil.size, color)\n",
        "        colored_mask = Image.composite(\n",
        "            colored_mask, Image.new(\"RGBA\", mask_pil.size), mask_pil\n",
        "        )\n",
        "\n",
        "        # Pastes the colored mask onto the result image\n",
        "        overlayed_image.paste(colored_mask, (0, 0), colored_mask)\n",
        "\n",
        "    return overlayed_image\n",
        "\n",
        "\n",
        "# Displays a PIL image horizontally next to a generated mask from the response.\n",
        "def display_horizontally(\n",
        "    input_images: list, mask_index: int = -1, figsize: tuple[int, int] = (15, 15)\n",
        "):\n",
        "    count = len(input_images)\n",
        "    fig, ax = plt.subplots(1, count, figsize=figsize)\n",
        "\n",
        "    for i in range(count):\n",
        "        cmap = \"gray\" if i == mask_index else None\n",
        "        ax[i].imshow(input_images[i], cmap)\n",
        "        ax[i].axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Generates a transparent PNG image from an input image and its generated mask.\n",
        "def generate_transparent_image(image_pil: str, mask_pil: Image) -> Image:\n",
        "    transparent_image = Image.new(\"RGBA\", image_pil.size, (128, 128, 128, 255))\n",
        "\n",
        "    transparent_image.paste(image_pil, mask=mask_pil)\n",
        "    transparent_image.putalpha(mask_pil)\n",
        "    return transparent_image\n",
        "\n",
        "\n",
        "def draw_bounding_boxes(base_image: Image, response: PredictResponse):\n",
        "    bbox_image = base_image.copy()\n",
        "    labeled_boxes = get_labeled_boxes(response)\n",
        "    color = \"red\"\n",
        "    draw = ImageDraw.Draw(bbox_image)\n",
        "    for box in labeled_boxes:\n",
        "        bounding_box = box[2]\n",
        "        draw.rectangle(bounding_box, outline=color, width=2)\n",
        "\n",
        "        font = ImageFont.load_default_imagefont()\n",
        "        text_label = f\"{box[0]}: {box[1]}\"\n",
        "        text_width = draw.textlength(text_label, font=font) + 3  # Add 2 for padding\n",
        "        text_height = 12\n",
        "        label_x = bounding_box[0]\n",
        "        label_y = bounding_box[1] - text_height - 2  # Position label above the box\n",
        "\n",
        "        # Draw a filled rectangle as the background for the label\n",
        "        draw.rectangle(\n",
        "            (label_x, label_y, label_x + text_width, label_y + text_height),\n",
        "            fill=color,\n",
        "        )\n",
        "        draw.text((label_x + 2, label_y), text_label, fill=\"white\", font=font)\n",
        "\n",
        "    return bbox_image\n",
        "\n",
        "\n",
        "def get_prediction_top_label(prediction) -> str:\n",
        "    # Labels returned on a single prediction are sorted by score.\n",
        "    label = prediction[\"labels\"][0][\"label\"]\n",
        "    score = prediction[\"labels\"][0][\"score\"]\n",
        "    return label, score\n",
        "\n",
        "\n",
        "# Calculates the bounding box of the masked area in a mask image.\n",
        "def get_bounding_box(mask: Image) -> tuple | None:\n",
        "    mask_array = mask.convert(\"1\").getdata()\n",
        "    width, height = mask.size\n",
        "    x1, y1, x2, y2 = width, height, 0, 0\n",
        "\n",
        "    for y in range(height):\n",
        "        for x in range(width):\n",
        "            if mask_array[y * width + x]:  # If pixel is white\n",
        "                x1 = min(x1, x)\n",
        "                y1 = min(y1, y)\n",
        "                x2 = max(x2, x)\n",
        "                y2 = max(y2, y)\n",
        "\n",
        "    if x1 > x2 or y1 > y2:\n",
        "        return None  # No masked area found\n",
        "    else:\n",
        "        return (x1, y1, x2 + 1, y2 + 1)  # Add 1 to include the last pixel\n",
        "\n",
        "\n",
        "def get_labeled_boxes(response: PredictResponse) -> list:\n",
        "    labeled_boxes = []\n",
        "    for prediction in response.predictions:\n",
        "        mask_pil = prediction_to_mask_pil(prediction)\n",
        "        bounding_box = get_bounding_box(mask_pil)\n",
        "        if bounding_box:\n",
        "            label, score = get_prediction_top_label(prediction)\n",
        "            score = round(float(score), 3)\n",
        "            labeled_box = (label, score, bounding_box)\n",
        "            labeled_boxes.append(labeled_box)\n",
        "\n",
        "    return labeled_boxes\n",
        "\n",
        "\n",
        "# Constructs a Vertex AI PredictRequest and uses it to call Image Segmentation.\n",
        "def call_vertex_image_segmentation(\n",
        "    image_bytes=None,\n",
        "    gcs_uri=None,\n",
        "    mime_type=None,\n",
        "    mode=\"foreground\",\n",
        "    prompt=None,\n",
        "    scribble_bytes=None,\n",
        "    mask_dilation=None,\n",
        "    max_predictions=None,\n",
        "    confidence_threshold=None,\n",
        "):\n",
        "    instances = []\n",
        "\n",
        "    if image_bytes:\n",
        "        instances.append(\n",
        "            {\n",
        "                \"image\": {\n",
        "                    \"bytesBase64Encoded\": image_bytes,\n",
        "                    \"mimeType\": mime_type,\n",
        "                },\n",
        "            }\n",
        "        )\n",
        "    elif gcs_uri:\n",
        "        instances.append(\n",
        "            {\n",
        "                \"image\": {\"gcsUri\": gcs_uri},\n",
        "            }\n",
        "        )\n",
        "\n",
        "    if scribble_bytes:\n",
        "        instances[0][\"scribble\"] = {\n",
        "            \"image\": {\n",
        "                \"bytesBase64Encoded\": scribble_bytes,\n",
        "                \"mimeType\": \"image/png\",\n",
        "            },\n",
        "        }\n",
        "\n",
        "    if prompt:\n",
        "        instances[0][\"prompt\"] = prompt\n",
        "\n",
        "    parameters = {\"mode\": mode}\n",
        "\n",
        "    if mask_dilation:\n",
        "        parameters[\"maskDilation\"] = mask_dilation\n",
        "    if max_predictions:\n",
        "        parameters[\"maxPredictions\"] = max_predictions\n",
        "    if confidence_threshold:\n",
        "        parameters[\"confidenceThreshold\"] = confidence_threshold\n",
        "\n",
        "    start = timeit.default_timer()\n",
        "    response = client.predict(\n",
        "        endpoint=model_endpoint, instances=instances, parameters=parameters\n",
        "    )\n",
        "    end = timeit.default_timer()\n",
        "    print(f\"Vertex Image Segmentation took {end - start:.2f}s.\")\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R45VRKWInfQQ"
      },
      "source": [
        "## Select an image to segment\n",
        "\n",
        "Run this cell to enable and select the `Choose files` button.\n",
        "You can then select an image file from your local device to upload.\n",
        "Large images are resized to a maximum dimension of 640 pixels for faster processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9caIrZ7Dek1"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "images = files.upload()\n",
        "RAW_IMAGE_BYTES = list(images.values())[0]\n",
        "ENCODED_IMAGE_BYTES = base64.b64encode(RAW_IMAGE_BYTES).decode(\"utf-8\")\n",
        "INPUT_IMAGE_PIL = Image.open(io.BytesIO(RAW_IMAGE_BYTES)).convert(\"RGB\")\n",
        "INPUT_IMAGE_PIL.thumbnail((640, 640))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(INPUT_IMAGE_PIL)\n",
        "\n",
        "print(\n",
        "    f\"image size(with x height): {INPUT_IMAGE_PIL.size[0]} x {INPUT_IMAGE_PIL.size[1]}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU32286ooc8Q"
      },
      "source": [
        "## Segment images using different modes\n",
        "\n",
        "You can generate image masks with different Image Segmentation features by setting the `mode` field to one of the available options:\n",
        "* **Foreground**: Generate a mask of the segmented foreground of the image.\n",
        "* **Background**: Generate a mask of the segmented background of the image.\n",
        "* **Semantic**: Select the items in an image to segment from a set of 194 classes.\n",
        "* **Prompt**: Use an open-vocabulary text prompt to guide the image segmentation.\n",
        "* **Interactive**: Draw a rough mask to guide the model segmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBLJtICO8iMQ"
      },
      "source": [
        "### Foreground segmentation request\n",
        "\n",
        "This section will explores how to edit images using different `edit_mode` and `mask_mode` parameter options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9N8l0oo_cWs"
      },
      "outputs": [],
      "source": [
        "image_bytes = ENCODED_IMAGE_BYTES  # Base64 encoded input image bytes\n",
        "gcs_uri = None  # gs:// path to the input image\n",
        "mime_type = None  # Image file type (JPEG, PNG, WEBP)\n",
        "mode = \"foreground\"  # Segmentation mode [foreground,background,semantic,prompt,interactive]\n",
        "prompt = None  # Prompt to guide segmentation for `semantic` and `prompt` modes\n",
        "scribble_bytes = None  # Input scribble for `interactive` segment mode\n",
        "mask_dilation = (\n",
        "    None  # Optional mask dilation for thin objects. Numeric value between 0 and 1.\n",
        ")\n",
        "max_predictions = (\n",
        "    None  # Optional maximum predictions limit for prompt mode. Unlimited by default.\n",
        ")\n",
        "confidence_threshold = (\n",
        "    None  # Optional confidence limit for prompt/background/foreground modes.\n",
        ")\n",
        "\n",
        "response = call_vertex_image_segmentation(\n",
        "    image_bytes,\n",
        "    gcs_uri,\n",
        "    mime_type,\n",
        "    mode,\n",
        "    prompt,\n",
        "    scribble_bytes,\n",
        "    mask_dilation,\n",
        "    max_predictions,\n",
        "    confidence_threshold,\n",
        ")\n",
        "\n",
        "MASK_PIL = prediction_to_mask_pil(response.predictions[0])\n",
        "display_horizontally([INPUT_IMAGE_PIL, MASK_PIL], mask_index=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5yLGWLwOVIJ"
      },
      "source": [
        "#### Background removal\n",
        "Use the foreground segmentation mask you created above to make the image background transparent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5K0CSb0twPO"
      },
      "outputs": [],
      "source": [
        "# Creates an empty transparent background.\n",
        "transparent_background = Image.new(\"RGBA\", INPUT_IMAGE_PIL.size, (128, 128, 128, 255))\n",
        "\n",
        "# Uses the mask to cut and paste the foreground object in the original image\n",
        "# onto the transparent background.\n",
        "transparent_background.paste(INPUT_IMAGE_PIL, mask=MASK_PIL)\n",
        "transparent_background.putalpha(MASK_PIL)\n",
        "\n",
        "display(transparent_background)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEUZeTtyO01R"
      },
      "source": [
        "#### Change background color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-WiqiFJO448"
      },
      "outputs": [],
      "source": [
        "# RGBA color light blue\n",
        "color = (141, 224, 254, 255)\n",
        "input_image = INPUT_IMAGE_PIL.copy()\n",
        "gray_background = Image.new(\"RGBA\", input_image.size, color)\n",
        "gray_background.paste(input_image, mask=MASK_PIL)\n",
        "\n",
        "display(gray_background)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--7rofOb95hT"
      },
      "source": [
        "### Background segment mode\n",
        "\n",
        "Generate background masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVtC3lFAGoAu"
      },
      "outputs": [],
      "source": [
        "response = call_vertex_image_segmentation(\n",
        "    image_bytes=ENCODED_IMAGE_BYTES,\n",
        "    gcs_uri=None,\n",
        "    mime_type=None,\n",
        "    mode=\"background\",\n",
        "    prompt=None,\n",
        "    scribble_bytes=None,\n",
        "    mask_dilation=None,\n",
        "    max_predictions=None,\n",
        "    confidence_threshold=None,\n",
        ")\n",
        "\n",
        "MASK_PIL = prediction_to_mask_pil(response.predictions[0])\n",
        "display_horizontally([INPUT_IMAGE_PIL, MASK_PIL], mask_index=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9pfcnNsGtcv"
      },
      "source": [
        "### Semantic segment mode\n",
        "\n",
        "Specify the objects to segment from the set of 194 classes. The full set is available in the Appendix section at the end of this tutorial. You can specify multiple classes by delimiting with commas, e.g. `prompt=\"cat, dog\"`\n",
        "\n",
        "The semantic segmenter will return a single prediction containing the generated mask. If the classes in the prompt are detected, they are masked in white pixels and the background will be black. If the requested classes are not detected in the image, the whole mask will be black."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aar3Pn3yG75T"
      },
      "outputs": [],
      "source": [
        "mode = \"semantic\"\n",
        "prompt = \"motorcycle, bus\"\n",
        "\n",
        "response = call_vertex_image_segmentation(\n",
        "    image_bytes=ENCODED_IMAGE_BYTES,\n",
        "    gcs_uri=None,\n",
        "    mime_type=None,\n",
        "    mode=mode,\n",
        "    prompt=prompt,\n",
        "    scribble_bytes=None,\n",
        "    mask_dilation=None,\n",
        "    max_predictions=None,\n",
        "    confidence_threshold=None,\n",
        ")\n",
        "\n",
        "MASK_PIL = prediction_to_mask_pil(response.predictions[0])\n",
        "display_horizontally([INPUT_IMAGE_PIL, MASK_PIL], mask_index=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO4q2sacIydg"
      },
      "source": [
        "### Prompt instance segmentation mode\n",
        "\n",
        "You can use Prompt mode to perform detection and segmentation on many instances of your suggested objects. The response can generate multiple masks, along with one or more associated labels for each mask. Each label also contains an confidence score. Only objects matching labels specified in the request prompt are detected and segmented. The prompt is completely open-vocabulary, it is not limited to any class set.\n",
        "\n",
        "**Recommended**:\n",
        "* Use the confidence_threshold and max_predictions parameters to filter and limit results\n",
        "* You can request multiple items be detected by separating them with commas. Hundreds of classes can be set in a single prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unrHSqhqHmlI"
      },
      "outputs": [],
      "source": [
        "mode = \"prompt\"\n",
        "prompt = \"green watermelon, cantaloupe, price tag\"\n",
        "confidence_threshold = 0.1\n",
        "max_predictions = None\n",
        "\n",
        "response = call_vertex_image_segmentation(\n",
        "    image_bytes=ENCODED_IMAGE_BYTES,\n",
        "    gcs_uri=None,\n",
        "    mime_type=None,\n",
        "    mode=mode,\n",
        "    prompt=prompt,\n",
        "    scribble_bytes=None,\n",
        "    mask_dilation=None,\n",
        "    max_predictions=max_predictions,\n",
        "    confidence_threshold=confidence_threshold,\n",
        ")\n",
        "\n",
        "print(f\"Number of predictions is {str(len(response.predictions))}\")\n",
        "\n",
        "bbox_image = draw_bounding_boxes(INPUT_IMAGE_PIL, response)\n",
        "overlayed_image = overlay(INPUT_IMAGE_PIL, response)\n",
        "display_horizontally([INPUT_IMAGE_PIL, bbox_image, overlayed_image], figsize=(25, 25))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk0eXjQ1nR4F"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "You have explored the Vertex AI's Image Segmentation service and its features.\n",
        "\n",
        "Check out the Vertex AI reference to learn more about how to [Segment images](https://cloud.google.com/vertex-ai/generative-ai/docs/image/img-gen-prompt-guide#edit-prompts)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuaLTarf-hvO"
      },
      "source": [
        "## Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZzRAwQ0dIjT"
      },
      "source": [
        "### Semantic segmentation classes\n",
        "\n",
        "| Class ID | Class ID | Class ID | Class ID |\n",
        "| --- | --- | --- | --- |\n",
        "|   backpack  |   broccoli  |   road  |   mountain_hill   |\n",
        "|   umbrella  |   carrot  |   snow  |   rock    |\n",
        "|   bag |   hot_dog |   sidewalk_pavement |   frisbee   |\n",
        "|   tie |   pizza |   runway  |   skis    |\n",
        "|   suitcase  |   donut |   terrain |   snowboard   |\n",
        "|   case  |   cake  |   book  |   sports_ball   |\n",
        "|   bird  |   fruit_other |   box |   kite    |\n",
        "|   cat |   food_other  |   clock |   baseball_bat    |\n",
        "|   dog |   chair_other |   vase  |   baseball_glove    |\n",
        "|   horse |   armchair  |   scissors  |   skateboard    |\n",
        "|   sheep |   swivel_chair  |   plaything_other |   surfboard   |\n",
        "|   cow |   stool |   teddy_bear  |   tennis_racket   |\n",
        "|   elephant  |   seat  |   hair_dryer  |   net   |\n",
        "|   bear  |   couch |   toothbrush  |   base    |\n",
        "|   zebra |   trash_can |   painting  |   sculpture   |\n",
        "|   giraffe |   potted_plant  |   poster  |   column    |\n",
        "|   animal_other  |   nightstand  |   bulletin_board  |   fountain    |\n",
        "|   microwave |   bed |   bottle  |   awning    |\n",
        "|   radiator  |   table |   cup |   apparel   |\n",
        "|   oven  |   pool_table  |   wine_glass  |   banner    |\n",
        "|   toaster |   barrel  |   knife |   flag    |\n",
        "|   storage_tank  |   desk  |   fork  |   blanket   |\n",
        "|   conveyor_belt |   ottoman |   spoon |   curtain_other   |\n",
        "|   sink  |   wardrobe  |   bowl  |   shower_curtain    |\n",
        "|   refrigerator  |   crib  |   tray  |   pillow    |\n",
        "|   washer_dryer  |   basket  |   range_hood  |   towel   |\n",
        "|   fan |   chest_of_drawers  |   plate |   rug_floormat    |\n",
        "|   dishwasher  |   bookshelf |   person  |   vegetation    |\n",
        "|   toilet  |   counter_other |   rider_other |   bicycle   |\n",
        "|   bathtub |   bathroom_counter  |   bicyclist |   car   |\n",
        "|   shower  |   kitchen_island  |   motorcyclist  |   autorickshaw    |\n",
        "|   tunnel  |   door  |   paper |   motorcycle    |\n",
        "|   bridge  |   light_other |   streetlight |   airplane    |\n",
        "|   pier_wharf  |   lamp  |   road_barrier  |   bus   |\n",
        "|   tent  |   sconce  |   mailbox |   train   |\n",
        "|   building  |   chandelier  |   cctv_camera |   truck   |\n",
        "|   ceiling |   mirror  |   junction_box  |   trailer   |\n",
        "|   laptop  |   whiteboard  |   traffic_sign  |   boat_ship   |\n",
        "|   keyboard  |   shelf |   traffic_light |   slow_wheeled_object   |\n",
        "|   mouse |   stairs  |   fire_hydrant  |   river_lake    |\n",
        "|   remote  |   escalator |   parking_meter |   sea   |\n",
        "|   cell phone  |   cabinet |   bench |   water_other   |\n",
        "|   television  |   fireplace |   bike_rack |   swimming_pool   |\n",
        "|   floor |   stove |   billboard |   waterfall   |\n",
        "|   stage |   arcade_machine  |   sky |   wall    |\n",
        "|   banana  |   gravel  |   pole  |   window    |\n",
        "|   apple |   platform  |   fence |   window_blind    |\n",
        "|   sandwich  |   playingfield  |   railing_banister  |       |\n",
        "|   orange  |   railroad  |   guard_rail  |       |\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "image_segmentation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
