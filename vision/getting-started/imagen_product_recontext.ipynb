{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxCkB_DXTHzf"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hny4I-ODTIS6"
      },
      "source": [
        "# Imagen Product Recontextualization\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen_product_recontext.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fvision%2Fgetting-started%2Fimagen_product_recontext.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/vision/getting-started/imagen_product_recontext.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen_product_recontext.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen_product_recontext.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen_product_recontext.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen_product_recontext.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen_product_recontext.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/imagen_product_recontext.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXljS1-Ib0ue"
      },
      "source": [
        "| Author |\n",
        "| --- |\n",
        "| [Jorj Ismailyan](https://github.com/jismailyan-google) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nLS57E2TO5y"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Product Recontextualization brings Google's cutting edge Imagen model to generate high quality images of products \"recontextualized\" in new scenes and backgrounds.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXsvgIuwTPZw"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this notebook, you will be exploring the features of Imagen Product Recontextualization using the Vertex AI Python SDK. You will\n",
        "\n",
        "- Generate images by providing images of a product\n",
        "  * (Optional) Set a product description\n",
        "- Supported product categories\n",
        "  * business and industrial\n",
        "  * clothing\n",
        "  * furniture\n",
        "  * garden and yard\n",
        "  * health and beauty\n",
        "  * jewelry\n",
        "  * shoes\n",
        "  * sporting goods\n",
        "  * toys and games"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skXAu__iqks_"
      },
      "source": [
        "### Costs\n",
        "\n",
        "- This notebook uses billable components of Google Cloud:\n",
        "  - Vertex AI\n",
        "\n",
        "- Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvKl-BtQTRiQ"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-UOCMvJdmlq"
      },
      "source": [
        "### Install Vertex AI SDK for Python (Jupyter only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5lOntr-doIT"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --user google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opUxT_k5TdgP"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbNgv4q1T2Mi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybBXSukZkgjg"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and enable the Vertex AI API.\n",
        "\n",
        "Learn more about setting up a project and a development environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q7YvbXXdtzDT"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform.gapic import PredictResponse\n",
        "\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param [\"us-central1\"]\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "api_regional_endpoint = f\"{LOCATION}-aiplatform.googleapis.com\"\n",
        "client_options = {\"api_endpoint\": api_regional_endpoint}\n",
        "client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
        "\n",
        "model_endpoint = f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/imagen-product-recontext-preview-06-30\"\n",
        "print(f\"Prediction client initiated on project {PROJECT_ID} in {LOCATION}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ju_PctW22NUl"
      },
      "outputs": [],
      "source": [
        "# @title Import libraries and define utilities\n",
        "# @markdown Run this cell before proceeding to import libraries and define utility functions.\n",
        "import base64\n",
        "import io\n",
        "import re\n",
        "import timeit\n",
        "from typing import Any, Dict\n",
        "\n",
        "from PIL import Image\n",
        "from google.cloud import storage\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Parses the generated image bytes from the response and converts it\n",
        "# to a PIL Image object.\n",
        "def prediction_to_pil_image(\n",
        "    prediction: PredictResponse, size=(640, 640)\n",
        ") -> Image.Image:\n",
        "    encoded_bytes_string = prediction[\"bytesBase64Encoded\"]\n",
        "    decoded_image_bytes = base64.b64decode(encoded_bytes_string)\n",
        "    image_pil = Image.open(io.BytesIO(decoded_image_bytes))\n",
        "    image_pil.thumbnail(size)\n",
        "    return image_pil\n",
        "\n",
        "\n",
        "# Displays images and predictions in a horizontal row.\n",
        "def display_row(items: list, figsize: tuple[int, int] = (15, 15)):\n",
        "    count = len(items)\n",
        "\n",
        "    if count == 0:\n",
        "        print(\"No items to display.\")\n",
        "        return\n",
        "\n",
        "    fig, ax = plt.subplots(1, count, figsize=figsize)\n",
        "    if count == 1:\n",
        "        axes = [ax]\n",
        "    else:\n",
        "        axes = ax\n",
        "\n",
        "    for i in range(count):\n",
        "        item = items[i]\n",
        "        current_ax = axes[i]\n",
        "\n",
        "        if isinstance(item, Image.Image):\n",
        "            current_ax.imshow(item, None)\n",
        "            current_ax.axis(\"off\")\n",
        "        elif \"bytesBase64Encoded\" in item:\n",
        "            pil_image = prediction_to_pil_image(item)\n",
        "            current_ax.imshow(pil_image, None)\n",
        "            current_ax.axis(\"off\")\n",
        "        elif \"raiFilteredReason\" in item:\n",
        "            rai_reason = item[\"raiFilteredReason\"]\n",
        "            current_ax.text(\n",
        "                0.5,\n",
        "                0.5,\n",
        "                rai_reason,\n",
        "                horizontalalignment=\"center\",\n",
        "                verticalalignment=\"center\",\n",
        "                transform=current_ax.transAxes,\n",
        "                fontsize=12,\n",
        "                wrap=True,\n",
        "            )\n",
        "            current_ax.set_xlim(0, 1)\n",
        "            current_ax.set_ylim(0, 1)\n",
        "            current_ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Download image bytes from a GCS URI.\n",
        "\n",
        "\n",
        "def download_gcs_image_bytes(uri: str) -> bytes:\n",
        "    matched = re.match(r\"gs://(.*?)/(.*)\", uri)\n",
        "\n",
        "    if matched:\n",
        "        bucket_name = matched.group(1)\n",
        "        object_name = matched.group(2)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid GCS URI format: {uri}\")\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(object_name)\n",
        "    return blob.download_as_bytes()\n",
        "\n",
        "\n",
        "# Constructs a Vertex AI PredictRequest and uses it to call Imagen Product Recontext.\n",
        "\n",
        "\n",
        "def call_product_recontext(\n",
        "    image_bytes_list=None,\n",
        "    image_uris_list=None,\n",
        "    prompt=None,\n",
        "    product_description=None,\n",
        "    disable_prompt_enhancement: bool = False,\n",
        "    sampleCount: int = 1,\n",
        "    baseSteps=None,\n",
        "    safetySetting=None,\n",
        "    personGeneration=None,\n",
        ") -> PredictResponse:\n",
        "    instances = []\n",
        "\n",
        "    instance: Dict[str, Any] = {\"productImages\": []}\n",
        "\n",
        "    if image_bytes_list:\n",
        "        for product_image_bytes in image_bytes_list:\n",
        "            product_image = {\"image\": {\"bytesBase64Encoded\": product_image_bytes}}\n",
        "            instance[\"productImages\"].append(product_image)\n",
        "\n",
        "    if image_uris_list:\n",
        "        for product_image_uri in image_uris_list:\n",
        "            product_image = {\"image\": {\"gcsUri\": product_image_uri}}\n",
        "            instance[\"productImages\"].append(product_image)\n",
        "\n",
        "    if len(instance[\"productImages\"]) == 0:\n",
        "        raise ValueError(\n",
        "            \"No product images provided. At least one image must be provided.\"\n",
        "        )\n",
        "\n",
        "    if product_description:\n",
        "        instance[\"productImages\"][0][\"productConfig\"] = {\n",
        "            \"productDescription\": product_description\n",
        "        }\n",
        "\n",
        "    if prompt:\n",
        "        instance[\"prompt\"] = prompt\n",
        "\n",
        "    parameters = {}\n",
        "\n",
        "    if baseSteps:\n",
        "        parameters[\"baseSteps\"] = baseSteps\n",
        "\n",
        "    if safetySetting:\n",
        "        parameters[\"safetySetting\"] = safetySetting\n",
        "\n",
        "    if personGeneration:\n",
        "        parameters[\"personGeneration\"] = personGeneration\n",
        "\n",
        "    if disable_prompt_enhancement:\n",
        "        parameters[\"enhancePrompt\"] = False\n",
        "\n",
        "    instances.append(instance)\n",
        "\n",
        "    start = timeit.default_timer()\n",
        "\n",
        "    response = client.predict(\n",
        "        endpoint=model_endpoint, instances=instances, parameters=parameters\n",
        "    )\n",
        "    end = timeit.default_timer()\n",
        "    print(f\"Product Recontextualization took {end - start:.2f}s.\")\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU32286ooc8Q"
      },
      "source": [
        "## Call the Product Recontext API\n",
        "\n",
        "You can call the API by forming requests with input images either as Cloud Storage URIs or uploaded as base64 bytes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBLJtICO8iMQ"
      },
      "source": [
        "### Request with image bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "I9caIrZ7Dek1"
      },
      "outputs": [],
      "source": [
        "# @title Set product images\n",
        "# @markdown Run this cell to enable and select the Choose files button.\n",
        "# @markdown You can then select one to three images of a single product to upload.\n",
        "# @markdown This notebook resizes large images to a maximum dimension of 1024 pixels for faster processing.\n",
        "images = files.upload()\n",
        "image_bytes_list = []\n",
        "pil_images = []\n",
        "\n",
        "num_images = min(3, len(images.values()))\n",
        "for i in range(num_images):\n",
        "    RAW_IMAGE_BYTES = list(images.values())[i]\n",
        "    ENCODED_IMAGE_BYTES = base64.b64encode(RAW_IMAGE_BYTES).decode(\"utf-8\")\n",
        "    image_bytes_list.append(ENCODED_IMAGE_BYTES)\n",
        "\n",
        "    PRODUCT_IMAGE_PIL = Image.open(io.BytesIO(RAW_IMAGE_BYTES)).convert(\"RGB\")\n",
        "    PRODUCT_IMAGE_PIL.thumbnail((1024, 1024))\n",
        "    pil_images.append(PRODUCT_IMAGE_PIL)\n",
        "\n",
        "    width, height = PRODUCT_IMAGE_PIL.size\n",
        "    print(f\"image size(width x height): {width} x {height}\")\n",
        "display_row(pil_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1203T6syOvP"
      },
      "source": [
        "#### Send request with a prompt\n",
        "\n",
        "Set a `prompt` in the request to describe how the generated image should look.\n",
        "\n",
        "You can also set a `product_description` as a short description of the product itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHaPiAlkyOvQ"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\n",
        "product_description = \"\"\n",
        "\n",
        "# Parameters\n",
        "disable_prompt_enhancement = False\n",
        "sampleCount = 1  # 1-4\n",
        "baseSteps = None\n",
        "safetySetting = \"block_low_and_above\"  # [\"block_low_and_above\", \"block_medium_and_above\", \"block_only_high\", \"block_none\"]\n",
        "personGeneration = \"allow_adult\"  # [\"dont_allow\", \"allow_adult\", \"allow_all\"]\n",
        "\n",
        "response = call_product_recontext(\n",
        "    prompt=prompt,\n",
        "    image_bytes_list=image_bytes_list,\n",
        "    product_description=product_description,\n",
        "    disable_prompt_enhancement=disable_prompt_enhancement,\n",
        "    sampleCount=sampleCount,\n",
        "    baseSteps=baseSteps,\n",
        "    safetySetting=safetySetting,\n",
        "    personGeneration=personGeneration,\n",
        ")\n",
        "\n",
        "display_row(list(response.predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-yAQ2rt_pll"
      },
      "source": [
        "#### Send request without a prompt\n",
        "\n",
        "You can also recontextualize the products by just providing one to three images without setting a `prompt` or `product_description` in the request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9N8l0oo_cWs"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "disable_prompt_enhancement = False\n",
        "sampleCount = 1  # 1-4\n",
        "baseSteps = None\n",
        "safetySetting = \"block_low_and_above\"  # [\"block_low_and_above\", \"block_medium_and_above\", \"block_only_high\", \"block_none\"]\n",
        "personGeneration = \"allow_adult\"  # [\"dont_allow\", \"allow_adult\", \"allow_all\"]\n",
        "\n",
        "response = call_product_recontext(\n",
        "    image_bytes_list=image_bytes_list,\n",
        "    disable_prompt_enhancement=disable_prompt_enhancement,\n",
        "    sampleCount=sampleCount,\n",
        "    baseSteps=baseSteps,\n",
        "    safetySetting=safetySetting,\n",
        "    personGeneration=personGeneration,\n",
        ")\n",
        "\n",
        "display_row(list(response.predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCmFdWB8sTRG"
      },
      "source": [
        "### Request with Cloud Storage URIs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KDEuwJ9asiv6"
      },
      "outputs": [],
      "source": [
        "# @title Set input image URIs\n",
        "# @markdown Enter one to three `gs://...` paths to the product image files \\\n",
        "# @markdown in Cloud Storage and then run this cell.\n",
        "# @markdown Make sure your selected project has access to these URIs.\n",
        "\n",
        "PRODUCT_IMAGE_URI_1 = \"\"  # @param {'type': 'string'}\n",
        "PRODUCT_IMAGE_URI_2 = \"\"  # @param {'type': 'string'}\n",
        "PRODUCT_IMAGE_URI_3 = \"\"  # @param {'type': 'string'}\n",
        "\n",
        "product_uris = [\n",
        "    x for x in [PRODUCT_IMAGE_URI_1, PRODUCT_IMAGE_URI_2, PRODUCT_IMAGE_URI_3] if x\n",
        "]\n",
        "pil_images = []\n",
        "for uri in product_uris:\n",
        "    product_image_bytes = download_gcs_image_bytes(uri)\n",
        "    product_image = Image.open(io.BytesIO(product_image_bytes)).convert(\"RGB\")\n",
        "    pil_images.append(product_image)\n",
        "\n",
        "print(\"Previewing images from GCS: \")\n",
        "display_row(pil_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oVy2FfJsTRG"
      },
      "source": [
        "#### Send request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs5dial6sTRG"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\n",
        "product_description = \"\"\n",
        "\n",
        "# Parameters\n",
        "disable_prompt_enhancement = False\n",
        "sampleCount = 1  # 1-4\n",
        "baseSteps = None\n",
        "safetySetting = \"block_low_and_above\"  # [\"block_low_and_above\", \"block_medium_and_above\", \"block_only_high\", \"block_none\"]\n",
        "personGeneration = \"allow_adult\"  # [\"dont_allow\", \"allow_adult\", \"allow_all\"]\n",
        "\n",
        "response = call_product_recontext(\n",
        "    prompt=prompt,\n",
        "    image_uris_list=product_uris,\n",
        "    disable_prompt_enhancement=disable_prompt_enhancement,\n",
        "    sampleCount=sampleCount,\n",
        "    baseSteps=baseSteps,\n",
        "    safetySetting=safetySetting,\n",
        "    personGeneration=personGeneration,\n",
        ")\n",
        "\n",
        "display_row(list(response.predictions))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "imagen_product_recontext.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
