{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjTHAV8FgEza"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdL4uvQQs76x"
      },
      "source": [
        "# Veo 2 Editing\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_editing.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fvision%2Fgetting-started%2Fveo2_editing.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/vision/getting-started/veo2_editing.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_editing.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_editing.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_editing.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_editing.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_editing.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_editing.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcgplvn9SX2-"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Katie Nguyen](https://github.com/katiemn) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDjAqcgigwdX"
      },
      "source": [
        "**Launch Stage: Experimental**\n",
        "\n",
        "## Overview\n",
        "\n",
        "### Veo 2\n",
        "\n",
        "Veo 2 on Vertex AI brings Google's video generation capabilities to application developers. It's capable of creating videos with astonishing detail that simulate real-world physics across a wide range of visual styles.\n",
        "\n",
        "In this tutorial, you will learn how to use the Vertex AI API to interact with Veo 2 Editing to:\n",
        "- Inpaint\n",
        "- Outpaint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2_iOv5uhXVg"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWYnCW0-h6HI"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqz5LUG6h8fA"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxBkUEqdiB1g"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtjPBmYHiEfx"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVrasKoriKZn"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMQf_BkyiMgF"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "from IPython.display import Image, Video, display\n",
        "import google.auth\n",
        "import google.auth.transport.requests\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_bwA9hiMzL"
      },
      "source": [
        "### Define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUrEwbvFiPhJ"
      },
      "outputs": [],
      "source": [
        "def send_request_to_google_api(api_endpoint, data=None):\n",
        "    \"\"\"\n",
        "    Sends an HTTP request to a Google API endpoint.\n",
        "\n",
        "    Args:\n",
        "        api_endpoint: The URL of the Google API endpoint.\n",
        "        data: (Optional) Dictionary of data to send in the request body (for POST, PUT, etc.).\n",
        "\n",
        "    Returns:\n",
        "        The response from the Google API.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get access token calling API\n",
        "    creds, project = google.auth.default()\n",
        "    auth_req = google.auth.transport.requests.Request()\n",
        "    creds.refresh(auth_req)\n",
        "    access_token = creds.token\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {access_token}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "\n",
        "    response = requests.post(api_endpoint, headers=headers, json=data)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "def compose_request(\n",
        "    prompt,\n",
        "    parameters: dict[str, object],\n",
        "    mask_gcs: str = \"\",\n",
        "    mask_mime_type: str = \"\",\n",
        "    mask_mode: str = \"\",\n",
        "    video_gcs: str = \"\",\n",
        "):\n",
        "    instance = {\"prompt\": prompt}\n",
        "    if mask_gcs:\n",
        "        instance[\"mask\"] = {\n",
        "            \"gcsUri\": mask_gcs,\n",
        "            \"mimeType\": mask_mime_type,\n",
        "            \"maskMode\": mask_mode,\n",
        "        }\n",
        "    if video_gcs:\n",
        "        instance[\"video\"] = {\"gcsUri\": video_gcs, \"mimeType\": \"video/mp4\"}\n",
        "    request = {\"instances\": [instance], \"parameters\": parameters}\n",
        "    return request\n",
        "\n",
        "\n",
        "def fetch_operation(lro_name):\n",
        "    request = {\"operationName\": lro_name}\n",
        "    for i in range(30):\n",
        "        resp = send_request_to_google_api(fetch_endpoint, request)\n",
        "        if \"done\" in resp and resp[\"done\"]:\n",
        "            return resp\n",
        "        time.sleep(10)\n",
        "\n",
        "\n",
        "def generate_video(\n",
        "    prompt: str,\n",
        "    parameters: dict[str, object],\n",
        "    mask_gcs: str = \"\",\n",
        "    mask_mime_type: str = \"\",\n",
        "    mask_mode: str = \"\",\n",
        "    video_gcs: str = \"\",\n",
        "):\n",
        "    req = compose_request(\n",
        "        prompt=prompt,\n",
        "        parameters=parameters,\n",
        "        mask_gcs=mask_gcs,\n",
        "        mask_mime_type=mask_mime_type,\n",
        "        mask_mode=mask_mode,\n",
        "        video_gcs=video_gcs,\n",
        "    )\n",
        "    resp = send_request_to_google_api(prediction_endpoint, req)\n",
        "    print(resp)\n",
        "    return fetch_operation(resp[\"name\"])\n",
        "\n",
        "\n",
        "def show_video(op):\n",
        "    if \"error\" in op:\n",
        "        print(\"\\n\" + op[\"error\"][\"message\"])\n",
        "        return\n",
        "    if \"videos\" in op[\"response\"]:\n",
        "        for video in op[\"response\"][\"videos\"]:\n",
        "            gcs_uri = video[\"gcsUri\"]\n",
        "            show_video_from_gcs(gcs_uri)\n",
        "\n",
        "\n",
        "def show_video_from_gcs(video_gcs):\n",
        "    file_name = video_gcs.split(\"/\")[-1]\n",
        "    !gsutil cp {video_gcs} {file_name}\n",
        "    display(Video(file_name, embed=True, height=400))\n",
        "\n",
        "\n",
        "def show_image_from_gcs(image_gcs):\n",
        "    file_name = image_gcs.split(\"/\")[-1]\n",
        "    !gsutil cp {image_gcs} {file_name}\n",
        "    display(Image(file_name, height=400))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jaSOOadiUj6"
      },
      "source": [
        "### Load the video model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APRfTklCiYR2"
      },
      "outputs": [],
      "source": [
        "video_model = f\"https://us-central1-aiplatform.googleapis.com/v1beta1/projects/{PROJECT_ID}/locations/us-central1/publishers/google/models/veo-2.0-generate-exp\"\n",
        "prediction_endpoint = f\"{video_model}:predictLongRunning\"\n",
        "fetch_endpoint = f\"{video_model}:fetchPredictOperation\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOAQvxAkP7C4"
      },
      "source": [
        "## Inpainting\n",
        "\n",
        "With inpainting, you can provide a mask to remove objects from a video. This can be done through static or dynamic inpainting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDaTx8WCidRG"
      },
      "source": [
        "### Static inpainting\n",
        "Static inpainting applies the given mask image to each frame of the video, allowing you to mask out sections of a video and remove content.\n",
        "\n",
        "This example will walk you through using an original video and mask image that's stored in Cloud Storage. In order to generate an edited video, specify the following:\n",
        "\n",
        "- **Prompt:** Can be empty since you're removing content from the video.\n",
        "- **Video GCS:** The Cloud Storage location of your starting video.\n",
        "- **Mask GCS:** The Cloud Storage location of your image mask.\n",
        "- **Mask mime type:** Select either `image/png`, `image/jpeg`, `video/mp4`.\n",
        "- **Output file location:** The generated video will be shown below with support from a previously defined helper function. The video will also be stored in Cloud Storage once video generation is complete. Specify the bucket path where you would like this video to be stored in `output_gcs`.\n",
        "- **Aspect ratio:** Select either 16:9 or 9:16.\n",
        "- **Prompt enhancement:** The model offers the option to enhance your provided prompt. To utilize this feature, set `enhance_prompt` to True. A new, detailed prompt will be created from your original one to help generate higher quality videos that better adhere to your prompt's intent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tygfLLlWyTo_"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"  # @param {type: 'string'}\n",
        "video_gcs = (\n",
        "    \"gs://cloud-samples-data/generative-ai/video/truck.mp4\"  # @param {type: 'string'}\n",
        ")\n",
        "mask_gcs = \"gs://cloud-samples-data/generative-ai/image/truck-inpainting-static-mask.png\"  # @param {type: 'string'}\n",
        "mask_mime_type = \"image/png\"  # @param [\"image/png\", 'image/jpeg', 'video/mp4']\n",
        "\n",
        "output_gcs = \"gs://[your-bucket-path]\"  # @param {type: 'string'}\n",
        "aspect_ratio = \"16:9\"  # @param [\"16:9\", \"9:16\"]\n",
        "enhance_prompt = False  # @param {type: 'boolean'}\n",
        "sample_count = 1  # @param {type: 'number'}\n",
        "duration = 8  # @param {type: 'number'}\n",
        "\n",
        "parameters = {\n",
        "    \"storageUri\": output_gcs,\n",
        "    \"aspectRatio\": aspect_ratio,\n",
        "    \"enhancePrompt\": enhance_prompt,\n",
        "    \"sampleCount\": sample_count,\n",
        "    \"durationSeconds\": duration,\n",
        "}\n",
        "\n",
        "print(\"----Original Video----\")\n",
        "show_video_from_gcs(video_gcs)\n",
        "print(\"----Image Mask----\")\n",
        "show_image_from_gcs(mask_gcs)\n",
        "\n",
        "op = generate_video(\n",
        "    prompt,\n",
        "    video_gcs=video_gcs,\n",
        "    mask_gcs=mask_gcs,\n",
        "    mask_mime_type=mask_mime_type,\n",
        "    mask_mode=\"INPAINT\",\n",
        "    parameters=parameters,\n",
        ")\n",
        "\n",
        "print(\"----Edited Video----\")\n",
        "show_video(op)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOBoqhdcXs4e"
      },
      "source": [
        "### Dynamic inpainting\n",
        "Dynamic inpainting uses the given mask image to select an object from the first frame to remove. Only one object is supported at a time.\n",
        "\n",
        "This example will walk you through using an original video and mask image that's stored in Cloud Storage. Since you're removing content from a video you don't need to specify a prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoJ4ucV_YDhQ"
      },
      "outputs": [],
      "source": [
        "video_gcs = (\n",
        "    \"gs://cloud-samples-data/generative-ai/video/truck.mp4\"  # @param {type: 'string'}\n",
        ")\n",
        "mask_gcs = \"gs://cloud-samples-data/generative-ai/image/truck-inpainting-dynamic-mask.png\"  # @param {type: 'string'}\n",
        "mask_mime_type = \"image/png\"  # @param [\"image/png\", 'image/jpeg', 'video/mp4']\n",
        "\n",
        "output_gcs = \"gs://[your-bucket-path]\"  # @param {type: 'string'}\n",
        "aspect_ratio = \"16:9\"  # @param [\"16:9\", \"9:16\"]\n",
        "sample_count = 1  # @param {type: 'number'}\n",
        "duration = 8  # @param {type: 'number'}\n",
        "\n",
        "parameters = {\n",
        "    \"storageUri\": output_gcs,\n",
        "    \"aspectRatio\": aspect_ratio,\n",
        "    \"sampleCount\": sample_count,\n",
        "    \"durationSeconds\": duration,\n",
        "}\n",
        "\n",
        "print(\"----Original Video----\")\n",
        "show_video_from_gcs(video_gcs)\n",
        "print(\"----Image Mask----\")\n",
        "show_image_from_gcs(mask_gcs)\n",
        "\n",
        "op = generate_video(\n",
        "    prompt=\"\",\n",
        "    video_gcs=video_gcs,\n",
        "    mask_gcs=mask_gcs,\n",
        "    mask_mime_type=mask_mime_type,\n",
        "    mask_mode=\"INPAINT_DYNAMIC\",\n",
        "    parameters=parameters,\n",
        ")\n",
        "\n",
        "print(\"----Edited Video----\")\n",
        "show_video(op)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YysYLyiVj8Zd"
      },
      "source": [
        "## Outpainting\n",
        "In this next example, you'll edit a video with Veo 2 by outpainting. This feature entails extending a video. To outpaint, provide an image mask with a single, unmasked rectangle representing where the original video should be placed.\n",
        "\n",
        "This example will walk you through using an original video and mask image that's stored in Cloud Storage. You can add a prompt if you would like certain content in the outpainted area, or you can leave the prompt field empty.\n",
        "\n",
        "**Safety:** All Veo videos include [SynthID](https://deepmind.google/technologies/synthid/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gNxNj9N2R4o"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"  # @param {type: 'string'}\n",
        "video_gcs = (\n",
        "    \"gs://cloud-samples-data/generative-ai/video/truck.mp4\"  # @param {type: 'string'}\n",
        ")\n",
        "mask_gcs = \"gs://cloud-samples-data/generative-ai/image/truck-outpainting-mask.png\"  # @param {type: 'string'}\n",
        "mask_mime_type = \"image/png\"  # @param [\"image/png\", 'image/jpeg', 'video/mp4']\n",
        "\n",
        "output_gcs = \"gs://[your-bucket-path]\"  # @param {type: 'string'}\n",
        "aspect_ratio = \"16:9\"  # @param [\"16:9\", \"9:16\"]\n",
        "enhance_prompt = False  # @param {type: 'boolean'}\n",
        "sample_count = 1  # @param {type: 'number'}\n",
        "duration = 8  # @param {type: 'number'}\n",
        "\n",
        "parameters = {\n",
        "    \"storageUri\": output_gcs,\n",
        "    \"aspectRatio\": aspect_ratio,\n",
        "    \"enhancePrompt\": enhance_prompt,\n",
        "    \"sampleCount\": sample_count,\n",
        "    \"durationSeconds\": duration,\n",
        "}\n",
        "\n",
        "print(\"----Original Video----\")\n",
        "show_video_from_gcs(video_gcs)\n",
        "print(\"----Image Mask----\")\n",
        "show_image_from_gcs(mask_gcs)\n",
        "\n",
        "op = generate_video(\n",
        "    prompt,\n",
        "    video_gcs=video_gcs,\n",
        "    mask_gcs=mask_gcs,\n",
        "    mask_mime_type=mask_mime_type,\n",
        "    mask_mode=\"OUTPAINT\",\n",
        "    parameters=parameters,\n",
        ")\n",
        "\n",
        "print(\"----Edited Video----\")\n",
        "show_video(op)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "veo2_editing.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
