{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxCkB_DXTHzf"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hny4I-ODTIS6"
      },
      "source": [
        "# Virtual Try-On on Vertex AI\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/virtual_try_on.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fvision%2Fgetting-started%2Fvirtual_try_on.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/vision/getting-started/virtual_try_on.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/virtual_try_on.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/virtual_try_on.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/virtual_try_on.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/virtual_try_on.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/virtual_try_on.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/virtual_try_on.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXljS1-Ib0ue"
      },
      "source": [
        "| Author |\n",
        "| --- |\n",
        "| [Jorj Ismailyan](https://github.com/jismailyan-google) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nLS57E2TO5y"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Virtual Try-On uses Google's cutting edge image generation models to generate high quality images of clothing products.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXsvgIuwTPZw"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this notebook, you will be exploring the features of Virtual Try-On using the Vertex AI Python SDK. You will\n",
        "\n",
        "- Generate images by providing images of a person and a product to try on\n",
        "- Supported products\n",
        " * Tops (t-shirts, button-up shirts, hoodies, sweaters, tank tops)\n",
        " * Bottoms (pants, jeans, skirts)\n",
        " * Shoes (sneakers, boots, sandals, flats, heels, dress shoes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skXAu__iqks_"
      },
      "source": [
        "### Costs\n",
        "\n",
        "- This notebook uses billable components of Google Cloud:\n",
        "  - Vertex AI\n",
        "\n",
        "- Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvKl-BtQTRiQ"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-UOCMvJdmlq"
      },
      "source": [
        "### Install Vertex AI SDK for Python (Jupyter only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5lOntr-doIT"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --user google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opUxT_k5TdgP"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbNgv4q1T2Mi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybBXSukZkgjg"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and enable the Vertex AI API.\n",
        "\n",
        "Learn more about setting up a project and a development environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q7YvbXXdtzDT"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform.gapic import PredictResponse\n",
        "\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param [\"us-central1\"]\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "api_regional_endpoint = f\"{LOCATION}-aiplatform.googleapis.com\"\n",
        "client_options = {\"api_endpoint\": api_regional_endpoint}\n",
        "client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
        "\n",
        "model_endpoint = f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/virtual-try-on-exp-05-31\"\n",
        "print(f\"Prediction client initiated on project {PROJECT_ID} in {LOCATION}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ju_PctW22NUl"
      },
      "outputs": [],
      "source": [
        "# @title Import libraries and define utilities\n",
        "# @markdown Run this cell before proceeding to import libraries and define utility functions.\n",
        "import base64\n",
        "import io\n",
        "import re\n",
        "import timeit\n",
        "\n",
        "from PIL import Image\n",
        "from google.cloud import storage\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Parses the generated image bytes from the response and converts it\n",
        "# to a PIL Image object.\n",
        "def prediction_to_pil_image(\n",
        "    prediction: PredictResponse, size=(640, 640)\n",
        ") -> Image.Image:\n",
        "    encoded_bytes_string = prediction[\"bytesBase64Encoded\"]\n",
        "    decoded_image_bytes = base64.b64decode(encoded_bytes_string)\n",
        "    image_pil = Image.open(io.BytesIO(decoded_image_bytes))\n",
        "    image_pil.thumbnail(size)\n",
        "    return image_pil\n",
        "\n",
        "\n",
        "# Displays images and predictions in a horizontal row.\n",
        "def display_row(items: list, figsize: tuple[int, int] = (15, 15)):\n",
        "    count = len(items)\n",
        "\n",
        "    if count == 0:\n",
        "        print(\"No items to display.\")\n",
        "        return\n",
        "\n",
        "    fig, ax = plt.subplots(1, count, figsize=figsize)\n",
        "    if count == 1:\n",
        "        axes = [ax]\n",
        "    else:\n",
        "        axes = ax\n",
        "\n",
        "    for i in range(count):\n",
        "        item = items[i]\n",
        "        current_ax = axes[i]\n",
        "\n",
        "        if isinstance(item, Image.Image):\n",
        "            current_ax.imshow(item, None)\n",
        "            current_ax.axis(\"off\")\n",
        "        elif \"bytesBase64Encoded\" in item:\n",
        "            pil_image = prediction_to_pil_image(item)\n",
        "            current_ax.imshow(pil_image, None)\n",
        "            current_ax.axis(\"off\")\n",
        "        elif \"raiFilteredReason\" in item:\n",
        "            rai_reason = item[\"raiFilteredReason\"]\n",
        "            current_ax.text(\n",
        "                0.5,\n",
        "                0.5,\n",
        "                rai_reason,\n",
        "                horizontalalignment=\"center\",\n",
        "                verticalalignment=\"center\",\n",
        "                transform=current_ax.transAxes,\n",
        "                fontsize=12,\n",
        "                wrap=True,\n",
        "            )\n",
        "            current_ax.set_xlim(0, 1)\n",
        "            current_ax.set_ylim(0, 1)\n",
        "            current_ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Download image bytes from a GCS URI.\n",
        "def download_gcs_image_bytes(uri: str) -> bytes:\n",
        "    matched = re.match(r\"gs://(.*?)/(.*)\", uri)\n",
        "\n",
        "    if matched:\n",
        "        bucket_name = matched.group(1)\n",
        "        object_name = matched.group(2)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid GCS URI format: {uri}\")\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(object_name)\n",
        "    return blob.download_as_bytes()\n",
        "\n",
        "\n",
        "# Constructs a Vertex AI PredictRequest and uses it to call Virtual Try-On.\n",
        "\n",
        "\n",
        "def call_virtual_try_on(\n",
        "    person_image_bytes=None,\n",
        "    product_image_bytes=None,\n",
        "    person_image_uri=None,\n",
        "    product_image_uri=None,\n",
        "    sample_count: int = 1,\n",
        "    base_steps=None,\n",
        "    safety_setting=None,\n",
        "    person_generation=None,\n",
        ") -> PredictResponse:\n",
        "    instances = []\n",
        "\n",
        "    if person_image_uri and product_image_uri:\n",
        "        instance = {\n",
        "            \"personImage\": {\"image\": {\"gcsUri\": person_image_uri}},\n",
        "            \"productImages\": [{\"image\": {\"gcsUri\": product_image_uri}}],\n",
        "        }\n",
        "        instances.append(instance)\n",
        "    elif person_image_bytes and product_image_bytes:\n",
        "        instance = {\n",
        "            \"personImage\": {\"image\": {\"bytesBase64Encoded\": person_image_bytes}},\n",
        "            \"productImages\": [{\"image\": {\"bytesBase64Encoded\": product_image_bytes}}],\n",
        "        }\n",
        "        instances.append(instance)\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Both person_image_bytes and product_image_bytes or both person_image_uri and product_image_uri must be set.\"\n",
        "        )\n",
        "\n",
        "    parameters = {\"sampleCount\": sample_count}\n",
        "\n",
        "    if base_steps:\n",
        "        parameters[\"baseSteps\"] = base_steps\n",
        "\n",
        "    if safety_setting:\n",
        "        parameters[\"safetySetting\"] = safety_setting\n",
        "\n",
        "    if person_generation:\n",
        "        parameters[\"personGeneration\"] = person_generation\n",
        "\n",
        "    start = timeit.default_timer()\n",
        "\n",
        "    response = client.predict(\n",
        "        endpoint=model_endpoint, instances=instances, parameters=parameters\n",
        "    )\n",
        "    end = timeit.default_timer()\n",
        "    print(f\"Virtual Try-On took {end - start:.2f}s.\")\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU32286ooc8Q"
      },
      "source": [
        "## Call the Virtual Try-On API\n",
        "\n",
        "You can call the API by forming requests with input images either as Cloud Storage URIs or uploaded as base64 bytes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBLJtICO8iMQ"
      },
      "source": [
        "### Request with image bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "I9caIrZ7Dek1"
      },
      "outputs": [],
      "source": [
        "# @title Set a person image\n",
        "# @markdown Run this cell to enable and select the Choose files button. You can then select an image file from your local device to upload. Large images are resized to a maximum dimension of 1024 pixels for faster processing.\n",
        "\n",
        "\n",
        "images = files.upload()\n",
        "RAW_PERSON_IMAGE_BYTES = list(images.values())[0]\n",
        "ENCODED_PERSON_IMAGE_BYTES = base64.b64encode(RAW_PERSON_IMAGE_BYTES).decode(\"utf-8\")\n",
        "PERSON_IMAGE_PIL = Image.open(io.BytesIO(RAW_PERSON_IMAGE_BYTES)).convert(\"RGB\")\n",
        "PERSON_IMAGE_PIL.thumbnail((1024, 1024))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(PERSON_IMAGE_PIL)\n",
        "\n",
        "print(\n",
        "    f\"image size(with x height): {PERSON_IMAGE_PIL.size[0]} x {PERSON_IMAGE_PIL.size[1]}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qj70GAQjfCPC"
      },
      "outputs": [],
      "source": [
        "# @title Set a product image\n",
        "# @markdown Run this cell to enable and select the Choose files button. You can then select an image file from your local device to upload. Large images are resized to a maximum dimension of 1024 pixels for faster processing.\n",
        "images = files.upload()\n",
        "RAW_PRODUCT_IMAGE_BYTES = list(images.values())[0]\n",
        "ENCODED_PRODUCT_IMAGE_BYTES = base64.b64encode(RAW_PRODUCT_IMAGE_BYTES).decode(\"utf-8\")\n",
        "PRODUCT_IMAGE_PIL = Image.open(io.BytesIO(RAW_PRODUCT_IMAGE_BYTES)).convert(\"RGB\")\n",
        "PRODUCT_IMAGE_PIL.thumbnail((1024, 1024))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(PRODUCT_IMAGE_PIL)\n",
        "\n",
        "print(\n",
        "    f\"image size(with x height): {PRODUCT_IMAGE_PIL.size[0]} x {PRODUCT_IMAGE_PIL.size[1]}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-yAQ2rt_pll"
      },
      "source": [
        "#### Send request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9N8l0oo_cWs"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "sample_count = 1  # 1-4\n",
        "base_steps = None\n",
        "safety_setting = \"block_low_and_above\"  # [\"block_low_and_above\", \"block_medium_and_above\", \"block_only_high\", \"block_none\"]\n",
        "person_generation = \"allow_adult\"  # [\"dont_allow\", \"allow_adult\", \"allow_all\"]\n",
        "\n",
        "response = call_virtual_try_on(\n",
        "    person_image_bytes=ENCODED_PERSON_IMAGE_BYTES,\n",
        "    product_image_bytes=ENCODED_PRODUCT_IMAGE_BYTES,\n",
        "    sample_count=sample_count,\n",
        "    base_steps=base_steps,\n",
        "    safety_setting=safety_setting,\n",
        "    person_generation=person_generation,\n",
        ")\n",
        "\n",
        "display_row(list(response.predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCmFdWB8sTRG"
      },
      "source": [
        "### Request with Cloud Storage URIs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KDEuwJ9asiv6"
      },
      "outputs": [],
      "source": [
        "# @title Set input image URIs\n",
        "# @markdown Enter `gs://...` paths to image files in Cloud Storage and then run \\\n",
        "# @markdown this cell. Make sure your selected project has access to these URIs.\n",
        "\n",
        "PERSON_IMAGE_URI = \"\"  # @param {'type': 'string'}\n",
        "PRODUCT_IMAGE_URI = \"\"  # @param {'type': 'string'}\n",
        "pil_images = []\n",
        "for uri in [PERSON_IMAGE_URI, PRODUCT_IMAGE_URI]:\n",
        "    product_image_bytes = download_gcs_image_bytes(uri)\n",
        "    product_image = Image.open(io.BytesIO(product_image_bytes)).convert(\"RGB\")\n",
        "    pil_images.append(product_image)\n",
        "\n",
        "print(\"Previewing images from GCS: \")\n",
        "display_row(pil_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oVy2FfJsTRG"
      },
      "source": [
        "#### Send request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs5dial6sTRG"
      },
      "outputs": [],
      "source": [
        "sample_count = 1  # 1-4\n",
        "base_steps = None\n",
        "safety_setting = \"block_low_and_above\"  # [\"block_low_and_above\", \"block_medium_and_above\", \"block_only_high\", \"block_none\"]\n",
        "person_generation = \"allow_adult\"  # [\"dont_allow\", \"allow_adult\", \"allow_all\"]\n",
        "\n",
        "response = call_virtual_try_on(\n",
        "    person_image_uri=PERSON_IMAGE_URI,\n",
        "    product_image_uri=PRODUCT_IMAGE_URI,\n",
        "    sample_count=sample_count,\n",
        "    base_steps=base_steps,\n",
        "    safety_setting=safety_setting,\n",
        "    person_generation=person_generation,\n",
        ")\n",
        "\n",
        "display_row(list(response.predictions))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "virtual_try_on.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
