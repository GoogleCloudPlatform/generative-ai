{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Getting Started with the Vertex AI Codey APIs - Code Completion\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/code/code_completion.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/code/code_completion.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/code/code_completion.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK1Q5ZYdVL4Y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook aims to provide a hands-on introduction to code completion using [Codey models](https://cloud.google.com/vertex-ai/docs/generative-ai/code/code-models-overview), specifically the `code-gecko` model. You will learn how to create prompts to interact with the `code-gecko` model and generate code suggestions based on the context of the code you're writing.\n",
    "\n",
    "\n",
    "### Vertex AI PaLM API\n",
    "The Vertex AI PaLM API, [released on May 10, 2023](https://cloud.google.com/vertex-ai/docs/generative-ai/release-notes#may_10_2023), is powered by [PaLM 2](https://ai.google/discover/palm2).\n",
    "\n",
    "### Using Vertex AI PaLM API\n",
    "\n",
    "You can interact with the Vertex AI PaLM API using the following methods:\n",
    "\n",
    "* Use the [Generative AI Studio](https://cloud.google.com/generative-ai-studio) for quick testing and command generation.\n",
    "* Use cURL commands in Cloud Shell.\n",
    "* Use the Python SDK in a Jupyter notebook\n",
    "\n",
    "This notebook focuses on using the Python SDK to call the Vertex AI PaLM API. For more information on using Generative AI Studio without writing code, you can explore [Getting Started with the UI instructions](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_generative_ai_studio.md)\n",
    "\n",
    "\n",
    "For more information, check out the [documentation on generative AI support for Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQT500QqVPIb"
   },
   "source": [
    "### Objectives\n",
    "\n",
    "In this tutorial, you will learn various code completion examples for completing:\n",
    "* Functions\n",
    "* Classes\n",
    "* Statements\n",
    "* Expressions & Variables\n",
    "* Imports\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1y6_3dTwV2fI"
   },
   "source": [
    "### Costs\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI Generative AI Studio\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
    "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDU0XJ1xRDlL"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5afkyDMSBW5"
   },
   "source": [
    "### Install Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kc4WxYmLSBW5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7UyNVSiyQ96"
   },
   "source": [
    "**Colab only:** Uncomment the following cell to restart the kernel or use the button to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmY9HVVGSBW5"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Fom0ZkMSBW6"
   },
   "source": [
    "### Authenticating your notebook environment\n",
    "* If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n",
    "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCaCx6PLSBW6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GckO4EysV5BT"
   },
   "source": [
    "## Code Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDYqwDmTLgEy"
   },
   "source": [
    "What is Code Completion?\n",
    "\n",
    "Code completion is a feature in many integrated development environments (IDEs) that suggests code to the programmer as they are typing. This can save time and help to prevent errors. Code completion suggestions are based on the context of the code being written, such as the programming language, the current line of code, and the variables that have been defined.\n",
    "\n",
    "\n",
    "\n",
    "Benefits of using code completion?\n",
    "\n",
    "There are several benefits to using code completion in general, including:\n",
    "\n",
    "* **Increased productivity**: Code completion can save programmers a lot of time by suggesting code as they are typing. This can free them up to focus on other tasks, such as designing the architecture of their software or debugging their code.\n",
    "\n",
    "* **Reduced errors**: Code completion can help to reduce errors by suggesting code that is syntactically correct and semantically meaningful. This can be especially helpful when programmers are working with new or unfamiliar programming languages or APIs.\n",
    "\n",
    "* **Improved code quality**: Code completion can help to improve the quality of code by suggesting code that is consistent with the style guide of the project. This can make the code more readable and maintainable.\n",
    "\n",
    "\n",
    "Code Completion and IDE Intergation:\n",
    "\n",
    "When code completion through Codey Model is integrated with an IDE, it can be even more powerful. The IDE can use its knowledge of the project's structure and codebase to provide more accurate and relevant suggestions. For example, if the programmer is typing code in a class, the IDE can suggest methods and fields from that class.\n",
    "\n",
    "Here are some of the benefits of using code completion with integration with different IDEs:\n",
    "\n",
    "* **Increased productivity**: Code completion can help programmers write code more quickly and accurately, which can lead to significant productivity gains.\n",
    "* **Improved code quality**: Code completion can help programmers avoid errors and typos, and can also suggest more efficient and idiomatic code.\n",
    "* **Better code readability**: Code completion can help programmers write more readable and maintainable code by suggesting consistent variable names and function signatures.\n",
    "* **Reduced learning curve**: Code completion can help new programmers learn new languages and frameworks more quickly by suggesting the correct symbols and functions to use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuQwwRiniVFG"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vnq2kIV8yQ97"
   },
   "source": [
    "**Colab only:** Uncomment the following cell to initialize the Vertex AI SDK. For Vertex AI Workbench, you don't need to run this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtMowvm-yQ97"
   },
   "outputs": [],
   "source": [
    "# import vertexai\n",
    "\n",
    "# PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "# vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zjV4alsiVql"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from vertexai.language_models import CodeGenerationModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5B1PlCAr3GQi"
   },
   "source": [
    "## Code completion with code-gecko@002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzoNuCqd3pbn"
   },
   "source": [
    "The Vertex AI Codey APIs include the code completion API, which supports code suggestions based on code that's recently written. Use the generative AI foundation model named `code-gecko` to interact with the code completion API.\n",
    "\n",
    "To learn more about creating prompts for code completion, see [Create prompts for code completion](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/code-completion#:~:text=code%20completion%2C%20see-,Create%20prompts%20for%20code%20completion,-.).\n",
    "\n",
    "Code completion API has few more parameters than code generation.\n",
    "\n",
    "* prefix: required : For code models, prefix represents the beginning of a piece of meaningful programming code or a natural language prompt that describes code to be generated.\n",
    "\n",
    "* suffix: optional : For code completion, suffix represents the end of a piece of meaningful programming code. The model attempts to fill in the code in between the prefix and suffix.\n",
    "\n",
    "* temperature: required : Temperature controls the degree of randomness in token selection. Same as for other models. range: (0.0 - 1.0, default 0)\n",
    "\n",
    "* maxOutputTokens: required : Maximum number of tokens that can be generated in the response. range: (1 - 64, default 64)\n",
    "\n",
    "* stopSequences: optional : Specifies a list of strings that tells the model to stop generating text if one of the strings is encountered in the response. The strings are case-sensitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6AzUJLt-ihw"
   },
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GqGueQgG3pAA"
   },
   "outputs": [],
   "source": [
    "code_completion_model = CodeGenerationModel.from_pretrained(\"code-gecko@latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIiZZHJAC0jC"
   },
   "source": [
    "### Hello Codey Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbChNT8v2TfB"
   },
   "source": [
    "#### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEv1Ymoi024h"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"def find_x_in_string(string_s, x):\n",
    "\n",
    "         \"\"\"\n",
    "\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5s-BLCe1EoL"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "         def reverse_string(s):\n",
    "            return s[::-1]\n",
    "         def test_empty_input_string():\n",
    "         \"\"\"\n",
    "\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbJNHw8F2Vox"
   },
   "source": [
    "#### Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Rf3hWGwhfm8"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "        ArrayList<String> myList = new ArrayList<>();\n",
    "        //add the `String` \"Hello, world!\" to the `ArrayList`:\n",
    "         \"\"\"\n",
    "\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4PpD90a0_6ju"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "        public static List<String> getUniqueStrings(List<String> strings) {\n",
    "         \"\"\"\n",
    "\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjfaCNwPAIn-"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "        String[] names = {\"Alice\", \"Bob\", \"Carol\"};\n",
    "        for (String name : names) {\n",
    "         \"\"\"\n",
    "\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3zuhvxr2YAD"
   },
   "source": [
    "#### JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8XN7je52bwU"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "        #javaScript\n",
    "        function factorial(n) {\n",
    "         \"\"\"\n",
    "\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q821xI-YAZaL"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "        function greet(name) {\n",
    "            return \"Hello, \" + name + \"!\";\n",
    "          }\n",
    "        const greeting = greet(YOUR_NAME_HERE);\n",
    "         \"\"\"\n",
    "\n",
    "response = code_completion_model.predict(prefix=prefix)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbCu3EhW2cJb"
   },
   "source": [
    "#### C/C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZiieZxc2gfS"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "        int main() {\n",
    "          char str[] = \"Hello, world!\";\n",
    "         \"\"\"\n",
    "\n",
    "response = code_completion_model.predict(prefix=prefix)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hi0HfUXAxqE"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "        LinkedList linkedList;\n",
    "\n",
    "        linkedList.addNode(1);\n",
    "        linkedList.addNode(2);\n",
    "        linkedList.addNode(3);\n",
    "\n",
    "        int value =\n",
    "         \"\"\"\n",
    "\n",
    "response = code_completion_model.predict(prefix=prefix)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWXz1C_76o9E"
   },
   "source": [
    "### Code Completion Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ps90YZ0j6sKV"
   },
   "source": [
    "#### Completing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FI85Rua46vka"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"import math\n",
    "            # Start typing the name of a function\n",
    "            def sqrt(x):\n",
    "         \"\"\"\n",
    "\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQdfz1qU8i_1"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"def greet(name):\n",
    "              print(f\"Hello, {name}!\")\n",
    "\n",
    "            # Call the greet() function\n",
    "         \"\"\"\n",
    "\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_7wnlUb7SmJ"
   },
   "source": [
    "#### Completing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMTM-3oA7acY"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"class Dog:\n",
    "              def bark(self):\n",
    "                print(\"Woof!\")\n",
    "\n",
    "            # Create a new Dog object\n",
    "          \"\"\"\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81ylPG1676y8"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"class Person:\n",
    "              #Represents a person.\n",
    "              def __init__(self, name, age):\n",
    "                self.name = name\n",
    "                self.age = age\n",
    "\n",
    "            # Start typing the name of the Person class\n",
    "            Person(\n",
    "          \"\"\"\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOg3nQHR7qs-"
   },
   "source": [
    "#### Completing Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNBjFgl47tFn"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"if age >= 21:\n",
    "              print(\"You are an adult. \")\n",
    "         \"\"\"\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SHI4knA8TqF"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"if x < 10:\n",
    "              # Complete the statement\n",
    "         \"\"\"\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6Yja9SS9PRq"
   },
   "source": [
    "#### Completing Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Boqfqa_9Riv"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"x = 10 +\n",
    "         \"\"\"\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AellPWeD-JT-"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"1 + 2 * 3\n",
    "         \"\"\"\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfjQEvm89UPI"
   },
   "source": [
    "#### Completing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZ2hdfCQ9TC1"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"# Define a variable\n",
    "            name = \"Alice\"\n",
    "            #get uppercase of the variable\n",
    "            name.upper()\n",
    "         \"\"\"\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xaat-Ar8-YGk"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"x = 10\n",
    "            y = x +\n",
    "         \"\"\"\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6RJZuoz9YGh"
   },
   "source": [
    "#### Completing Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqDKbWeY9X0g"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"import math\n",
    "            import numpy as np\n",
    "            #import machine learning libraries\n",
    "         \"\"\"\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmTs_-9P-k3O"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"import math\n",
    "            import time\n",
    "            import random\n",
    "            import sys\n",
    "         \"\"\"\n",
    "response = code_completion_model.predict(prefix=prefix,\n",
    "                                         max_output_tokens=64)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5gHEM_k2lCf"
   },
   "source": [
    "### Feedback Loop Code Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jl8rGgVq2lXj"
   },
   "outputs": [],
   "source": [
    "prefix = \"def find_max_element(list):\"\n",
    "i = 0\n",
    "while(i<3):\n",
    "  response = code_completion_model.predict(prefix=prefix,)\n",
    "  print(response.text)\n",
    "  prefix = response.text\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8ORkzaACFm1"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"class Dog:\n",
    "              def bark(self):\n",
    "                print(\"Woof!\")\n",
    "          \"\"\"\n",
    "i = 0\n",
    "while(i<3):\n",
    "    response = code_completion_model.predict(prefix=prefix,)\n",
    "    print(response.text)\n",
    "    prefix = response.text\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X32dfzSDCWyh"
   },
   "source": [
    "### Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMQ6v5a1CZtf"
   },
   "source": [
    "#### **How to write effective code completion prompts**\n",
    "\n",
    "When writing code completion prompts, it is important to be as specific and descriptive as possible. The more information you can provide the model, the better it will be able to understand what you are trying to achieve.\n",
    "\n",
    "Here are some tips for writing effective code completion prompts:\n",
    "\n",
    "* Start with a natural language description of what you want the model to generate. This should be a clear and concise statement of your goal, such as \"Complete the following function to print the sum of two numbers\" or \"Generate a function to check if a string is a palindrome.\"\n",
    "\n",
    "* Include any relevant context in the prompt. This could include the code that you have already written, the programming language you are using, or any other information that the model might need to know.\n",
    "\n",
    "* Use examples to illustrate what you are looking for. If you can, provide the model with examples of the code that you want it to generate. This will help the model to better understand your intentions.\n",
    "Here is an example of a good code completion prompt:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "Complete the following Python function to check if a string is a palindrome:\n",
    "\n",
    "def is_palindrome(string):\n",
    "  \"\"\"Checks if a string is a palindrome.\n",
    "\n",
    "  Args:\n",
    "    string: A string.\n",
    "\n",
    "  Returns:\n",
    "    A boolean value indicating whether the string is a palindrome.\n",
    "  \"\"\"\n",
    "  # TODO: Implement this function.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMvw6dDjCwLc"
   },
   "source": [
    "#### **How to choose the right temperature and max output tokens**\n",
    "\n",
    "The temperature and max output tokens are two important parameters that control the behavior of the code completion model.\n",
    "\n",
    "* Temperature: The temperature controls how creative the model is. A higher temperature will lead to more creative and unexpected suggestions, while a lower temperature will lead to more conservative and predictable suggestions.\n",
    "\n",
    "* Max output tokens: The max output tokens controls the maximum length of the code that the model can generate. A higher max output tokens will allow the model to generate longer code snippets, while a lower max output tokens will limit the length of the generated code.\n",
    "\n",
    "When choosing the right temperature and max output tokens, it is important to consider the specific task that you are trying to accomplish. If you need the model to generate creative and unexpected suggestions, you should use a higher temperature. If you need the model to generate code snippets that are of a specific length, you should use the appropriate max output tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6asQyDqrC8Lq"
   },
   "source": [
    "#### **How to interpret and use code completion suggestions**\n",
    "\n",
    "Once you have generated some code completion suggestions, it is important to carefully interpret and use them.\n",
    "\n",
    "The code completion model is not perfect, and it is possible that it will generate suggestions that are incorrect or incomplete. It is important to review the suggestions carefully and to test them before using them in your code.\n",
    "\n",
    "Here are some tips for interpreting and using code completion suggestions:\n",
    "\n",
    "* Make sure that the suggestions are syntactically correct. The code completion model may generate suggestions that are syntactically incorrect. It is important to check the syntax of the suggestions before using them in your code.\n",
    "\n",
    "* Test the suggestions before using them in your code. Once you have found some suggestions that you are happy with, it is important to test them before using them in your code. This will help to ensure that the suggestions are correct and that they will work as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ixwWF-iDF8I"
   },
   "source": [
    "#### **How to avoid common code completion pitfalls**\n",
    "\n",
    "Here are some common code completion pitfalls to avoid:\n",
    "\n",
    "* Do not rely on the code completion model to generate all of your code. The code completion model is a tool, but it should not be used to generate all of your code. It is important to understand the code that you are writing and to be able to review and test it carefully.\n",
    "\n",
    "* Do not use code completion suggestions without understanding them. It is important to understand the code completion suggestions before using them in your code. This will help you to identify any potential errors or problems.\n",
    "\n",
    "* Do not use code completion suggestions for tasks that are too complex. The code completion model is not designed to generate complex code snippets. If you need to generate complex code, it is best to write it yourself."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
