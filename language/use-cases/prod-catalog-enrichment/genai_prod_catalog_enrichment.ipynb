{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36f054db-6a1b-4c53-8130-da8caa943119",
      "metadata": {
        "id": "2eec5cc39a59"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b95a7456-9f82-4f5f-9dd4-a0277e307b5f",
      "metadata": {
        "id": "d7ab2023065c"
      },
      "source": [
        "# Product Catalog Extraction Tool using Generative AI\n",
        "\n",
        "**NOTE:** This notebook uses the PaLM generative model, which will reach its [discontinuation date in October 2024](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text#model_versions).\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/use-cases/prod-catalog-enrichment/genai_prod_catalog_enrichment.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/use-cases/prod-catalog-enrichment/genai_prod_catalog_enrichment.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/language/use-cases/prod-catalog-enrichment/genai_prod_catalog_enrichment.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45633f2d-d69e-47a3-9ddc-c93fa91caba7",
      "metadata": {
        "id": "4d284846d432"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Sanchit Latawa](https://github.com/slatawa) , Lalit Kumar Digala  |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cde2c1e-bdc4-4515-9bd1-3cb616a6b56d",
      "metadata": {
        "id": "46d06a35173e"
      },
      "source": [
        "# Product Catalog Extraction Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee2bf6c9-f5d4-402c-84ea-55678e325958",
      "metadata": {
        "id": "d871da230388"
      },
      "source": [
        "A Generative AI driven tool utilizing [Google Vertex AI](https://cloud.google.com/vertex-ai) to extract text and images from product catalogs.\n",
        "\n",
        "# Objectives\n",
        "- Extract product information (text, images) from product catalogs in PDF format.\n",
        "- Enrich extracted data with AI-generated captions and metadata.\n",
        "- Provide structured output for downstream processing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "679e9912-5a42-4fcc-99e9-eadb68f137e6",
      "metadata": {
        "id": "47cb031f6983"
      },
      "source": [
        "# Solution Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ac97a7d-e68b-4506-936e-6831743c1c34",
      "metadata": {
        "id": "e44112989bfe"
      },
      "source": [
        "![Problem Space](./sol_arc_img.png) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61545882-7068-44dd-b2b2-af164cbcc11c",
      "metadata": {
        "id": "ea3dac4d4c73"
      },
      "source": [
        "# Image/Text Extraction:\n",
        "Employs [PyMuPDF](https://pymupdf.readthedocs.io/en/latest/) to extract raw images and text from PDF files, including citations.\n",
        "\n",
        "# Text/Image Cleaning & Enrichment:\n",
        "- Sanitizes extracted text and images.\n",
        "- Leverages [Imagen](https://cloud.google.com/vertex-ai/docs/generative-ai/image/overview) for caption generation (\"specific captions\").\n",
        "- Stores enriched data in an intermediate bucket for traceability.\n",
        "\n",
        "# Dynamic Prompt Generation & LLM Interaction:\n",
        "- Generates prompts for tasks: Product ISQ, FAQ generation, Image Labeling, Image Captions.\n",
        "- Submits prompts to a Large Language Model (LLM).\n",
        "- Implements auto-reflection for refining output if needed.\n",
        "- Aggregates results into a final JSON.\n",
        "\n",
        "# Storage:\n",
        "Stores the final JSON in Google Cloud Storage (GCS) for downstream use."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "483cdd25-8470-4923-a547-43980da2d3b3",
      "metadata": {
        "id": "88e92e2d58b5"
      },
      "source": [
        "# Tool Evaluation\n",
        "Product Catalogs could be in various formats, below space graph shows the performance of the tool"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40bfd6b3-c2b0-460c-98e8-3c152d700f86",
      "metadata": {
        "id": "c666d586d237"
      },
      "source": [
        "![Problem Space](./problem_space_img.png) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c76baba-e498-43aa-92bd-b2c9ad8e6527",
      "metadata": {
        "id": "895f5084c7cc"
      },
      "source": [
        "Given a product catalog pdf URI this tool will extract text and image details of the product.\n",
        "\n",
        "Text Details that are extracted\n",
        "\n",
        "- Company Details - Details of Company which owns the Product - name , address , email , contact details.\n",
        "- Product Name - Name of the product , description.\n",
        "- FAQ Frequently asked questions around the product\n",
        "- ISQ Product specifications\n",
        "- Image Details that are extracted\n",
        "\n",
        "\n",
        "Main Image of the product\n",
        "\n",
        "- Captions for the Image\n",
        "- Label for the Image\n",
        "- Tags for the Image\n",
        "\n",
        "\n",
        "Once these details are extracted the Result JSON file is placed in the output GCS bucket that is also passed as an argument. For a sample JSON look at the file output_prod_details.json in this repo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ead50b44-3766-44fe-827a-cee652958931",
      "metadata": {
        "id": "724cae2e668a"
      },
      "source": [
        "- Argument 1  GCS URI of the pdf file \n",
        "- Argument 2  Bucket Name where the output file will be placed\n",
        "- Argument 3  Google Cloud Project ID\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f9461c8-7f2a-4fa1-889e-74ba3104954e",
      "metadata": {
        "id": "ed3e96027c3e"
      },
      "source": [
        "# Sample Run\n",
        "\n",
        "Let us try running the enrichment engine on a sample product catalog. Below you see a screen grab of prod catalog that has Diesel Generator Set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b310b3d-5cc3-48b8-8ccb-b23ffc134b7a",
      "metadata": {
        "id": "538553d08989"
      },
      "source": [
        "![Image Description](./prod_catalog_img.png) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62a01946-3dc1-4c28-8394-23b0b4d1651a",
      "metadata": {
        "id": "7c0999c43e5a"
      },
      "source": [
        "- Argument 1  GCS URI of the pdf file\n",
        "- Argument 2  Bucket Name where the output file will be placed\n",
        "- Argument 3  Google Cloud Project ID"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eea88389-ac50-4371-af1b-3de49d32daaf",
      "metadata": {
        "id": "469a00e31f76"
      },
      "source": [
        "In below screengrab we have the pdf metadata , company details and product name, features being extracted\n",
        "\n",
        "![Image Description](./output_1.png) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "558cc031-fadc-40f1-bd89-6fd27a73d77d",
      "metadata": {
        "id": "8b4972269f70"
      },
      "source": [
        "Looking further into the JSON — we have also generated product category and tags — which can be useful when indexing the product for search. Along with this with help of LLM we have generated FAQ's which can help end consumers.\n",
        "\n",
        "![Image Description](./output_2.png) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3372fd6e-c16f-4a8c-b2e1-93a193ab8fa5",
      "metadata": {
        "id": "718f8b6df41f"
      },
      "source": [
        "# Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf05b2b7-29b0-46fd-a1ca-d6a49826305e",
      "metadata": {
        "id": "6f6621fa43bd"
      },
      "source": [
        "# Install Vertex AI SDK & Other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4de4dcfb-beea-474d-a820-aaef41bd42ad",
      "metadata": {
        "id": "f3fa3fce9ac4"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform\n",
        "!pip install google-cloud-storage\n",
        "!pip install PyMuPDF\n",
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9126cf1e-edc5-4910-8a01-1f6f16227043",
      "metadata": {
        "id": "d2d20b6c1653"
      },
      "source": [
        "Colab only: Run the following cell to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4e6ea28d-9111-4a3d-bc3b-5b4518c9f087",
      "metadata": {
        "id": "4e2fe77d3964"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Automatically restart kernel after installs so that your environment can access the new packages\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)\n",
        "else:\n",
        "    # Otherwise, attempt to discover local credentials as described on https://cloud.google.com/docs/authentication/application-default-credentials\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfbfa08f-3636-4dc0-a127-008b6cd7c570",
      "metadata": {
        "id": "6d44c17346a3"
      },
      "source": [
        "# Colab Only\n",
        "You will need to run the following cell to authenticates your Colab environment with your Google Cloud account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8aa18d22-dcaa-4963-9eed-5dbac6f6b5cb",
      "metadata": {
        "id": "b3ae1865bf6e"
      },
      "outputs": [],
      "source": [
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fdd51cd-4565-4acb-8100-b793b821a4e9",
      "metadata": {
        "id": "53c8acea7ad6"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d6df5753-18e3-415c-98c5-1b8159896d3b",
      "metadata": {
        "id": "d797f2e0d9b3"
      },
      "outputs": [],
      "source": [
        "# import modules\n",
        "import csv\n",
        "import datetime\n",
        "import requests\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import ast\n",
        "import traceback\n",
        "import fitz\n",
        "import vertexai\n",
        "from vertexai.language_models import TextGenerationModel\n",
        "from google.cloud import storage\n",
        "from vertexai.vision_models import ImageTextModel, Image\n",
        "from vertexai.vision_models import ImageTextModel, Image\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8583ddf9-0cbb-409e-bd47-0227cd7a807d",
      "metadata": {
        "id": "422453c723b9"
      },
      "outputs": [],
      "source": [
        "# generative AI helper\n",
        "\n",
        "\n",
        "def get_blocked_response_template():\n",
        "    blocked_response = {\n",
        "        \"response_error\": {\n",
        "            \"is_blocked\": True,\n",
        "            \"safety_attributes\": {},\n",
        "            \"message\": \"The response is blocked because the input or \"\n",
        "            \"response potentially violates Google's policies. \"\n",
        "            \"Try rephrasing the prompt or \"\n",
        "            \"adjusting the parameter settings.\",\n",
        "        }\n",
        "    }\n",
        "    return blocked_response\n",
        "\n",
        "\n",
        "def get_failed_faq_template():\n",
        "    failed_faq = {\"catalogue_faqs\": [{\"response_error\": \"\", \"llm_response\": \"\"}]}\n",
        "    return failed_faq\n",
        "\n",
        "\n",
        "def get_prompt(context, task, error=\"\", product_name=\"\"):\n",
        "    \"\"\"Gets the prompt for the given task.\"\"\"\n",
        "\n",
        "    # FAQ's, ISQ's constants\n",
        "\n",
        "    faq_json_format = \"\"\"{\n",
        "        \"catalogue_faqs\": [\n",
        "            {\"question\": \"What is the size of the paper\n",
        "            napkin produced by this machine?\",\n",
        "            \"answer\": \"The paper napkin produced by\n",
        "            this machine is 30 X 30 cm.\"},\n",
        "            {\"question\": \"What is the speed of this machine?\",\n",
        "            \"answer\": \"This machine can produce 2,50,000 pieces in 8 hours.\"},\n",
        "            {\"question\": \"How many colors can this machine print?\",\n",
        "            \"answer\": \"This machine can print up to 2 colors.\"},\n",
        "            {\"question\": \"What is the weight of this machine?\",\n",
        "            \"answer\": \"This machine weighs approximately 2500 kgs.\"},\n",
        "            {\"question\": \"How many people are required\n",
        "            to operate this machine?\",\n",
        "            \"answer\": \"This machine requires one\n",
        "            operator and one helper to operate.\"},\n",
        "            {\"question\": \"What type of raw material does this machine use?\",\n",
        "            \"answer\": \"This machine uses tissue paper with a gsm of 12 to 30.\"}\n",
        "        ]\n",
        "    }\"\"\"\n",
        "\n",
        "    sample_json_response = {\n",
        "        \"product_name\": [\n",
        "            \"SINGLE SIZE PAPER NAPKIN MACHINE\",\n",
        "        ],\n",
        "        \"specifications\": [\n",
        "            {\n",
        "                \"SINGLE SIZE PAPER NAPKIN MACHINE\": {\n",
        "                    \"Size\": \"30 X 30 CM\",\n",
        "                    \"No of Printing\": \"As Per Requirement\",\n",
        "                    \"Embossing Unit\": \"As Per Requirement\",\n",
        "                    \"Motor\": [\n",
        "                        \"3hp motor with variable\"\n",
        "                        \" AC drive with VDF (Variable frequency drive)\",\n",
        "                        \"1hp motor (AC)\",\n",
        "                    ],\n",
        "                    \"Speed\": \"2,50,000 PIECES / 8 HOURS\",\n",
        "                    \"Weight\": \"2500 kgs (approx)\",\n",
        "                    \"Man Power\": \"One operator & One helper\",\n",
        "                    \"Raw Material\": \"Tissue paper 12 to 30 gsm\",\n",
        "                    \"Counting\": \"digital\",\n",
        "                    \"PRICE WITHOUT PRINT\": \"4,50,000\",\n",
        "                    \"1 COLOUR PRINT\": \"5,75,000\",\n",
        "                    \"2 COLOUR PRINT\": \"6,25,000\",\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        \"confidence_score\": 0.8,\n",
        "    }\n",
        "\n",
        "    company_details_format = {\n",
        "        \"company_details\": {\n",
        "            \"company_name\": \"Global Conversion Machines\",\n",
        "            \"company_description\": \"\",\n",
        "            \"company_phone_number\": {\n",
        "                \"SALES TEAM\": \"+ 91 958 215 2344\",\n",
        "                \"MARKETING TEAM\": \"+ 91 874 482 8924\",\n",
        "                \"SERVICE TEAM\": \"+ 91 888 291 3467\",\n",
        "            },\n",
        "            \"company_email\": \"globalconversionmachines@gmail.com\",\n",
        "            \"company_website\": \"\",\n",
        "            \"company_social_handles\": {\n",
        "                \"twitter\": \"@globalcmachines\",\n",
        "                \"instagram\": \"@globalconversionmachines\",\n",
        "                \"youtube\": \"Global Conversion Machines\",\n",
        "            },\n",
        "            \"company_address\": \"\",\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # blocked_response = get_blocked_response_template()\n",
        "    malformed_json = \"\"\"\n",
        "    {\n",
        "        'product_name': ['Acrylic Body Rotameter'],\n",
        "        'specifications': [\n",
        "            {'Acrylic Body Rotameter': {\n",
        "                'Metering Tube': 'Solid Acrylic Block',\n",
        "                'Body': 'Imported transparent acrylic block',\n",
        "                'Wetted Parts': 'M.S. / S.S. / P.P. / Teflon',\n",
        "                'End Connection': 'S.S. 304/316/PVC/PP/MS',\n",
        "                'Scale': 'Engraved on body',\n",
        "                'Packing': 'Neoprene / Teflon / Silicon',\n",
        "                'Model': 'JP/ABR',\n",
        "                'Temperature': 'Max 60C',\n",
        "                'Pressure': 'Max 25 Kg/Cm',\n",
        "                'Available sizes': '1/8 to 100 NB',\n",
        "                'Flow Ranges': '2 to 60,000 LPH of water at\n",
        "                ambient temperature and 0.1 to 750 Nm/hr of air at NTP',\n",
        "                'End Connection': 'Screwed / Flanged / Hose Nipple',\n",
        "                'Orientation': 'Bottom Top / Rear Rear',\n",
        "                'Accuracy': '2% of FSD',\n",
        "                'Accessories': 'High & low flow alarms and 4-20\n",
        "                mA output on your request',\n",
        "                'THREDED CONNECTION': {\n",
        "                    'Line Size Flow rate (BSP CONNECTION)':\n",
        "                    'Water at amb.temp. in LPH',\n",
        "                    'Minimum LPH': 'Maximum LPH',\n",
        "                    'BSP 6': '60',\n",
        "                    'BSP 200': '2000',\n",
        "                    'BSP 400': '4000',\n",
        "                    '1 BSP': '500',\n",
        "                    '1.5 BSP': '1200',\n",
        "                    '2 BSP': '2500'\n",
        "                    }\n",
        "                }\n",
        "             },\n",
        "            'confidence_score': 0.8\n",
        "            }\n",
        "    \"\"\"\n",
        "\n",
        "    fixed_json = \"\"\"\n",
        "    {\n",
        "    \"product_name\": [\n",
        "    \"Acrylic Body Rotameter\"\n",
        "    ],\n",
        "    \"specifications\": [\n",
        "    {\n",
        "    \"Acrylic Body Rotameter\": {\n",
        "    \"Metering Tube\": \"Solid Acrylic Block\",\n",
        "    \"Body\": \"Imported transparent acrylic block\",\n",
        "    \"Wetted Parts\": \"M.S. / S.S. / P.P. / Teflon\",\n",
        "    \"End Connection\": \"S.S. 304/316/PVC/PP/MS\",\n",
        "    \"Scale\": \"Engraved on body\",\n",
        "    \"Packing\": \"Neoprene / Teflon / Silicon\",\n",
        "    \"Model\": \"JP/ABR\",\n",
        "    \"Temperature\": \"Max 60C\",\n",
        "    \"Pressure\": \"Max 25 Kg/Cm\",\n",
        "    \"Available sizes\": \"1/8 to 100 NB\",\n",
        "    \"Flow Ranges\": \"2 to 60,000 LPH of water\n",
        "    at ambient temperature and 0.1\n",
        "    to 750 Nm/hr of air at NTP\",\n",
        "    \"End Connection\": \"Screwed / Flanged / Hose Nipple\",\n",
        "    \"Orientation\": \"Bottom Top / Rear Rear\",\n",
        "    \"Accuracy\": \"2% of FSD\",\n",
        "    \"Accessories\": \"High & low flow alarms and 4-20 mA output on your request\",\n",
        "    \"THREDED CONNECTION\": {\n",
        "    \"Line Size Flow rate (BSP CONNECTION)\": \"Water at amb.temp. in LPH\",\n",
        "    \"Minimum LPH\": \"Maximum LPH\",\n",
        "    \"BSP 6\": \"60\",\n",
        "    \"BSP 200\": \"2000\",\n",
        "    \"BSP 400\": \"4000\",\n",
        "    \"1 BSP\": \"500\",\n",
        "    \"1.5 BSP\": \"1200\",\n",
        "    \"2 BSP\": \"2500\"\n",
        "    }\n",
        "    }\n",
        "    }\n",
        "    ],\n",
        "    \"confidence_score\": 0.9\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    non_woven_bag = {\n",
        "        \"tags\": [\"Industrial Machine\", \"Bag Making Machine\"],\n",
        "        \"suggested_category\": \"Non Woven Bag Making Machine\",\n",
        "    }\n",
        "\n",
        "    toilet_roll_machine = {\n",
        "        \"tags\": [\"Industrial Machine\", \"Paper Roll Machine\", \"Toilet Roll Machine\"],\n",
        "        \"suggested_category\": \"Toilet Roll Making Machine\",\n",
        "    }\n",
        "\n",
        "    malformed_faq = \"\"\"\n",
        "    {\n",
        "        \"catalogue_faqs\": [\n",
        "            {\"question\": \"What is the purpose of this diagram?\",\n",
        "            \"answer\": \"This diagram shows the piping and wiring\n",
        "            schematic for an AO Smith heat pump water heater.\"},\n",
        "            {\"question\": \"What are the different components\n",
        "            shown in the diagram?\",\n",
        "            \"answer\": \"The diagram shows the following components:\n",
        "            1)    Hot water to rooms\n",
        "            2)    Tank temp sensor\n",
        "            3)    Hot water outlet\n",
        "            4)    Flow switch\n",
        "            5)    Vibration pads\n",
        "            6)    Return water from rooms\n",
        "            7)    Cold water inlet to heat pump\n",
        "            8)    FFL note\"},\n",
        "            {\"question\": \"What are the different\n",
        "            steps involved in the operation of this system?\",\n",
        "            \"answer\": \"The steps involved in the\n",
        "            operation of this system are as follows:\n",
        "            1)    Cold water enters the heat pump through the cold water inlet.\n",
        "            2)    The heat pump heats the water\n",
        "            and sends it to the hot water tank.\n",
        "            3)    The hot water is then distributed to the\n",
        "            rooms through the hot water to rooms pipes.\n",
        "            4)    The return water from the rooms is then sent back to the\n",
        "            heat pump through the return water from rooms pipes.\n",
        "            5)    The process repeats itself.\"},\n",
        "            {\"question\": \"What are some of the important safety precautions\n",
        "            that should be taken when working on this system?\",\n",
        "            \"answer\": \"Some of the important safety precautions\n",
        "            that should be taken when working on this system include:\n",
        "            1)    Always turn off the power to the system before working on it.\n",
        "            2)    Be sure to use proper safety equipment,\n",
        "            such as gloves and eye protection.\n",
        "            3)    Never work on the system while it is hot.\n",
        "            4)    Be aware of the location of\n",
        "            all of the components in the system.\n",
        "            5)    If you are unsure about anything,\n",
        "            always consult a qualified professional.\"}\n",
        "        ]\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    fixed_faq = \"\"\"\n",
        "    {\"catalogue_faqs\": [{\"question\": \"What is the purpose of this diagram?\",\n",
        "    \"answer\": \"This diagram shows the piping and wiring schematic\n",
        "    for an AO Smith heat pump water heater.\"},\n",
        "    {\"question\": \"What are the different components shown in the diagram?\",\n",
        "    \"answer\": \"The diagram shows the following\n",
        "    components:\\n1) Hot water to rooms\\n2) Tank temp sensor\\n\n",
        "    3) Hot water outlet\\n4) Flow switch\\n\n",
        "    5) Vibration pads\\n6) Return water from rooms\\n\n",
        "    7) Cold water inlet to heat pump\\n8) FFL note\"},\n",
        "    {\"question\": \"What are the different\n",
        "     steps involved in the operation of this system?\",\n",
        "    \"answer\": \"The steps involved in the\n",
        "    operation of this system are as follows:\\n\n",
        "    1) Cold water enters the heat pump through the cold water inlet.\\n\n",
        "    2) The heat pump heats the water and sends it to the hot water tank.\\n\n",
        "    3) The hot water is then distributed to the\n",
        "    rooms through the hot water to rooms pipes.\\n\n",
        "    4) The return water from the rooms is then\n",
        "    sent back to the heat pump through the return water from rooms pipes.\\n\n",
        "    5) The process repeats itself.\"},\n",
        "    {\"question\": \"What are some of the important\n",
        "    safety precautions that should be taken when working on this system?\",\n",
        "    \"answer\": \"Some of the important safety\n",
        "    precautions that should be taken when working on this system include:\\n\n",
        "    1) Always turn off the power to the system before working on it.\\n\n",
        "    2) Be sure to use proper safety equipment,\n",
        "    such as gloves and eye protection.\\n\n",
        "    3) Never work on the system while it is hot.\\n\n",
        "    4) Be aware of the location of all of the components in the system.\\n\n",
        "    5) If you are unsure about anything,\n",
        "    always consult a qualified professional.\"}]}\n",
        "    \"\"\"\n",
        "\n",
        "    # failed_faq = get_failed_faq_template()\n",
        "\n",
        "    check_faq_prompt = f\"\"\"For the following text,\n",
        "    examine if it contains a description,\n",
        "    product specifications or features.\n",
        "    If found, return a boolean response True.\n",
        "     If not found, return a boolean response False.\n",
        "\n",
        "    {context}\"\"\"\n",
        "\n",
        "    faq_prompt = f\"\"\"Generate a list of frequently asked\n",
        "    questions (FAQ) based only on the provided input.\n",
        "\n",
        "    Extract the key points, common queries,\n",
        "    and important details to create a concise\n",
        "    and informative set of questions and\n",
        "    answers that would provide clarity on this subject for readers.\n",
        "\n",
        "    Return the output in JSON format.\n",
        "    input: 02 SINGLE SIZE PAPER NAPKIN\n",
        "    MACHINE Size: 30 X 30 CM No of Printing :\n",
        "    As Per Requirement Embossing Unit:\n",
        "    As Per Requirement Motor: 1) 3hp motor with variable\n",
        "    AC drive with VDF (Variable frequency drive)\n",
        "     2) 1hp motor (AC) Speed: 2,50,000 PIECES / 8 HOURS\n",
        "    Weight: 2500 kgs (approx) Man Power: One operator &\n",
        "    One helper Raw Material:\n",
        "    Tissue paper 12 to 30 gsm Counting: digital Counting Band saw\n",
        "     cutting with mauling sharping system PRICE WITHOUT PRINT : `4,50,000\n",
        "     1 COLOUR PRINT : `5,75,000 2 COLOUR PRINT : `6,25,000\n",
        "    output: {faq_json_format}\n",
        "\n",
        "    input: {context}\n",
        "    output:\n",
        "    \"\"\"\n",
        "\n",
        "    check_specs_prompt = f\"\"\"For the following text, examine\n",
        "    if it contains a product description, specifications\n",
        "    or features. If found, return a boolean response True.\n",
        "     If not found, return a boolean response False.\n",
        "\n",
        "    {context}\n",
        "    \"\"\"\n",
        "\n",
        "    product_specs_prompt = f\"\"\"Convert the following text into a\n",
        "    product specifications JSON containing \\\"product_name\\\"\n",
        "    and other \\\"specifications\\\".\n",
        "    Also, add a \\\"confidence_score\\\" to the end of the JSON.\n",
        "\n",
        "    input: 02 SINGLE SIZE PAPER NAPKIN MACHINE\n",
        "     Size: 30 X 30 CM No of Printing : As Per Requirement Embossing Unit:\n",
        "    As Per Requirement Motor: 1) 3hp\n",
        "    motor with variable AC drive with VDF (Variable frequency drive)\n",
        "    2) 1hp motor (AC) Speed: 2,50,000 PIECES / 8\n",
        "    HOURS Weight: 2500 kgs (approx) Man Power: One operator &\n",
        "    One helper Raw Material: Tissue paper 12 to\n",
        "    30 gsm Counting: digital Counting Band saw\n",
        "     cutting with mauling sharping system\n",
        "     PRICE WITHOUT PRINT :\n",
        "     `4,50,000 1 COLOUR PRINT :\n",
        "     `5,75,000 2 COLOUR PRINT : `6,25,00\n",
        "    output: {sample_json_response}\n",
        "\n",
        "    input: {context}\n",
        "    output:\n",
        "    \"\"\"\n",
        "\n",
        "    company_details_prompt = f\"\"\"Convert the following\n",
        "    text into a JSON containing company details.\n",
        "    Ensure that the details extracted\n",
        "    are based solely on the content of the\n",
        "    following text and are as accurate as possible.\n",
        "\n",
        "    input: CONTACT US COMPLETE MACHINE GLOBAL\n",
        "    CONVERSION MACHINES SALES TEAM MARKETING\n",
        "    TEAM SERVICE TEAM + 91 958 215 2344 + 91 874 482 8924 + 91 888 291 3467\n",
        "     Email : globalconversionmachines@gmail.com\n",
        "     Follow us on @ globalcmachines @\n",
        "     globalconversionmachines Global Conversion Machines\n",
        "    output: {company_details_format}\n",
        "\n",
        "    input: {context}\n",
        "    output:\n",
        "    \"\"\"\n",
        "\n",
        "    fix_json_prompt = f\"\"\"Fix the error/malformation\n",
        "    in the following JSON and ensure that you only return a valid JSON.\n",
        "\n",
        "    Error: {error}\n",
        "\n",
        "    input: {malformed_json}\n",
        "    output: {fixed_json}\n",
        "\n",
        "    input: {context}\n",
        "    output:\n",
        "    \"\"\"\n",
        "\n",
        "    tags_and_label_prompt = f\"\"\"Suggest some tags and\n",
        "     a category for the given product name and\n",
        "    description and convert it into JSON format.\n",
        "    Ensure that the suggestions are based solely on the content of\n",
        "    the text and are as accurate as possible.\n",
        "\n",
        "    input: Product Name: Non Woven Bag Making Machine\n",
        "    Product Description: 07 NON WOVEN BAG MAKING MACHINE Technical Speciﬁcation\n",
        "    Fabric Paper Tube Diameter: 2.75 -3 Inches\n",
        "    Max Speed: 20 -120 Bags /min Bag Width: 3.9-32\n",
        "    Inches Bag Height: 7.75-24mm Bottom Insert Size: 1.20-3.25 Inches\n",
        "    Side Folding Size: 1.20-3.25 Inches\n",
        "    Bag Thickness: 30-120g Power Supplier: 220v/380v Power: 12kw 15kw\n",
        "    Overall Dimension (L*w*h): 7600*1900*2100mm Weight: 2200 Kg Air\n",
        "    Compressor: 0.6-1.0 Mpa Unwinding Method: Magnetic Power Tension Control\n",
        "     Unwinding Diameter: 1000 Mm Max.width Of\n",
        "      Unwinding: 1300 Mm Correction Device: Photoelectric\n",
        "     Epc System An Synchronous Rectiﬁcation Motor 110w PRICE PRICE: ` 15,95,000\n",
        "    output: {non_woven_bag}\n",
        "\n",
        "    input: Product Name: Toilet Roll Machine\n",
        "    Product Description: 04 TOILET ROLL MACHINE PRODUCT PRICE PRODUCTION TYPE\n",
        "     1 4500 Rolls / 8 Hours Toilet Roll ` 4,75,000\n",
        "     TYPE 2 9000 Rolls / 8 Hours Toilet Roll,\n",
        "     ` 5,25,000 Kitchen Rolls ,\n",
        "      Non Woven Cleaning Rolls,\n",
        "      Hospital Bed Tissue Rolls.\n",
        "      TYPE 3 17,000 Rolls /\n",
        "      8 Hours Toilet Roll,\n",
        "      `11,50,000 Kitchen Rolls,\n",
        "      Non Woven Cleaning Rolls,\n",
        "      Hospital Bed Tissue Rolls.\n",
        "      TYPE 4 Any Customized Production Capacity\n",
        "    output: {toilet_roll_machine}\n",
        "\n",
        "    input: Product Name: {product_name}\n",
        "    Product Description: {context}\n",
        "    output:\n",
        "    \"\"\"\n",
        "\n",
        "    fix_faq_json_prompt = f\"\"\"Fix the error/malformation in the following\n",
        "    JSON and ensure that you only return a valid JSON.\n",
        "\n",
        "    Error: {error}\n",
        "\n",
        "    input: {malformed_faq}\n",
        "    output: {fixed_faq}\n",
        "\n",
        "    input: {context}\n",
        "    output:\n",
        "    \"\"\"\n",
        "\n",
        "    if task == \"faq\":\n",
        "        return faq_prompt\n",
        "    elif task == \"specs\":\n",
        "        return product_specs_prompt\n",
        "    elif task == \"check_specs\":\n",
        "        return check_specs_prompt\n",
        "    elif task == \"company_details\":\n",
        "        return company_details_prompt\n",
        "    elif task == \"image_tags_and_labels\":\n",
        "        return tags_and_label_prompt\n",
        "    elif task == \"fix_json\":\n",
        "        return fix_json_prompt\n",
        "    elif task == \"fix_faq_json\":\n",
        "        return fix_faq_json_prompt\n",
        "    else:\n",
        "        return check_faq_prompt\n",
        "\n",
        "\n",
        "def fix_json(error, context, project):\n",
        "    try:\n",
        "        fix_json_prompt = get_prompt(context, \"fix_json\", error)\n",
        "        fix_json_response = vertex_ai_llm(fix_json_prompt)\n",
        "        if not fix_json_response.is_blocked:\n",
        "            response = ast.literal_eval(\n",
        "                fix_json_response.text.strip().replace(\"null\", \"None\")\n",
        "            )\n",
        "            print(\"[INFO]: JSON fixed successfully!\")\n",
        "        else:\n",
        "            print(\"[WARNING]: Fix JSON Response Blocked by LLM.\")\n",
        "            response = get_blocked_response_template()\n",
        "            response[\"response_error\"][\n",
        "                \"safety_attributes\"\n",
        "            ] = fix_json_response.safety_attributes\n",
        "            return response\n",
        "\n",
        "        return response\n",
        "\n",
        "    except SyntaxError as e:\n",
        "        print(\n",
        "            f\"[ERROR]: SyntaxError during fixing JSON. The LLM may have\"\n",
        "            f\" again returned a malformed JSON! \\n{e}\\n\"\n",
        "        )\n",
        "        print(fix_json_response.text.strip())\n",
        "        response = get_blocked_response_template()\n",
        "        response[\"response_error\"][\"is_blocked\"] = False\n",
        "        response[\"response_error\"][\n",
        "            \"message\"\n",
        "        ] = f\"\"\"The LLM repeatedly returned\n",
        "            malformed JSON's!\n",
        "            \\n{fix_json_response.text.strip().\n",
        "        replace('null', 'None')}\"\"\"\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR]: Unknown error during fixing JSON. \\n{e}\\n\")\n",
        "        print(fix_json_response.text.strip())\n",
        "        response = get_blocked_response_template()\n",
        "        response[\"response_error\"][\"is_blocked\"] = False\n",
        "        response[\"response_error\"][\n",
        "            \"message\"\n",
        "        ] = f\"\"\"{fix_json_response.text.strip().replace('null', 'None')}\"\"\"\n",
        "        return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac42eaab-f039-4978-bacb-0e41987ddc22",
      "metadata": {
        "id": "149439b1904d"
      },
      "outputs": [],
      "source": [
        "def generate_tags_and_labels(context, products, project):\n",
        "    try:\n",
        "        tags_and_labels = {}\n",
        "        for product in products:\n",
        "            tags_and_labels_prompt = get_prompt(context,\n",
        "                                                \"image_tags_and_labels\",\n",
        "                                                product_name=product)\n",
        "            tags_and_labels_response = \\\n",
        "                vertex_ai_llm(tags_and_labels_prompt)\n",
        "            if not tags_and_labels_response.is_blocked:\n",
        "                response = ast.literal_eval(tags_and_labels_response.\n",
        "                                            text.strip())\n",
        "                tags_and_labels[product] = response\n",
        "            else:\n",
        "                print(\"Tags and Label Generation Response Blocked by LLM.\")\n",
        "                response = get_blocked_response_template()\n",
        "                response[\"response_error\"][\"safety_attributes\"] =\\\n",
        "                    tags_and_labels_response.safety_attributes\n",
        "                return response\n",
        "            return tags_and_labels\n",
        "\n",
        "    except SyntaxError as e:\n",
        "        print(\n",
        "            f\"[ERROR]: SyntaxError during Tags \"\n",
        "            f\"and Label generation. \"\n",
        "            f\"The LLM may have returned a malformed JSON! \\n{e}\")\n",
        "        print(tags_and_labels_response.text.strip())\n",
        "        return {}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR]: Unknown error \"\n",
        "              f\"during Tags and Label generation. \\n{e}\")\n",
        "        print(tags_and_labels_response.text.strip())\n",
        "        return {}\n",
        "\n",
        "\n",
        "def generate_isqs(context, project):\n",
        "    try:\n",
        "        product_specs_prompt = get_prompt(context, \"specs\")\n",
        "        product_isqs = vertex_ai_llm(product_specs_prompt)\n",
        "        if not product_isqs.is_blocked:\n",
        "            isq_response = \\\n",
        "                ast.literal_eval(product_isqs.text.\n",
        "                                 strip().replace('null', \"None\"))\n",
        "        else:\n",
        "            print(f\"[WARNING]: ISQ Generation Response \"\n",
        "                  f\"blocked by LLM: {product_isqs.safety_attributes}\")\n",
        "            isq_response = get_blocked_response_template()\n",
        "            isq_response[\"response_error\"][\"safety_attributes\"] = \\\n",
        "                product_isqs.safety_attributes\n",
        "            return isq_response\n",
        "\n",
        "        return isq_response\n",
        "\n",
        "    except SyntaxError as e:\n",
        "        print(f\"[ERROR]: SyntaxError during ISQ generation. \"\n",
        "              f\"The LLM may have returned a malformed JSON! \\n{e}\\n\")\n",
        "        print(product_isqs.text.strip())\n",
        "        isq_response = fix_json(e, product_isqs.text.strip())\n",
        "        return isq_response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR]: Unknown error during ISQ generation. \\n{e}\\n\")\n",
        "        print(product_isqs.text.strip())\n",
        "        isq_response = get_blocked_response_template()\n",
        "        isq_response[\"response_error\"][\"is_blocked\"] = False\n",
        "        isq_response[\"response_error\"][\"message\"] = \\\n",
        "            f\"\"\"{product_isqs.text.strip().replace('null', 'None')}\"\"\"\n",
        "        return isq_response\n",
        "\n",
        "\n",
        "def generate_faqs(context, project):\n",
        "    try:\n",
        "        get_faq_prompt = get_prompt(context, \"faq\")\n",
        "        faq_response = vertex_ai_llm(get_faq_prompt)\n",
        "        if not faq_response.is_blocked:\n",
        "            response = \\\n",
        "                ast.literal_eval(faq_response.\n",
        "                                 text.strip().\n",
        "                                 replace('null', 'None'))\n",
        "        else:\n",
        "            print(f\"[WARNING]: FAQ Generation \"\n",
        "                  f\"Response Blocked by LLM. {faq_response.safety_attributes}\")\n",
        "            response = get_blocked_response_template()\n",
        "            response[\"response_error\"][\"safety_attributes\"] =\\\n",
        "                faq_response.safety_attributes\n",
        "            return response\n",
        "\n",
        "        return response\n",
        "\n",
        "    except SyntaxError as e:\n",
        "        print(f\"[ERROR]: SyntaxError during FAQ generation.\"\n",
        "              f\" The LLM may have returned a malformed JSON! \\n{e}\\n\")\n",
        "        print(faq_response.text.strip())\n",
        "        response = fix_faq_json(e, faq_response.text.strip())\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR]: Unknown error during FAQ generation. \\n{e}\\n\")\n",
        "        print(faq_response.text.strip())\n",
        "        response = get_failed_faq_template()\n",
        "        response[\"catalogue_faqs\"][0][\"response_error\"] = f\"{e}\"\n",
        "        response[\"catalogue_faqs\"][0][\"llm_response\"] = \\\n",
        "            f\"{faq_response.text.strip().replace('null', 'None')}\"\n",
        "        return response\n",
        "\n",
        "\n",
        "def generate_company_details(company_text, project):\n",
        "    try:\n",
        "        response = {}\n",
        "        company_details_prompt = get_prompt(company_text, \"company_details\")\n",
        "        company_details_response = \\\n",
        "            vertex_ai_llm(company_details_prompt)\n",
        "        if not company_details_response.is_blocked:\n",
        "            response = \\\n",
        "                ast.literal_eval(company_details_response.\n",
        "                                 text.strip().\n",
        "                                 replace('null', 'None'))\n",
        "            print(\"[INFO]: Company Details Extraction Completed\")\n",
        "        else:\n",
        "            print(\n",
        "                f\"[WARNING]: Company Details Extraction  \"\n",
        "                f\"Response blocked by LLM. \"\n",
        "                f\"{company_details_response.safety_attributes}\")\n",
        "            response = get_blocked_response_template()\n",
        "            response[\"response_error\"][\"safety_attributes\"] = \\\n",
        "                company_details_response.safety_attributes\n",
        "            return response\n",
        "\n",
        "        return response\n",
        "\n",
        "    except SyntaxError as e:\n",
        "        print(\n",
        "            f\"[ERROR]: SyntaxError during company\"\n",
        "            f\" details extraction. The LLM\"\n",
        "            f\" may have returned a malformed JSON! \\n{e}\\n\")\n",
        "        print(company_details_response.text.strip())\n",
        "        return {}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR]: Unknown error during \"\n",
        "              f\"company details extraction. \\n{e}\\n\")\n",
        "        print(company_details_response.text.strip())\n",
        "        return {}\n",
        "\n",
        "\n",
        "def fix_faq_json(error, context):\n",
        "    try:\n",
        "        fix_json_prompt = get_prompt(context, \"fix_faq_json\", error)\n",
        "        fix_json_response = vertex_ai_llm(fix_json_prompt)\n",
        "        if not fix_json_response.is_blocked:\n",
        "            response = \\\n",
        "                ast.literal_eval(fix_json_response.\n",
        "                                 text.strip().replace('null', 'None'))\n",
        "            print(\"[INFO]: JSON fixed successfully!\")\n",
        "        else:\n",
        "            print(\"[WARNING]: Fix JSON Response Blocked by LLM.\")\n",
        "            response = get_blocked_response_template()\n",
        "            response[\"response_error\"][\"safety_attributes\"] = \\\n",
        "                fix_json_response.safety_attributes\n",
        "            return response\n",
        "\n",
        "        return response\n",
        "\n",
        "    except SyntaxError as e:\n",
        "        print(f\"[ERROR]: SyntaxError during fixing FAQ JSON. \"\n",
        "              f\"The LLM may have again returned a malformed JSON! \\n{e}\\n\")\n",
        "        print(fix_json_response.text.strip())\n",
        "        response = get_failed_faq_template()\n",
        "        response[\"catalogue_faqs\"][0][\"response_error\"] = f\"{e}\"\n",
        "        response[\"catalogue_faqs\"][0][\"llm_response\"] = \\\n",
        "            f\"{fix_json_response.text.strip().replace('null', 'None')}\"\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR]: Unknown error during fixing FAQ JSON. \\n{e}\\n\")\n",
        "        print(fix_json_response.text.strip())\n",
        "        response = get_failed_faq_template()\n",
        "        response[\"catalogue_faqs\"][0][\"response_error\"] = f\"{e}\"\n",
        "        response[\"catalogue_faqs\"][0][\"llm_response\"] = \\\n",
        "            f\"{fix_json_response.text.strip().replace('null', 'None')}\"\n",
        "        return response\n",
        "\n",
        "\n",
        "def vertex_ai_llm(prompt):\n",
        "    try:\n",
        "        model = TextGenerationModel.from_pretrained(\"text-bison\")\n",
        "        response = model.predict(prompt, \"candidate_count\": 1,\n",
        "            \"max_output_tokens\": 1024,\n",
        "            \"temperature\": 0,\n",
        "            \"top_p\": 0.95,\n",
        "            \"top_k\": 40)\n",
        "        return response.text\n",
        "    except Exception:\n",
        "        print(f\"[ERROR]: Vertex AI LLM API failed -\"\n",
        "              f\" {str(traceback.format_exc())}\")\n",
        "        return ''\n",
        "\n",
        "\n",
        "def visual_question(image, question):\n",
        "    try:\n",
        "        model = ImageTextModel.from_pretrained(\"imagetext@001\")\n",
        "        source_image = Image(image)\n",
        "        answers = model.ask_question(\n",
        "            image=source_image,\n",
        "            question=question,\n",
        "            # Optional:\n",
        "            number_of_results=3,\n",
        "        )\n",
        "        return answers\n",
        "    except Exception:\n",
        "        print(f\"[ERROR]: Vertex AI VQA \"\n",
        "              f\"API failed - {str(traceback.format_exc())}\")\n",
        "        return ['', '', '']\n",
        "\n",
        "\n",
        "def image_caption(image):\n",
        "    try:\n",
        "        model = ImageTextModel.from_pretrained(\"imagetext@001\")\n",
        "        source_image = Image(image)\n",
        "        captions = model.get_captions(\n",
        "            image=source_image,\n",
        "            # Optional:\n",
        "            number_of_results=3,\n",
        "            language=\"en\",\n",
        "        )\n",
        "        return captions\n",
        "    except Exception:\n",
        "        print(f\"[ERROR]: Vertex AI Image caption API failed \"\n",
        "              f\"- {str(traceback.format_exc())}\")\n",
        "        return ['', '', '']\n",
        "\n",
        "\n",
        "def get_options(products, product_descriptions=False):\n",
        "    options = \"\"\n",
        "    for product_no, product in enumerate(products):\n",
        "        product = product.replace(\"'\", \"\")\n",
        "        product = product.replace('\"', \"\")\n",
        "        product = product.replace(\"\\n\", \"\")\n",
        "        # product = product.replace(\"\\n\",\"\")\n",
        "        # if product not in products_image_map:\n",
        "        #     products_image_map[product] = []\n",
        "        options = options + f\"{str(product_no + 1)}. {product}\\n\"\n",
        "    return options\n",
        "\n",
        "\n",
        "def product_description_from_text_prompt(text, products):\n",
        "    options = get_options(products)\n",
        "    prompt = f\"\"\"\n",
        "This is the extracted text from pdf page.\n",
        "As it is extracted using OCR, the order\n",
        "of the words and spellings might not be completely correct.\\\n",
        "you need to provide short product caption\n",
        "based on the extracted text in json format\n",
        "\n",
        "Example Extracted Text\n",
        "Product A is a bench .\n",
        " It is of white color.\n",
        " I am having a good day.\n",
        "  I need a toilet roll making machine like product B.\n",
        "\n",
        "Example Input products:\n",
        "1. Product A\n",
        "2. Product B\n",
        "\n",
        "Example Output format:\n",
        "```\n",
        "json\n",
        "{str({\"Product A\": \"it is a white colored bench\",\n",
        "      \"Product B\": \"It is a machine which is used to make toilet rolls.\"})}\n",
        "```\n",
        "\n",
        "\n",
        "Extracted Text:\n",
        "```\n",
        "{text.replace(\"'\", \"\").replace('\"', \"\")}\n",
        "```\n",
        "\n",
        "Input products:\n",
        "{options}\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def product_tags_from_text_prompt(text, products):\n",
        "    options = get_options(products)\n",
        "    prompt = f\"\"\"\n",
        "This is the extracted text from pdf page. As it is extracted using OCR,\n",
        "the order of the words and spellings might not be completely correct.\\\n",
        "you need to provide 3 tags for each of the products based\n",
        "on the extracted text in json format\n",
        "\n",
        "Example Extracted Text\n",
        "Toilet roll making machine can make toilet rolls easily. Its weight is 2kg.\n",
        "Contly medicine tablets can cure liver diseases. It has no side effects.\n",
        "\n",
        "Example Input products:\n",
        "1. Toilet Roll Machine\n",
        "2. Contly\n",
        "\n",
        "Example Output format:\n",
        "```\n",
        "json\n",
        "{str({\"Toilet Roll Machine\": [\"machine\", \"industrial machine\", \"tool\"],\n",
        "      \"Contly\": [\"capsule\", \"medicine\", \"tablet\"]})}\n",
        "```\n",
        "\n",
        "\n",
        "Extracted Text:\n",
        "```\n",
        "{text.replace(\"'\", \"\").replace('\"', \"\")}\n",
        "```\n",
        "\n",
        "Input products:\n",
        "{options}\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def product_category_from_text_prompt(text, products):\n",
        "    options = get_options(products)\n",
        "    prompt = f\"\"\"\n",
        "This is the extracted text from pdf page.\n",
        "As it is extracted using OCR,\n",
        "the order of the words and spellings might not be completely correct.\n",
        "you need to provide product category\n",
        "for each of the products based on\n",
        "the extracted text in json format\n",
        "\n",
        "Example Extracted Text\n",
        "Toilet roll making machine can make toilet rolls easily.\n",
        "It's weight is 2kg.\n",
        " Contly medicine tablets can cure liver diseases. It has no side effects.\n",
        "\n",
        "Example Input products:\n",
        "1. Toilet Roll Machine\n",
        "2. Contly\n",
        "\n",
        "Example Output format:\n",
        "```\n",
        "json\n",
        "{str({\"Toilet Roll Machine\": \"toilet roll making machine\",\n",
        "      \"Contly\": \"liver medicine\"})}\n",
        "```\n",
        "```\n",
        "\n",
        "\n",
        "Extracted Text:\n",
        "```\n",
        "{text.replace(\"'\", \"\").replace('\"', \"\")}\n",
        "```\n",
        "\n",
        "Input products:\n",
        "{options}\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def map_product_and_image(images, products, product_description):\n",
        "    example_json = {\"Product_A\": \"Image 3\",\n",
        "                    \"Product_B\": \"Image 7\",\n",
        "                    \"Product_C\": \"\",\n",
        "                    \"Product_D\": \"Image 2\"}\n",
        "    images_str = \"\"\n",
        "    for image_no, image in enumerate(images, start=1):\n",
        "        image_name = f\"Image {str(image_no)}\\n\"\n",
        "        caption1 = image[\"caption1\"].replace('\"', '').replace(\"'\", \"\")\n",
        "        caption2 = image[\"caption2\"].replace('\"', '').replace(\"'\", \"\")\n",
        "        images_str = images_str + f\"{image_name}\\nMain Caption -\" \\\n",
        "                                  f\" reliable and correct:\" \\\n",
        "                                  f\"\\n{caption1}\\n\\nSpecific Caption \" \\\n",
        "                                  f\"Guesses which can be \" \\\n",
        "                                  f\"incorrect:\\n{caption2}\\n\\n\"\n",
        "\n",
        "    products_str = get_options(products)\n",
        "\n",
        "    product_description_str = \"\"\n",
        "    for product_no, product in enumerate(products, start=1):\n",
        "        if product in product_description:\n",
        "            product_desc = product_description[product]\n",
        "            product = product.replace(\"'\", \"\")\n",
        "            product = product.replace('\"', \"\")\n",
        "            product = product.replace(\"\\n\", \"\")\n",
        "            product_description_str = \\\n",
        "                product_description_str + f\"{product}: {str(product_desc)}\\n\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You need to map products with images.\n",
        "\n",
        "For images we have generated 2 types of captions using different methods.\n",
        "\n",
        "\n",
        "Main caption of image is generic but it is accurate.\n",
        "Specific caption guesses of image might\n",
        "be very specific but can be sometimes wrong.\n",
        "Specific caption guesses contain 3 values,\n",
        "with 1st one has higher chances of being correct\n",
        "and 3rd one has comparatively lower chances of being correct.\n",
        "\n",
        "\n",
        "Very Important points to remember:\n",
        "1. A product can only be mapped to maximum one image only.\n",
        "2. An image can only be mapped to maximum one product only.\n",
        "3. There is also possibility that there will no image for a product.\n",
        "4. There is also possibility that an image is not relevant to any product.\n",
        "\n",
        "Output should be in json format with product as key\n",
        "and mapped image as value. If no image can be\n",
        "mapped for a product, then simply keep its value as empty.\n",
        "\n",
        "Output format:\n",
        "```\n",
        "json\n",
        "{example_json}\n",
        "```\n",
        "\n",
        "Products are as follows:\n",
        "\n",
        "{products_str}\n",
        "\n",
        "To better understand products, we also have mapped\n",
        "tags for some of the products, might not be there for all products.\n",
        "Compare the main caption with product\n",
        "tags for more accurate product image mapping.\n",
        "Check product tags properly, so that\n",
        "you dont confuse similar name object with actual products.\n",
        "example: image of toilet rolls are not\n",
        "to be confused or mapped with toilet roll making machine\n",
        "Here are product tags:\n",
        "{product_description_str}\n",
        "\n",
        "\n",
        "Images are as follows:\n",
        "\n",
        "{images_str}\n",
        "\n",
        "\n",
        "Output:\n",
        "\"\"\"\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e7ea65-7dca-4b5a-8b7b-e31bb86f1b3e",
      "metadata": {
        "id": "bf9ae533472a"
      },
      "outputs": [],
      "source": [
        "def llm_json_to_dict(llm_json_text):\n",
        "  \"\"\"\n",
        "  Converts a string containing LLM-generated JSON into a Python dictionary.\n",
        "  Handles cases where JSON may have single quotes instead of double quotes.\n",
        "  \"\"\"\n",
        "    try:\n",
        "        start = llm_json_text.rfind('{')\n",
        "        end = llm_json_text.rfind('}')\n",
        "        answers = llm_json_text[start:end + 1]\n",
        "        answer_dict = json.loads(answers)\n",
        "        return answer_dict\n",
        "    except Exception:\n",
        "        start = llm_json_text.rfind('{')\n",
        "        end = llm_json_text.rfind('}')\n",
        "        answers = llm_json_text[start:end + 1].replace(\"'\", '\"')\n",
        "        answer_dict = json.loads(answers)\n",
        "        return answer_dict\n",
        "\n",
        "\n",
        "def get_specific_caption(pdf_json):\n",
        "  \"\"\"\n",
        "  Extracts images with red bounding boxes from a PDF, generates captions for them, \n",
        "  and adds the captions to the provided JSON data.\n",
        "  \"\"\"\n",
        "    try:\n",
        "        pdf_gcs_uri = pdf_json[\"file_url\"]\n",
        "        pdf_gcs_path = pdf_gcs_uri.replace(\"gs://\", \"\")\n",
        "        input_gcs_bucket = pdf_gcs_path.split(\"/\")[0]\n",
        "        filename = pdf_gcs_path.replace(f\"{input_gcs_bucket}/\", \"\")\n",
        "        bucket_object = storage.Client().bucket(input_gcs_bucket)\n",
        "        blob = bucket_object.blob(filename)\n",
        "        zoom = 1\n",
        "        mat = fitz.Matrix(zoom, zoom)\n",
        "        k = 0\n",
        "        all_done = False\n",
        "        max_images = 0\n",
        "        while not all_done:\n",
        "            pdf_file = fitz.open(\"pdf\", blob.download_as_bytes())\n",
        "            for page_index, page in enumerate(pdf_file):\n",
        "                images_info = pdf_json[\"pages\"][page_index][\"images\"]\n",
        "                no_of_images = len(images_info)\n",
        "                if no_of_images > max_images:\n",
        "                    max_images = no_of_images\n",
        "                if no_of_images > k:\n",
        "                    images_info_left = images_info[k:]\n",
        "                    for i, image_info in \\\n",
        "                            enumerate(images_info_left, start=k + 1):\n",
        "                        bbox = image_info[\"bbox\"]\n",
        "                        page.draw_rect([bbox[0] - 2,\n",
        "                                        bbox[1] - 2,\n",
        "                                        bbox[2] + 2,\n",
        "                                        bbox[3] + 2],\n",
        "                                       color=(1, 0, 0), width=3)\n",
        "                        pix = page.get_pixmap(matrix=mat)\n",
        "                        pix.save(\"img.png\")\n",
        "                        with open(\"img.png\", \"rb\") as image:\n",
        "                            img = image.read()\n",
        "                        question = \"What is there in the \" \\\n",
        "                                   \"image which is highlighted \" \\\n",
        "                                   \"by a red bounding box?\"\n",
        "                        captions = visual_question(img, question)\n",
        "                        temp = pdf_json[\"pages\"][page_index]\n",
        "                        temp[\"images\"][k][\"specific_captions\"] \\\n",
        "                            = captions\n",
        "                        break\n",
        "            k = k + 1\n",
        "            if k >= max_images:\n",
        "                all_done = True\n",
        "    except Exception:\n",
        "        print(f\"[ERROR]: Specific caption \"\n",
        "              f\"generation failed - {str(traceback.format_exc())}\")\n",
        "    return pdf_json\n",
        "\n",
        "\n",
        "def parse_prod_name(products, product_description):\n",
        "  \"\"\"\n",
        "  Parses product names to match descriptions, ensuring consistency \n",
        "  and handling variations in formatting.\n",
        "  \"\"\"\n",
        "    product_description_int = {}\n",
        "    for product in product_description:\n",
        "        x = re.sub(r'\\W+', '', product)\n",
        "        x = x.lower()\n",
        "        product_description_int[x] = product_description[product]\n",
        "    product_description_final = {}\n",
        "    for product in products:\n",
        "        x = re.sub(r'\\W+', '', product)\n",
        "        x = x.lower()\n",
        "        if x in product_description_int:\n",
        "            product_description_final[product] = product_description_int[x]\n",
        "    return product_description_final\n",
        "\n",
        "\n",
        "def generate_tags_json(context, products):\n",
        "  \"\"\"\n",
        "  Generates a JSON structure containing product tags, using LLM assistance \n",
        "  and ensuring consistency with provided product names.\n",
        "  \"\"\"\n",
        "    product_tags_prompt = product_tags_from_text_prompt(context, products)\n",
        "    product_tags = vertex_ai_llm(product_tags_prompt)\n",
        "    product_tags = llm_json_to_dict(product_tags)\n",
        "    product_tags = parse_prod_name(products, product_tags)\n",
        "    return product_tags\n",
        "\n",
        "\n",
        "def generate_category_json(context, products):\n",
        "  \"\"\"\n",
        "  Generates a JSON structure containing product categories, using LLM assistance\n",
        "  and ensuring consistency with provided product names.\n",
        "  \"\"\"\n",
        "    product_category_prompt = \\\n",
        "        product_category_from_text_prompt(context, products)\n",
        "    product_category = vertex_ai_llm(product_category_prompt)\n",
        "    product_category = llm_json_to_dict(product_category)\n",
        "    product_category = parse_prod_name(products, product_category)\n",
        "    return product_category\n",
        "\n",
        "\n",
        "def generate_images_json(page, products, product_tags, bucket_name):\n",
        "  \"\"\" \n",
        "  Generates a JSON structure mapping products to their associated images and captions, \n",
        "  utilizing LLM assistance for enhanced matching.\n",
        "  \"\"\"\n",
        "    products_image_map = {}\n",
        "    # product_descriptions = {}\n",
        "    images = page[\"images\"]\n",
        "    # text = page[\"texts\"][\"full_text\"]\n",
        "    if len(products) > 0:\n",
        "        images_captions = []\n",
        "        for image_no, image in enumerate(images):\n",
        "            url = image['image_url']\n",
        "            # print(url)\n",
        "            filename = url.replace(f\"gs://{bucket_name}/\", \"\")\n",
        "            # print(filename)\n",
        "            bucket = storage.Client().bucket(bucket_name)\n",
        "            blob = bucket.get_blob(filename)\n",
        "            img = blob.download_as_bytes()\n",
        "            captions = image_caption(img)\n",
        "            images[image_no][\"captions\"] = captions\n",
        "            # display(Img(img))\n",
        "            # print(captions)\n",
        "            try:\n",
        "                specific_captions = image[\"specific_captions\"]\n",
        "            except Exception as err:\n",
        "                print(f\"[ERROR]: No specific caption generated - {err}\")\n",
        "                specific_captions = ['', '', '']\n",
        "            try:\n",
        "                caption1 = captions[0]\n",
        "            except Exception as err:\n",
        "                print(f\"[ERROR]: No generic caption generated - {err}\")\n",
        "                caption1 = '\\n'\n",
        "            images_captions.append({\"image\": image,\n",
        "                                    \"caption1\": caption1,\n",
        "                                    \"caption2\": str(specific_captions)})\n",
        "        prompt = map_product_and_image(images_captions, products, product_tags)\n",
        "        response = vertex_ai_llm(prompt)\n",
        "        products_image_map = llm_json_to_dict(response)\n",
        "    product_images = {}\n",
        "    for product in products_image_map:\n",
        "        try:\n",
        "            image_no = int(products_image_map[product])\n",
        "            image = images[image_no - 1]\n",
        "            generic_caption = image[\"captions\"]\n",
        "            specific_caption = image[\"specific_captions\"]\n",
        "            url = image['image_url']\n",
        "            filename = url.replace(f\"gs://{bucket_name}/\", \"\")\n",
        "            blob = bucket.get_blob(filename)\n",
        "            img = blob.download_as_bytes()\n",
        "            # display(Img(img))\n",
        "            product_images[product] = {\"image_url\": url,\n",
        "                                       \"generic_caption\": generic_caption,\n",
        "                                       \"specific_caption\": specific_caption}\n",
        "        except Exception:\n",
        "            product_images[product] = \"No image found\"\n",
        "    return product_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4f3f63f8-c829-44bd-ade6-779dc95f9e58",
      "metadata": {
        "id": "58833bafe358"
      },
      "outputs": [],
      "source": [
        "def load_json(path):\n",
        "    \"\"\"Loads a JSON file from the given path.\"\"\"\n",
        "    with open(path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "def write_json(data, path):\n",
        "    \"\"\"Writes a JSON dictionary to the given path.\"\"\"\n",
        "    with open(path, \"w\") as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "\n",
        "def clean_text(pdf_json):\n",
        "    try:\n",
        "        for page in pdf_json[\"pages\"]:\n",
        "            text = page[\"texts\"][\"full_text\"]\n",
        "            unicode_pattern = r\"[\\u0080-\\uFFFF]\"\n",
        "            filtered_text = re.sub(\"\\\\s{2,}\", \" \", re.sub(unicode_pattern, \"\", text))\n",
        "            page[\"texts\"][\"full_text\"] = (\n",
        "                filtered_text.replace(\":\", \"\")\n",
        "                .replace(\"\\n\", \" \")\n",
        "                .replace(\"{\", \"(\")\n",
        "                .replace(\"[\", \"(\")\n",
        "                .replace(\"}\", \")\")\n",
        "                .replace(\"]\", \")\")\n",
        "                .replace(\"(\", \"\")\n",
        "                .replace(\")\", \"\")\n",
        "                .strip()\n",
        "            )\n",
        "        print(\"[INFO]: Text cleaning completed successfully.\")\n",
        "        return pdf_json\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR]: Error during text cleaning - {e}\")\n",
        "        return {}\n",
        "\n",
        "\n",
        "def get_company_text(text_list):\n",
        "    try:\n",
        "        if len(text_list) == 1:\n",
        "            return text_list[0][\"texts\"][\"full_text\"]\n",
        "        elif len(text_list) > 4:\n",
        "            return f\"\"\"{text_list[0]['texts']['full_text']} \\\n",
        "            {text_list[1]['texts']['full_text']} \\\n",
        "            {text_list[-2]['texts']['full_text']} \\\n",
        "            {text_list[-1]['texts']['full_text']}\"\"\"\n",
        "        else:\n",
        "            return f\"\"\"{text_list[0]['texts']['full_text']}\\\n",
        "                       {text_list[-1]['texts']['full_text']}\"\"\"\n",
        "    except IndexError as e:\n",
        "        print(f\"[ERROR]: Found an empty list in PDF JSON - {e}\")\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR]: Unknown error during company text extraction - {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d96fd153-0a4e-4c77-8deb-9eaa2366a7f3",
      "metadata": {
        "id": "1c1ba2da5205"
      },
      "outputs": [],
      "source": [
        "def image_info_for_page(pdf_file, images_path, page, page_index, gcs_bucket=None):\n",
        "    images_info = page.get_images()\n",
        "    # print(len(images_info))\n",
        "    bound = page.bound()\n",
        "    xmin, ymin, xmax, ymax = bound[0], bound[1], bound[2], bound[3]\n",
        "    images = []\n",
        "    i = 0\n",
        "    for i_no, image_info in enumerate(images_info, start=1):\n",
        "        try:\n",
        "            image_xref = image_info[0]\n",
        "            image_id = image_info[7]\n",
        "            # print(image_id)\n",
        "            # print(image_xref, image_id)\n",
        "            bbox = page.get_image_bbox(image_id)\n",
        "            if (\n",
        "                (bbox[0] < xmin or bbox[0] > xmax)\n",
        "                and (bbox[2] < xmin or bbox[2] > xmax)\n",
        "            ) or (\n",
        "                (bbox[1] < ymin or bbox[1] > ymax)\n",
        "                and (bbox[3] < ymin or bbox[3] > ymax)\n",
        "            ):\n",
        "                continue\n",
        "            # print(bbox)\n",
        "            base_image = pdf_file.extract_image(image_xref)\n",
        "            # Store image bytes\n",
        "            image_bytes = base_image[\"image\"]\n",
        "            # Store image extension\n",
        "            image_ext = base_image[\"ext\"]\n",
        "            if not (\n",
        "                str(image_ext.lower()) == \"jpeg\"\n",
        "                or str(image_ext.lower()) == \"jpg\"\n",
        "                or str(image_ext.lower()) == \"png\"\n",
        "            ):\n",
        "                continue\n",
        "            i = i + 1\n",
        "            # Generate image file name\n",
        "            image_name = str(page_index) + \"_\" + str(i) + \".\" + image_ext\n",
        "            image_name = os.path.join(images_path, image_name)\n",
        "            if gcs_bucket:\n",
        "                url = f\"gs://{gcs_bucket}/{image_name}\"\n",
        "                bucket_object = storage.Client().bucket(gcs_bucket)\n",
        "                image_name = bucket_object.blob(image_name)\n",
        "                with image_name.open(\"wb\") as image_file:\n",
        "                    image_file.write(image_bytes)\n",
        "            else:\n",
        "                url = image_name\n",
        "                with open(image_name, \"wb\") as image_file:\n",
        "                    image_file.write(image_bytes)\n",
        "            image = {\n",
        "                \"xref\": image_xref,\n",
        "                \"id\": image_id,\n",
        "                \"image_url\": url,\n",
        "                \"bbox\": (bbox[0], bbox[1], bbox[2], bbox[3]),\n",
        "            }\n",
        "            # print(image_name)\n",
        "            # print(image[\"bbox\"])\n",
        "            images.append(image)\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR]: extracting an image - {e}\")\n",
        "    return images\n",
        "\n",
        "\n",
        "def text_info_for_page(pdf_file, page):\n",
        "    texts = {\"full_text\": \"\", \"spans\": []}\n",
        "    file_dict = page.get_text(\"dict\")\n",
        "    texts[\"full_text\"] = str(page.get_text(sort=True))\n",
        "\n",
        "    blocks = file_dict[\"blocks\"]\n",
        "    for block in blocks:\n",
        "        # print(block)\n",
        "        if block[\"type\"] == 0:\n",
        "            # print(block[\"lines\"])\n",
        "            for line in block[\"lines\"]:\n",
        "                for span in line[\"spans\"]:\n",
        "                    # print(span)\n",
        "                    if span[\"text\"].strip() != \"\":\n",
        "                        texts[\"spans\"].append(span)\n",
        "                        # print(span['text'])\n",
        "    return texts\n",
        "\n",
        "\n",
        "def get_info_for_page(pdf_file, page, page_index, images_path, gcs_bucket=None):\n",
        "    text_info = {}\n",
        "    image_info = []\n",
        "    image_info = image_info_for_page(\n",
        "        pdf_file, images_path, page, page_index, gcs_bucket\n",
        "    )\n",
        "    text_info = text_info_for_page(pdf_file, page)\n",
        "    return {\"images\": image_info, \"texts\": text_info}\n",
        "\n",
        "\n",
        "def check_text_pdf(filename, input_gcs_bucket=None):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        if input_gcs_bucket:\n",
        "            bucket_object = storage.Client().bucket(input_gcs_bucket)\n",
        "            blob = bucket_object.blob(filename)\n",
        "            pdf_file = fitz.open(\"pdf\", blob.download_as_bytes())\n",
        "        else:\n",
        "            pdf_file = fitz.open(filename)\n",
        "        text = True\n",
        "        for i, page in enumerate(pdf_file):\n",
        "            if page.get_text():\n",
        "                pass\n",
        "            else:\n",
        "                text = False\n",
        "                print(f\"[ERROR]: Page {i+1} of \" f\"{filename} PDF is a scanned page!\")\n",
        "                break\n",
        "        return text\n",
        "    else:\n",
        "        print(f\"[ERROR]: {filename} is not a valid PDF!\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def get_info_for_pdf(\n",
        "    filename, images_path, input_gcs_bucket=None, image_gcs_bucket=None\n",
        "):\n",
        "    if input_gcs_bucket:\n",
        "        bucket_object = storage.Client().bucket(input_gcs_bucket)\n",
        "        blob = bucket_object.blob(filename)\n",
        "        pdf_file = fitz.open(\"pdf\", blob.download_as_bytes())\n",
        "    else:\n",
        "        pdf_file = fitz.open(filename)\n",
        "    pdf_dict = {\"pages\": [], \"file_url\": f\"gs://{input_gcs_bucket}/{filename}\"}\n",
        "    for page_index, page in enumerate(pdf_file, start=1):\n",
        "        page_info = get_info_for_page(\n",
        "            pdf_file, page, page_index, images_path, image_gcs_bucket\n",
        "        )\n",
        "        pdf_dict[\"pages\"].append(page_info)\n",
        "    return pdf_dict\n",
        "\n",
        "\n",
        "def parse_pdf(filename, input_gcs_bucket, output_gcs_bucket):\n",
        "    name = filename.split(\"/\")[-1]\n",
        "    images_path = f\"images/{name}\".replace(\".pdf\", \"\")\n",
        "    pdf_json = get_info_for_pdf(\n",
        "        filename, images_path, input_gcs_bucket, output_gcs_bucket\n",
        "    )\n",
        "    # create_json_from_dict(json_path,pdf_json,output_gcs_bucket)\n",
        "    return pdf_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6697b113-bbea-4f39-b1ca-584a76b8b6c2",
      "metadata": {
        "id": "3939cdf8d000"
      },
      "outputs": [],
      "source": [
        "def get_todays_date():\n",
        "    \"\"\"Returns today's date in 'DD_MM_YYYY' format.\"\"\"\n",
        "    today = datetime.date.today()\n",
        "    return today.strftime(\"%d_%m_%Y\")\n",
        "\n",
        "\n",
        "def download_blob(\n",
        "    bucket_name, source_blob_name, destination_file_name, prefix, csv_folder\n",
        "):\n",
        "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(f\"{prefix}/{source_blob_name}\")\n",
        "    blob.download_to_filename(f\"{csv_folder}/{destination_file_name}\")\n",
        "    print(\n",
        "        \"[INFO]: Downloaded storage object \"\n",
        "        \"{} from bucket {} to local file {}.\".format(\n",
        "            source_blob_name, bucket_name, destination_file_name\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def upload_blob(bucket_name, source_file_name, destination_blob_name, prefix, date_):\n",
        "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(f\"{prefix}/{date_}/{destination_blob_name}\")\n",
        "    blob.upload_from_filename(source_file_name)\n",
        "\n",
        "    print(f\"[INFO]: File {source_file_name} \" f\"uploaded to {destination_blob_name}.\")\n",
        "\n",
        "\n",
        "def get_csv_info(csv_gcs_uri, bucket_name, csv_folder):\n",
        "    download_blob(\n",
        "        bucket_name,\n",
        "        csv_gcs_uri.split(\"/\")[-1],\n",
        "        csv_gcs_uri.split(\"/\")[-1],\n",
        "        csv_gcs_uri.split(\"/\")[-2],\n",
        "        csv_folder,\n",
        "    )\n",
        "    with open(f\"{csv_folder}/{csv_gcs_uri.split('/')[-1]}\", \"r\") as f:\n",
        "        reader = csv.reader(f)\n",
        "        csv_data = list(reader)\n",
        "    return csv_data[1:]\n",
        "\n",
        "\n",
        "def download_pdf(url, filename):\n",
        "    response = requests.get(url)\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "def update_output_json(\n",
        "    json_output_response,\n",
        "    faq_json,\n",
        "    isq_json,\n",
        "    product_images,\n",
        "    product_category,\n",
        "    product_tags,\n",
        "    error_ws2_message,\n",
        "):\n",
        "    todays_date = get_todays_date()\n",
        "    products_output_response = get_output_template()\n",
        "    products_output_response[0][\"product_name_citation\"][0][\n",
        "        \"created_date\"\n",
        "    ] = todays_date\n",
        "    products_output_response[0][\"specification_citation\"][0][\n",
        "        \"created_date\"\n",
        "    ] = todays_date\n",
        "    products_output_response[0][\"product_image_citation\"][0][\n",
        "        \"created_date\"\n",
        "    ] = todays_date\n",
        "    products_output_response[0][\"product_category_citation\"][0][\n",
        "        \"created_date\"\n",
        "    ] = todays_date\n",
        "\n",
        "    try:\n",
        "        products_output_response[0][\"product_images\"] = product_images\n",
        "        products_output_response[0][\"product_category\"] = product_category\n",
        "        products_output_response[0][\"product_tags\"] = product_tags\n",
        "        if \"response_error\" not in isq_json:\n",
        "            if \"product_name\" in isq_json:\n",
        "                products_output_response[0][\"product_name\"] = isq_json[\"product_name\"]\n",
        "            if \"confidence_score\" in isq_json:\n",
        "                products_output_response[0][\"product_name_citation\"][0][\n",
        "                    \"confidence_score\"\n",
        "                ] = isq_json[\"confidence_score\"]\n",
        "                products_output_response[0][\"specification_citation\"][0][\n",
        "                    \"confidence_score\"\n",
        "                ] = isq_json[\"confidence_score\"]\n",
        "            if \"specifications\" in isq_json:\n",
        "                products_output_response[0][\"specification\"] = isq_json[\n",
        "                    \"specifications\"\n",
        "                ]\n",
        "            json_output_response[\"products\"].extend(products_output_response)\n",
        "        else:\n",
        "            products_output_response[0] = {**products_output_response[0], **isq_json}\n",
        "            json_output_response[\"products\"].extend(products_output_response)\n",
        "        if (\n",
        "            \"response_error\" not in products_output_response[0]\n",
        "            and error_ws2_message != \"\"\n",
        "        ):\n",
        "            response_error = {\"message\": error_ws2_message}\n",
        "            products_output_response[0][\"response_error\"] = response_error\n",
        "        if \"response_error\" not in faq_json:\n",
        "            json_output_response[\"catalogue_faqs\"].extend(\n",
        "                faq_json[list(faq_json.keys())[0]]\n",
        "            )\n",
        "        else:\n",
        "            json_output_response[\"catalogue_faqs\"].append(faq_json)\n",
        "\n",
        "        return json_output_response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR]: Error while updating output JSON - {e}\")\n",
        "        return {}\n",
        "\n",
        "\n",
        "def get_output_template():\n",
        "    products_output_response = [\n",
        "        {\n",
        "            \"product_name\": [],\n",
        "            \"product_name_citation\": [\n",
        "                {\n",
        "                    \"pdf_name\": \"\",\n",
        "                    \"url\": \"\",\n",
        "                    \"page\": 0,\n",
        "                    \"startIndex\": [],\n",
        "                    \"endIndex\": [],\n",
        "                    \"confidence_score\": 0.0,\n",
        "                    \"created_date\": \"01/01/1970\",\n",
        "                }\n",
        "            ],\n",
        "            \"specification\": {},\n",
        "            \"specification_citation\": [\n",
        "                {\n",
        "                    \"attribute\": \"\",\n",
        "                    \"pdf_name\": \"\",\n",
        "                    \"url\": \"\",\n",
        "                    \"page\": 0,\n",
        "                    \"startIndex\": [],\n",
        "                    \"endIndex\": [],\n",
        "                    \"confidence_score\": 0.0,\n",
        "                    \"created_date\": \"01/01/1970\",\n",
        "                }\n",
        "            ],\n",
        "            \"product_images\": [],\n",
        "            \"product_image_citation\": [\n",
        "                {\n",
        "                    \"pdf_name\": \"\",\n",
        "                    \"url\": \"\",\n",
        "                    \"page\": 0,\n",
        "                    \"startIndex\": [],\n",
        "                    \"endIndex\": [],\n",
        "                    \"confidence_score\": 0.0,\n",
        "                    \"created_date\": \"01/01/1970\",\n",
        "                }\n",
        "            ],\n",
        "            \"product_category\": [],\n",
        "            \"product_tags\": [],\n",
        "            \"product_category_citation\": [\n",
        "                {\n",
        "                    \"pdf_name\": \"\",\n",
        "                    \"url\": \"\",\n",
        "                    \"page\": 0,\n",
        "                    \"startIndex\": [],\n",
        "                    \"endIndex\": [],\n",
        "                    \"confidence_score\": 0.0,\n",
        "                    \"created_date\": \"01/01/1970\",\n",
        "                }\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "    return products_output_response\n",
        "\n",
        "\n",
        "def create_json_from_dict(json_path, dict_, gcs_bucket=None):\n",
        "    if gcs_bucket:\n",
        "        bucket_object = storage.Client().get_bucket(gcs_bucket)\n",
        "        json_path = bucket_object.blob(json_path)\n",
        "        json_obj = json.dumps(dict_)\n",
        "        json_path.upload_from_string(data=json_obj, content_type=\"application/json\")\n",
        "    else:\n",
        "        with open(json_path, \"w\") as outfile:\n",
        "            json.dump(dict_, outfile)\n",
        "\n",
        "\n",
        "def check_pdf_type(filename, input_gcs_bucket=None):\n",
        "    scanned = False\n",
        "    tables = False\n",
        "    images = False\n",
        "    total_images = 0\n",
        "    if input_gcs_bucket:\n",
        "        bucket_object = storage.Client().bucket(input_gcs_bucket)\n",
        "        blob = bucket_object.blob(filename)\n",
        "        pdf_file = fitz.open(\"pdf\", blob.download_as_bytes())\n",
        "    else:\n",
        "        pdf_file = fitz.open(filename)\n",
        "    pages = []\n",
        "    for page_no, page in enumerate(pdf_file, start=1):\n",
        "        page_wise_details = {\n",
        "            \"scanned\": False,\n",
        "            \"Images\": False,\n",
        "            \"Tables\": False,\n",
        "            \"Total Images\": 0,\n",
        "        }\n",
        "        print(f\"Page no {page_no}\")\n",
        "        if not page.get_text():\n",
        "            print(\"[Info]: scanned!\")\n",
        "            scanned = True\n",
        "            page_wise_details[\"scanned\"] = True\n",
        "        images_info = page.get_images()\n",
        "        print(f\"[Info]: No of images: {len(images_info)}\")\n",
        "        if len(images_info) > 0:\n",
        "            images = True\n",
        "            page_wise_details[\"Images\"] = True\n",
        "            page_wise_details[\"Total Images\"] = len(images_info)\n",
        "            total_images = total_images + len(images_info)\n",
        "        tables = page.find_tables()\n",
        "        if len(list(tables)) > 0:\n",
        "            print(\"[Info]: Tables present\")\n",
        "            tables = True\n",
        "            page_wise_details[\"Tables\"] = True\n",
        "        pages.append(page_wise_details)\n",
        "    return {\n",
        "        \"scanned\": scanned,\n",
        "        \"Tables\": tables,\n",
        "        \"Images\": images,\n",
        "        \"Total_Images\": total_images,\n",
        "        \"pages\": pages,\n",
        "    }\n",
        "\n",
        "\n",
        "def end_to_end_pipeline(input_pdf_uri, output_gcs_bucket, project_id):\n",
        "    # csv_folder = \"csv\"\n",
        "    pdf_folder = \"pdf_files\"\n",
        "    # date_ = get_todays_date()\n",
        "    # os.makedirs(csv_folder, exist_ok=True)\n",
        "    os.makedirs(pdf_folder, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        start = time.time()\n",
        "        # csv_data = get_csv_info(csv_gcs_uri, bucket_name, csv_folder)\n",
        "        end = time.time()\n",
        "        print(f\"[INFO]: CSV data fetched \" f\"successfully in {end - start} seconds\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR]: Error \" f\"during fetching data from CSV - {e}\")\n",
        "        return None\n",
        "\n",
        "    uri = input_pdf_uri\n",
        "\n",
        "    # check if file name exists\n",
        "    full_path = uri.replace(\"gs://\", \"\")\n",
        "    input_gcs_bucket = full_path.split(\"/\")[0]\n",
        "    filename = full_path.replace(f\"{input_gcs_bucket}/\", \"\")\n",
        "    name = filename.split(\"/\")[-1]\n",
        "    output_gcs_bucket = output_gcs_bucket\n",
        "\n",
        "    try:\n",
        "        pdf_type = check_pdf_type(filename, input_gcs_bucket)\n",
        "        if not pdf_type[\"scanned\"]:\n",
        "            start = time.time()\n",
        "            pdf_json = parse_pdf(filename, input_gcs_bucket, output_gcs_bucket)\n",
        "            end = time.time()\n",
        "            print(f\"[INFO]: Parsed PDF successfully in {end - start} seconds\")\n",
        "\n",
        "            pdf_json = get_specific_caption(pdf_json)\n",
        "            name_initials = name.replace(\".pdf\", \"\")\n",
        "            json_path = f\"./{name_initials}.json\"\n",
        "            create_json_from_dict(json_path, pdf_json, output_gcs_bucket)\n",
        "            pdf_json = clean_text(pdf_json)\n",
        "            json_output_response = {\n",
        "                \"pdf_name\": f\"{filename.split('/')[-1]}\",\n",
        "                \"pdf_url\": uri,  # f\"gs://{input_gcs_bucket}/{filename}\",\n",
        "                \"company_details\": {},\n",
        "                \"products\": [],\n",
        "                \"catalogue_faqs\": [],\n",
        "                # \"pc_item_doc_id\": pc_item_doc_id,\n",
        "                # \"pc_doc_modified_date\": pc_doc_modified_date,\n",
        "                # \"pc_item_doc_path\": pc_item_doc_path,\n",
        "                # \"fk_pc_item_id\": fk_pc_item_id,\n",
        "                # \"fk_glusr_usr_id\": fk_glusr_usr_id\n",
        "            }\n",
        "            print(json_output_response, \"\\n\")\n",
        "            start = time.time()\n",
        "            company_text = get_company_text(pdf_json[\"pages\"])\n",
        "            if company_text:\n",
        "                company_details = generate_company_details(company_text, project_id)\n",
        "                if \"company_details\" in company_details:\n",
        "                    json_output_response[\"company_details\"] = company_details[\n",
        "                        \"company_details\"\n",
        "                    ]\n",
        "                elif \"response_error\" in company_details:\n",
        "                    json_output_response[\"company_details\"] = company_details\n",
        "                else:\n",
        "                    json_output_response[\"company_details\"] = {}\n",
        "            end = time.time()\n",
        "            print(f\"[INFO]: Company details \" f\"extraction time: {end - start} seconds\")\n",
        "            for page_no, page in enumerate(pdf_json[\"pages\"]):\n",
        "                try:\n",
        "                    print(str(page_no))\n",
        "                    context = page[\"texts\"][\"full_text\"]\n",
        "                    start = time.time()\n",
        "                    faq_json = generate_faqs(context, project_id)\n",
        "                    isq_json = generate_isqs(context, project_id)\n",
        "                    end = time.time()\n",
        "                    print(\n",
        "                        f\"[INFO]: FAQ, ISQ generation \"\n",
        "                        f\"time for page {page_no + 1}: \"\n",
        "                        f\"{end - start} seconds\"\n",
        "                    )\n",
        "\n",
        "                    error_ws2_msg = \"\"\n",
        "                    try:\n",
        "                        products = isq_json[\"product_name\"]\n",
        "                    except Exception:\n",
        "                        products = []\n",
        "                    print(\"Products:\", products)\n",
        "                    if len(products) > 0:\n",
        "                        try:\n",
        "                            start = time.time()\n",
        "                            product_tags = generate_tags_json(context, products)\n",
        "                            end = time.time()\n",
        "                            print(\n",
        "                                f\"[INFO]: Product tag \"\n",
        "                                f\"generation time for page {page_no + 1}: \"\n",
        "                                f\"{end - start} seconds\"\n",
        "                            )\n",
        "                        except Exception:\n",
        "                            print(\n",
        "                                f\"[ERROR]: Error during generation \"\n",
        "                                f\"of product tags -\"\n",
        "                                f\" {str(traceback.format_exc())}\"\n",
        "                            )\n",
        "                            error_ws2_msg = error_ws2_msg\n",
        "                            product_tags = {}\n",
        "                        try:\n",
        "                            start = time.time()\n",
        "                            product_category = generate_category_json(context, products)\n",
        "                            end = time.time()\n",
        "                            print(\n",
        "                                f\"[INFO]: Product category generation time \"\n",
        "                                f\"for page {page_no + 1}: \"\n",
        "                                f\"{end - start} seconds\"\n",
        "                            )\n",
        "                        except Exception:\n",
        "                            print(\n",
        "                                f\"[ERROR]: Error during generation of\"\n",
        "                                f\" product category - \"\n",
        "                                f\"{str(traceback.format_exc())}\"\n",
        "                            )\n",
        "                            product_category = {}\n",
        "\n",
        "                        try:\n",
        "                            start = time.time()\n",
        "                            image_json = generate_images_json(\n",
        "                                page, products, product_tags, output_gcs_bucket\n",
        "                            )\n",
        "                            end = time.time()\n",
        "                            print(\n",
        "                                f\"[INFO]: Image JSON generation \"\n",
        "                                f\"time for page {page_no + 1}:\"\n",
        "                                f\" {end - start} seconds\"\n",
        "                            )\n",
        "                        except Exception as error:\n",
        "                            print(\n",
        "                                f\"[ERROR]: Error during generation \"\n",
        "                                f\"of product category - \"\n",
        "                                f\"{str(traceback.format_exc())} + {error}\"\n",
        "                            )\n",
        "                            error_ws2_msg = (\n",
        "                                error_ws2_msg + \"\\n\" + \"Product image json \"\n",
        "                                \"generation failed - {str(e)}\"\n",
        "                            )\n",
        "                            image_json = {}\n",
        "                    else:\n",
        "                        product_tags = {}\n",
        "                        product_category = {}\n",
        "                        image_json = {}\n",
        "\n",
        "                    start = time.time()\n",
        "                    json_output_response = update_output_json(\n",
        "                        json_output_response,\n",
        "                        faq_json,\n",
        "                        isq_json,\n",
        "                        image_json,\n",
        "                        product_category,\n",
        "                        product_tags,\n",
        "                        error_ws2_msg,\n",
        "                    )\n",
        "                    end = time.time()\n",
        "                    print(\n",
        "                        f\"[INFO]: Output for page {page_no + 1}: \"\n",
        "                        f\"updated in {end - start} seconds\"\n",
        "                    )\n",
        "                except Exception as error:\n",
        "                    print(\n",
        "                        f\"[ERROR]: Error during generating \"\n",
        "                        f\"final json - \"\n",
        "                        f\"{str(traceback.format_exc())} - {error}\"\n",
        "                    )\n",
        "\n",
        "            final_json_path = f\"{name_initials}_output.json\"\n",
        "            start = time.time()\n",
        "            create_json_from_dict(\n",
        "                final_json_path, json_output_response, output_gcs_bucket\n",
        "            )\n",
        "            end = time.time()\n",
        "            print(\n",
        "                f\"[INFO]: Final output JSON \"\n",
        "                f\"uploaded to GCS in {end - start} seconds\"\n",
        "            )\n",
        "        else:\n",
        "            print(\"[INFO]: Please process text PDF's only!\")\n",
        "\n",
        "        return json_output_response\n",
        "    except Exception as error:\n",
        "        print(\n",
        "            f\"[ERROR]: Error for filename: \"\n",
        "            f\"{filename} - {str(traceback.format_exc())} - {error}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce641a91-9611-4a64-b29c-0e5d78136f93",
      "metadata": {
        "id": "e16bb45d3513"
      },
      "source": [
        "### ALl set lets run the pipeline \n",
        "\n",
        "Set these variables below:\n",
        "\n",
        "1. Enter `YOUR_PROJECT_ID` in project_id\n",
        "2. Enter `Input PDF GCS URI` in pdf_uri\n",
        "3. Enter `Output GCS Bucket` in output_gcs_bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c002f534-97a9-4691-9073-5a92481a40bc",
      "metadata": {
        "id": "3b023312476c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO]: CSV data fetched successfully in 4.76837158203125e-07 seconds\n",
            "Page no 1\n",
            "[Info]: No of images: 2\n",
            "[Info]: Tables present\n",
            "[INFO]: Parsed PDF successfully in 0.6498634815216064 seconds\n",
            "[INFO]: Text cleaning completed successfully.\n",
            "{'pdf_name': 'hepasky-herbal-liver-tablets.pdf', 'pdf_url': 'gs://test-sl/hepasky-herbal-liver-tablets.pdf', 'company_details': {}, 'products': [], 'catalogue_faqs': []} \n",
            "\n",
            "[INFO]: Company Details Extraction Completed\n",
            "[INFO]: Company details extraction time: 1.0386943817138672 seconds\n",
            "0\n",
            "[INFO]: FAQ, ISQ generation time for page 1: 2.9087531566619873 seconds\n",
            "Products: ['HEPASKY']\n",
            "[INFO]: Product tag generation time for page 1: 0.6757297515869141 seconds\n",
            "[INFO]: Product category generation time for page 1: 0.439899206161499 seconds\n",
            "[INFO]: Image JSON generation time for page 1: 4.299449682235718 seconds\n",
            "[INFO]: Output for page 1: updated in 5.555152893066406e-05 seconds\n",
            "[INFO]: Final output JSON uploaded to GCS in 0.22490668296813965 seconds\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    start = time.time()\n",
        "    project_id = \"sl-test-project-353312\"\n",
        "    pdf_uri = \"gs://test-sl/hepasky-herbal-liver-tablets.pdf\"\n",
        "    output_gcs_bucket = \"test-sl\"\n",
        "    return_json = end_to_end_pipeline(pdf_uri, output_gcs_bucket, project_id)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "genai_prod_catalog_enrichment.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
